{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/code_location/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "import arch_generate_random_CNN\n",
    "import importlib\n",
    "importlib.reload(arch_generate_random_CNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "success = False\n",
    "\n",
    "while not success:\n",
    "    try:\n",
    "        brain_net_architecture, repeating_cnn_elements = arch_generate_random_CNN.get_random_cnn_architecture()\n",
    "\n",
    "        n_classes_dict = {'f0_label':700}\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        input_tensor = tf.placeholder(tf.float32, shape=[None, 100, 1000, 1], name='input_nervegrams')\n",
    "        output_tensor, nets = functions_brain_network.make_brain_net(input_tensor,\n",
    "                                                                     n_classes_dict,\n",
    "                                                                     brain_net_architecture,\n",
    "                                                                     trainable=True,\n",
    "                                                                     batchnorm_flag=True,\n",
    "                                                                     dropout_flag=True,\n",
    "                                                                     save_arch_path=None,\n",
    "                                                                     save_pckl_path=None,\n",
    "                                                                     only_include_layers=None)\n",
    "        success = True\n",
    "    except ValueError:\n",
    "        print('REPEAT')\n",
    "\n",
    "print('----> INPUT:', input_tensor.shape)\n",
    "for layer_dict in brain_net_architecture:\n",
    "    key = layer_dict['args']['name']\n",
    "    if 'conv' in key:\n",
    "        print('------ {} ------'.format(key))\n",
    "    if 'pool' in key or 'conv' in key:\n",
    "        print(layer_dict['args'])\n",
    "    print(key, nets[key].shape)\n",
    "\n",
    "    \n",
    "\n",
    "print('----> OUTPUT:', output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_possible_arch(n_classes_dict={'f0_label':700}):\n",
    "    success = False\n",
    "    count = 0\n",
    "    while not success:\n",
    "#         new_net = arch_generate_random_CNN.RandomCNN()\n",
    "        try:\n",
    "#             brain_net_architecture = new_net.all_layer_list\n",
    "            brain_net_architecture, repeating_cnn_elements = arch_generate_random_CNN.get_random_cnn_architecture()\n",
    "            tf.reset_default_graph()\n",
    "            input_tensor = tf.placeholder(tf.float32, shape=[None, 100, 1000, 1], name='input_nervegrams')\n",
    "            output_tensor, nets = functions_brain_network.make_brain_net(input_tensor,\n",
    "                                                                         n_classes_dict,\n",
    "                                                                         brain_net_architecture,\n",
    "                                                                         trainable=True,\n",
    "                                                                         batchnorm_flag=True,\n",
    "                                                                         dropout_flag=True,\n",
    "                                                                         save_arch_path=None,\n",
    "                                                                         save_pckl_path=None,\n",
    "                                                                         only_include_layers=None)\n",
    "            success = True\n",
    "        except ValueError:\n",
    "            count += 1\n",
    "#             print(count, len(new_net.num_conv_kernels))\n",
    "            pass\n",
    "    return brain_net_architecture, repeating_cnn_elements['conv_layer_count'], count, nets\n",
    "\n",
    "\n",
    "n_list = []\n",
    "arch_list = []\n",
    "nets_list = []\n",
    "count = 0\n",
    "for _ in range(100):\n",
    "    arch, n, count_i, nets = get_possible_arch()\n",
    "    n_list.append(n)\n",
    "    arch_list.append(arch)\n",
    "    nets_list.append(nets)\n",
    "    count += count_i\n",
    "    print(_, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(n_list, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = np.random.randint(len(arch_list))\n",
    "print(IDX)\n",
    "arch = arch_list[IDX]\n",
    "nets = nets_list[IDX]\n",
    "for layer_dict in arch:\n",
    "    layer_name = layer_dict['args']['name']\n",
    "    if 'conv' in layer_name:\n",
    "        print('------ {} ------'.format(layer_name))\n",
    "        print(nets[layer_name].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valid_format = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01/arch_{:04d}/validation_metrics.json'\n",
    "brain_format = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01/arch_{:04d}/brain_arch.json'\n",
    "\n",
    "\n",
    "def get_valid_trace(valid_metrics_fn, metric_key='f0_label:accuracy', checkpoint_number_key='step'):\n",
    "    '''\n",
    "    '''\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    valid_step = valid_metrics_dict[checkpoint_number_key]\n",
    "    ### START: WORK AROUND FOR BUG CAUSED BY PREEMPTING AND RESTARTING TRAINING (valid step is reset)\n",
    "    checkpoint_numbers = [valid_step[0]]\n",
    "    for idx, diff in enumerate(np.diff(valid_step)):\n",
    "        if diff > 0: checkpoint_numbers.append(checkpoint_numbers[-1] + diff)\n",
    "        else: checkpoint_numbers.append(checkpoint_numbers[-1] + valid_step[idx+1])\n",
    "    assert len(checkpoint_numbers) == len(valid_step)\n",
    "    assert len(checkpoint_numbers) == len(metric_values)\n",
    "    ### END: WORK AROUND FOR BUG CAUSED BY PREEMPTING AND RESTARTING TRAINING (valid step is reset)\n",
    "    return checkpoint_numbers, metric_values\n",
    "\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    '''\n",
    "    '''\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "\n",
    "list_traces = []\n",
    "list_num_layers = []\n",
    "list_best_metric = []\n",
    "list_arch_nums = []\n",
    "\n",
    "for idx in range(750):\n",
    "    brain_arch_fn = brain_format.format(idx)\n",
    "    valid_metrics_fn = valid_format.format(idx)\n",
    "    \n",
    "    if os.path.exists(brain_arch_fn) and os.path.exists(valid_metrics_fn):\n",
    "        list_traces.append(get_valid_trace(valid_metrics_fn))\n",
    "        list_num_layers.append(calc_num_layers(brain_arch_fn))\n",
    "        list_best_metric.append(calc_best_metric(valid_metrics_fn))\n",
    "        list_arch_nums.append(idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCOLS = 5\n",
    "NROWS = 1\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(4*NCOLS, 4*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].hist(list_num_layers, 8, color='k')\n",
    "ax[0].set_xlabel('Number of conv layers')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[1].hist(list_best_metric, 100, color='k')\n",
    "ax[1].set_xlabel('Validation accuracy')\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[2].plot(list_num_layers, list_best_metric, 'k.')\n",
    "ax[2].set_xlabel('Number of conv layers')\n",
    "ax[2].set_ylabel('Validation accuracy')\n",
    "ax[3].plot(np.sort(list_best_metric), 'k.')\n",
    "ax[3].set_xlabel('Arch number')\n",
    "ax[3].set_ylabel('Validation accuracy')\n",
    "\n",
    "for idx, (checkpoint_numbers, metric_values) in enumerate(list_traces):\n",
    "    if list_num_layers[idx] > 0:\n",
    "        ax[4].plot(checkpoint_numbers, metric_values, ls='-', lw=0.25, color='k')\n",
    "    else:\n",
    "        ax[4].plot(checkpoint_numbers, metric_values, ls='-', lw=0.25, color='b')\n",
    "ax[4].set_xlabel('Step number')\n",
    "ax[4].set_ylabel('Validation accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_05_PNDv08_archSearch01/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC04_arch_search_v01_summary.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_sort_idx = np.argsort(list_best_metric)\n",
    "bidx = metric_sort_idx[-10]\n",
    "print(list_arch_nums[bidx], list_best_metric[bidx], list_num_layers[bidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = '/om2/user/msaddler/pitchnet/saved_models/PND_v04_TLAS_classification0'\n",
    "arch_fn = os.path.join(output_dir, 'brain_arch.json')\n",
    "\n",
    "arch_fn_list = [\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0703/brain_arch.json',\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0693/brain_arch.json',\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0156/brain_arch.json',\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0051/brain_arch.json',\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0342/brain_arch.json',\n",
    "'/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0664/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0084/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0265/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0637/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0086/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0254/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0416/brain_arch.json',\n",
    "]\n",
    "\n",
    "# arch_fn_list = [\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0628/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0374/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0471/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0018/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0610/brain_arch.json',\n",
    "# '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0429/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0721/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0282/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0682/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0533/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0466/brain_arch.json',\n",
    "# # '/om/scratch/Sun/msaddler/pitchnet/saved_models/arch_search_v00/arch_0284/brain_arch.json',\n",
    "# ]\n",
    "\n",
    "for arch_fn in arch_fn_list:\n",
    "\n",
    "    with open(arch_fn) as f:\n",
    "        arch_list = json.load(f)\n",
    "    print('_' * len(arch_fn))\n",
    "    print(arch_fn)\n",
    "    for layer in arch_list:\n",
    "        if layer['layer_type'] == 'tf.layers.conv2d':\n",
    "            print('layer: {} | kernel_shape: {} | filters: {}'.format(\n",
    "                layer['args']['name'], layer['args']['kernel_size'], layer['args']['filters']))\n",
    "        elif 'pool' in layer['layer_type']:\n",
    "            print('layer: {} | strides: {} | pool_size: {}'.format(\n",
    "                layer['args']['name'], layer['args']['strides'], layer['args']['pool_size']))\n",
    "        elif layer['layer_type'] == 'tf.layers.dense':\n",
    "            print('layer: {} | units: {}'.format(\n",
    "                layer['args']['name'], layer['args']['units']))\n",
    "        elif layer['layer_type'] in ['tf.nn.relu',\n",
    "                                     'tf.layers.batch_normalization',\n",
    "                                     'tf.layers.dropout',\n",
    "                                     'fc_top_classification'\n",
    "                                    ]:\n",
    "            print('layer: {}'.format(layer['args']['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import arch_generate_random_CNN\n",
    "import importlib\n",
    "importlib.reload(arch_generate_random_CNN)\n",
    "\n",
    "for _ in range(20):\n",
    "    layer_list, repeating_cnn_elements = arch_generate_random_CNN.get_random_cnn_architecture()\n",
    "#         kwargs_sample_repeating_cnn_elements={'max_kernel_area':100})\n",
    "    conv_layer_count = repeating_cnn_elements['conv_layer_count']\n",
    "    print('----')\n",
    "    for layer_index in range(conv_layer_count):\n",
    "        kernel_shapes = repeating_cnn_elements['conv_kernel_shapes'][layer_index]\n",
    "        kernel_depths = repeating_cnn_elements['conv_kernel_depths'][layer_index]\n",
    "        pool_strides = repeating_cnn_elements['pool_strides'][layer_index]\n",
    "        print(layer_index, kernel_shapes+[kernel_depths], pool_strides)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/code_location/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "import arch_generate_random_CNN\n",
    "import arch_generate_output_directory\n",
    "import importlib\n",
    "\n",
    "\n",
    "def modify_arch(brain_net_architecture,\n",
    "                list_factor_dim1=[1, 1, 1, 1, 1],\n",
    "                list_max_dim1=[100, 100, 100, 34, 34],\n",
    "                verbose=True):\n",
    "    '''\n",
    "    '''\n",
    "    if not isinstance(list_factor_dim1, list):\n",
    "        list_factor_dim1 = [list_factor_dim1] * len(list_max_dim1)\n",
    "    \n",
    "    layer_idx = 0\n",
    "    for layer_dict in brain_net_architecture:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            max_dim1 = list_max_dim1[layer_idx]\n",
    "            factor_dim1 = list_factor_dim1[layer_idx]\n",
    "            [dim1, dim2] = layer_dict['args']['kernel_size']\n",
    "            \n",
    "            old_area = dim1 * dim2\n",
    "            dim1_new = np.ceil(dim1 * factor_dim1).astype(int)\n",
    "            dim1_new = min(max_dim1, dim1_new)\n",
    "            dim2_new = np.ceil(old_area / dim1_new).astype(int)\n",
    "            new_area = dim1_new * dim2_new\n",
    "            \n",
    "            layer_dict['args']['kernel_size'] = [dim1_new, dim2_new]\n",
    "            \n",
    "            if verbose:\n",
    "                print('conv_{}: {}-->{}, {}-->{}'.format(layer_idx,\n",
    "                                                         [dim1, dim2],\n",
    "                                                         [dim1_new, dim2_new],\n",
    "                                                         old_area,\n",
    "                                                         new_area))\n",
    "            \n",
    "            layer_idx += 1\n",
    "            \n",
    "    return brain_net_architecture\n",
    "\n",
    "\n",
    "def modify_arch_first_layer(brain_net_architecture,\n",
    "                            factor_dim1=1,\n",
    "                            factor_dim2=1,\n",
    "                            verbose=True):\n",
    "    '''\n",
    "    '''\n",
    "    for layer_dict in brain_net_architecture:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            [dim1, dim2] = layer_dict['args']['kernel_size']\n",
    "            dim1_new = np.round(dim1 * factor_dim1).astype(int)\n",
    "            dim2_new = np.round(dim2 * factor_dim2).astype(int)\n",
    "            layer_dict['args']['kernel_size'] = [dim1_new, dim2_new]\n",
    "            if verbose:\n",
    "                print('conv_{}: {}-->{}'.format(0, [dim1, dim2], [dim1_new, dim2_new]))\n",
    "            \n",
    "            break\n",
    "    return brain_net_architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "conv_0: [1, 250]-->[1, 25]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 67584), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0000/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 38]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 67584), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0001/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 50]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 61440), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0002/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 63]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 61440), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0003/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 75]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 61440), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0004/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 88]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 55296), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0005/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 100]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 55296), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0006/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 113]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 49152), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0007/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 125]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 49152), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0008/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 138]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 49152), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0009/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 150]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 43008), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0010/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 163]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 43008), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0011/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 175]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 43008), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0012/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 188]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 36864), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0013/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 200]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 36864), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0014/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 213]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 36864), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0015/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 225]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 30720), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0016/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 238]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 30720), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0017/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 250]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 30720), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0018/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 263]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 24576), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0019/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 275]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 24576), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0020/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 288]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 18432), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0021/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 300]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 18432), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0022/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 313]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 18432), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0023/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 325]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 12288), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0024/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 338]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 12288), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0025/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 350]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 12288), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0026/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 363]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 6144), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0027/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 375]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 6144), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0028/brain_arch.json\n",
      "conv_0: [1, 250]-->[1, 388]\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 6144), dtype=float32)\n",
      "/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0029/brain_arch.json\n"
     ]
    }
   ],
   "source": [
    "# Max possible dim2 scaling factor = 1.56 (leads to kernel with length 390 in time dimension)\n",
    "\n",
    "# manipulation_list = [\n",
    "# #     (1, 1),\n",
    "# #     (2, 1),\n",
    "# #     (3, 1),\n",
    "# #     (4, 1),\n",
    "# #     (5, 1),\n",
    "# #     (10, 1),\n",
    "#     (1, 1.56),\n",
    "# ]\n",
    "\n",
    "manipulation_list = [(1, x) for x in np.arange(0.1, 1.561, 0.05)]\n",
    "print(len(manipulation_list))\n",
    "\n",
    "# Baseline architecture\n",
    "brain_arch_fn = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/brain_arch_0302validtime.json'\n",
    "\n",
    "# Filename format for saving modified architectures and creating output directories\n",
    "new_arch_fn_format = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_{:04d}/brain_arch.json'\n",
    "\n",
    "for arch_IDX, (factor_dim1, factor_dim2) in enumerate(manipulation_list):\n",
    "    with open(brain_arch_fn) as f:\n",
    "        brain_net_architecture = json.load(f)\n",
    "    # Create new architecture config\n",
    "    brain_net_architecture = modify_arch_first_layer(brain_net_architecture,\n",
    "                                                     factor_dim1=factor_dim1,\n",
    "                                                     factor_dim2=factor_dim2,\n",
    "                                                     verbose=True)\n",
    "    # Test new architecture config\n",
    "    tf.reset_default_graph()\n",
    "    n_classes_dict = {'f0_label':700}\n",
    "    batch_size = 128\n",
    "    input_tensor = tf.placeholder(tf.float32, shape=[batch_size, 100, 1000, 1], name='input_nervegrams')\n",
    "    output_tensor, nets = functions_brain_network.make_brain_net(input_tensor,\n",
    "                                                                 n_classes_dict,\n",
    "                                                                 brain_net_architecture,\n",
    "                                                                 trainable=True,\n",
    "                                                                 batchnorm_flag=True,\n",
    "                                                                 dropout_flag=True,\n",
    "                                                                 save_arch_path=None,\n",
    "                                                                 save_pckl_path=None,\n",
    "                                                                 only_include_layers=None)\n",
    "    print('--- TENSORS ---')\n",
    "    for key in ['flatten_end_conv']:#sorted(nets.keys()):\n",
    "        print(key, nets[key])\n",
    "    \n",
    "    # Save new architecture config\n",
    "    new_arch_fn = new_arch_fn_format.format(arch_IDX)\n",
    "    print(new_arch_fn)\n",
    "    \n",
    "#     output_dir, basename = os.path.split(new_arch_fn)\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.mkdir(output_dir)\n",
    "#     arch_generate_output_directory.save_network_architecture(brain_net_architecture, new_arch_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### [1, 1, 1, 1, 1] ######\n",
      "\n",
      "conv_0: [1, 250]-->[1, 250], 250-->250\n",
      "conv_1: [19, 11]-->[19, 11], 209-->209\n",
      "conv_2: [12, 9]-->[12, 9], 108-->108\n",
      "conv_3: [7, 7]-->[7, 7], 49-->49\n",
      "conv_4: [5, 3]-->[5, 3], 15-->15\n",
      "WARNING:tensorflow:From /code_location/multi_gpu/functions_brain_network.py:355: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /code_location/multi_gpu/functions_brain_network.py:55: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /code_location/multi_gpu/functions_brain_network.py:75: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /code_location/multi_gpu/functions_brain_network.py:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /code_location/multi_gpu/functions_brain_network.py:83: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "--- TENSORS ---\n",
      "flatten_end_conv Tensor(\"flatten_end_conv/Reshape:0\", shape=(128, 30720), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "manipulation_list = [\n",
    "    # Original (with valid padding)\n",
    "    [1, 1, 1, 1, 1],\n",
    "\n",
    "    # Perturbations to make filters shorter in freq and longer in time\n",
    "    [1, 0.3, 1, 1, 1],\n",
    "    [1, 0.35, 1, 1, 1],\n",
    "    [1, 0.4, 1, 1, 1],\n",
    "    [1, 0.45, 1, 1, 1],\n",
    "    [1, 0.5, 1, 1, 1],\n",
    "    [1, 0.55, 1, 1, 1],\n",
    "    [1, 0.6, 1, 1, 1],\n",
    "    [1, 0.65, 1, 1, 1],\n",
    "    [1, 0.7, 1, 1, 1],\n",
    "    [1, 0.75, 1, 1, 1],\n",
    "    [1, 0.8, 1, 1, 1],\n",
    "    [1, 0.85, 1, 1, 1],\n",
    "    [1, 0.9, 1, 1, 1],\n",
    "    [1, 0.95, 1, 1, 1],\n",
    "    [1, 1, 0.7, 1, 1],\n",
    "    [1, 1, 0.8, 1, 1],\n",
    "    [1, 1, 0.9, 1, 1],\n",
    "    [1, 1, 1, 0.7, 1],\n",
    "    [1, 1, 1, 0.8, 1],\n",
    "    [1, 1, 1, 1, 0.6],\n",
    "    [1, 1, 1, 1, 0.8],\n",
    "    \n",
    "    # Perturbations to make filters longer in freq and shorter in time\n",
    "    [1, 1.2, 1, 1, 1],\n",
    "    [1, 1.4, 1, 1, 1],\n",
    "    [1, 1.6, 1, 1, 1],\n",
    "    [1, 1.8, 1, 1, 1],\n",
    "    [1, 2.0, 1, 1, 1],\n",
    "    \n",
    "    [2, 1, 1, 1, 1],\n",
    "    [2, 2, 1, 1, 1],\n",
    "    [2, 2, 2, 1, 1],\n",
    "    [2, 2, 2, 2, 1],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    \n",
    "    [3, 1, 1, 1, 1],\n",
    "    [3, 3, 1, 1, 1],\n",
    "    [3, 3, 3, 1, 1],\n",
    "    [3, 3, 3, 3, 1],\n",
    "    [3, 3, 3, 3, 3],\n",
    "    \n",
    "    [4, 1, 1, 1, 1],\n",
    "    [4, 4, 1, 1, 1],\n",
    "    [4, 4, 4, 1, 1],\n",
    "    [4, 4, 4, 4, 1],\n",
    "    [4, 4, 4, 4, 4],\n",
    "    \n",
    "    [5, 1, 1, 1, 1],\n",
    "    [5, 5, 1, 1, 1],\n",
    "    [5, 5, 5, 1, 1],\n",
    "    [5, 5, 5, 5, 1],\n",
    "    [5, 5, 5, 5, 5],\n",
    "]\n",
    "\n",
    "\n",
    "for list_factor_dim1 in manipulation_list:\n",
    "    print('\\n###### {} ######\\n'.format(list_factor_dim1))\n",
    "    brain_arch_fn = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/brain_arch_0302validtime.json'\n",
    "    with open(brain_arch_fn) as f:\n",
    "        brain_net_architecture = json.load(f)\n",
    "\n",
    "    brain_net_architecture = modify_arch(brain_net_architecture, list_factor_dim1=list_factor_dim1)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    n_classes_dict = {'f0_label':700}\n",
    "    batch_size = 128\n",
    "    input_tensor = tf.placeholder(tf.float32, shape=[batch_size, 100, 1000, 1], name='input_nervegrams')\n",
    "    output_tensor, nets = functions_brain_network.make_brain_net(input_tensor,\n",
    "                                                                 n_classes_dict,\n",
    "                                                                 brain_net_architecture,\n",
    "                                                                 trainable=True,\n",
    "                                                                 batchnorm_flag=True,\n",
    "                                                                 dropout_flag=True,\n",
    "                                                                 save_arch_path=None,\n",
    "                                                                 save_pckl_path=None,\n",
    "                                                                 only_include_layers=None)\n",
    "#     init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(init_op)\n",
    "#         tmp = np.random.randn(batch_size, 100, 1000, 1)\n",
    "#         tmp_out = sess.run(output_tensor, feed_dict={input_tensor: tmp})\n",
    "    \n",
    "#     print('--- CONV KERNELS ---')\n",
    "#     for x in brain_net_architecture:\n",
    "#         if x['layer_type'] == 'tf.layers.conv2d':\n",
    "#             print('conv', x['args']['kernel_size'])\n",
    "    print('--- TENSORS ---')\n",
    "    for key in ['flatten_end_conv']:#sorted(nets.keys()):\n",
    "        print(key, nets[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_arch_fn) as f:\n",
    "    brain_net_architecture = json.load(f)\n",
    "\n",
    "for x in brain_net_architecture:\n",
    "    if x['layer_type'] == 'tf.layers.conv2d':\n",
    "        print('conv', x['args']['kernel_size'])\n",
    "    elif x['layer_type'] == 'hpool':\n",
    "        print('pool', x['args']['strides'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_list = [\n",
    "    # Original (with valid padding)\n",
    "    [1, 1, 1, 1, 1],\n",
    "\n",
    "    # Perturbations to make filters shorter in freq and longer in time\n",
    "    [1, 0.3, 1, 1, 1],\n",
    "    [1, 0.35, 1, 1, 1],\n",
    "    [1, 0.4, 1, 1, 1],\n",
    "    [1, 0.45, 1, 1, 1],\n",
    "    [1, 0.5, 1, 1, 1],\n",
    "    [1, 0.55, 1, 1, 1],\n",
    "    [1, 0.6, 1, 1, 1],\n",
    "    [1, 0.65, 1, 1, 1],\n",
    "    [1, 0.7, 1, 1, 1],\n",
    "    [1, 0.75, 1, 1, 1],\n",
    "    [1, 0.8, 1, 1, 1],\n",
    "    [1, 0.85, 1, 1, 1],\n",
    "    [1, 0.9, 1, 1, 1],\n",
    "    [1, 0.95, 1, 1, 1],\n",
    "    [1, 1, 0.7, 1, 1],\n",
    "    [1, 1, 0.8, 1, 1],\n",
    "    [1, 1, 0.9, 1, 1],\n",
    "    [1, 1, 1, 0.7, 1],\n",
    "    [1, 1, 1, 0.8, 1],\n",
    "    [1, 1, 1, 1, 0.6],\n",
    "    [1, 1, 1, 1, 0.8],\n",
    "    \n",
    "    # Perturbations to make filters longer in freq and shorter in time\n",
    "    [1, 1.2, 1, 1, 1],\n",
    "    [1, 1.4, 1, 1, 1],\n",
    "    [1, 1.6, 1, 1, 1],\n",
    "    [1, 1.8, 1, 1, 1],\n",
    "    [1, 2.0, 1, 1, 1],\n",
    "    \n",
    "    [2, 1, 1, 1, 1],\n",
    "    [2, 2, 1, 1, 1],\n",
    "    [2, 2, 2, 1, 1],\n",
    "    [2, 2, 2, 2, 1],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    \n",
    "    [3, 1, 1, 1, 1],\n",
    "    [3, 3, 1, 1, 1],\n",
    "    [3, 3, 3, 1, 1],\n",
    "    [3, 3, 3, 3, 1],\n",
    "    [3, 3, 3, 3, 3],\n",
    "    \n",
    "    [4, 1, 1, 1, 1],\n",
    "    [4, 4, 1, 1, 1],\n",
    "    [4, 4, 4, 1, 1],\n",
    "    [4, 4, 4, 4, 1],\n",
    "    [4, 4, 4, 4, 4],\n",
    "    \n",
    "    [5, 1, 1, 1, 1],\n",
    "    [5, 5, 1, 1, 1],\n",
    "    [5, 5, 5, 1, 1],\n",
    "    [5, 5, 5, 5, 1],\n",
    "    [5, 5, 5, 5, 5],\n",
    "]\n",
    "\n",
    "\n",
    "# Baseline architecture\n",
    "brain_arch_fn = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/brain_arch_0302validtime.json'\n",
    "\n",
    "# Filename format for saving modified architectures and creating output directories\n",
    "new_arch_fn_format = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_0302_{:04d}/brain_arch.json'\n",
    "\n",
    "for arch_IDX, list_factor_dim1 in enumerate(manipulation_list):\n",
    "#     print('\\n###### {} ######\\n'.format(list_factor_dim1))\n",
    "    with open(brain_arch_fn) as f:\n",
    "        brain_net_architecture = json.load(f)\n",
    "\n",
    "    brain_net_architecture = modify_arch(brain_net_architecture, list_factor_dim1=list_factor_dim1, verbose=False)\n",
    "    new_arch_fn = new_arch_fn_format.format(arch_IDX)\n",
    "    \n",
    "    output_dir, basename = os.path.split(new_arch_fn)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "#     arch_generate_output_directory.save_network_architecture(brain_net_architecture, new_arch_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_arch_fn = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/brain_arch_0302validtime.json'\n",
    "brain_arch_fn_sorted = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/brain_arch_0302validtime_sortedkeys.json'\n",
    "\n",
    "with open(brain_arch_fn) as f:\n",
    "    brain_net_architecture = json.load(f)\n",
    "\n",
    "arch_generate_output_directory.save_network_architecture(brain_net_architecture, brain_arch_fn_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0000/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0000/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0001/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0001/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0002/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0002/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0003/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0003/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0004/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0004/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0005/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0005/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0006/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0006/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0007/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0007/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0008/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0008/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0009/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0009/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0010/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0010/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0011/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0011/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0012/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0012/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0013/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0013/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0014/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0014/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0015/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0015/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0016/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0016/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0017/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0017/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0018/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0018/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0019/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0019/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0020/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0020/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0021/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0021/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0022/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0022/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0023/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0023/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0024/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0024/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0025/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0025/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0026/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0026/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0027/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0027/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0028/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0028/config.json\n",
      "Pre-existing config file found: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0029/config.json\n",
      "config_dict similarity check is ignoring: []\n",
      "Successfully (over)wrote config file: /om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0029/config.json\n"
     ]
    }
   ],
   "source": [
    "# Quick script for copying config files to hand-designed directories\n",
    "# (Manually write config.json in first directory, then copy it to all other directories with simple change)\n",
    "import functions_parameter_handling\n",
    "\n",
    "config_fn = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_0000/config.json'\n",
    "new_config_fn = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations_v01/arch_0302_{:04d}/config.json'\n",
    "CONFIG = functions_parameter_handling.load_config_dict_from_json(config_fn)\n",
    "\n",
    "# for arch_idx in range(len(manipulation_list)):\n",
    "for arch_idx in range(30):\n",
    "    \n",
    "    CONFIG_STR = json.dumps(CONFIG)\n",
    "    NEW_CONFIG_STR = CONFIG_STR.replace('arch_0302_0000', 'arch_0302_{:04d}'.format(arch_idx))\n",
    "    NEW_CONFIG = json.loads(NEW_CONFIG_STR)\n",
    "    \n",
    "#     functions_parameter_handling.write_config_dict_to_json(NEW_CONFIG, new_config_fn.format(arch_idx),\n",
    "#                                                            force_overwrite=False, ignore_config_dict_keys=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
