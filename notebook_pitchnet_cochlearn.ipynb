{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/python-packages/msutil')\n",
    "import util_figures_cnn\n",
    "import util_stimuli\n",
    "import util_misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_brain_arch = '/saved_models/arch_search_v02_topN/f0_label_192/arch_0302/brain_arch.json'\n",
    "with open(fn_brain_arch, 'r') as f:\n",
    "    list_brain_arch = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:384: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:55: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:75: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:83: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 100, 1000, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "output_tensor, nets = functions_brain_network.make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_brain_net(\n",
    "#     input_tensor,\n",
    "#     n_classes_dict,\n",
    "#     list_brain_arch,\n",
    "#     trainable=True,\n",
    "#     batchnorm_flag=True,\n",
    "#     dropout_flag=True):\n",
    "#     '''\n",
    "#     '''\n",
    "#     list_brain_arch_partial = []\n",
    "#     dict_brain_arch_tensors = {}\n",
    "#     layer_input = input_tensor\n",
    "#     for layer_idx, layer in enumerate(list_brain_arch):\n",
    "#         msg = \"Brain architecture should not have multiple layers with the same name.\"\n",
    "#         assert (layer['args']['name'] not in dict_brain_arch_tensors.keys()), msg\n",
    "#         if layer['layer_type'] == 'tf.layers.conv2d':\n",
    "#             part = functools.partial(conv2d_valid_width_wrapper, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "#         elif layer['layer_type'] == 'tf.nn.relu':\n",
    "#             part = functools.partial(tf.nn.relu, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'tf.layers.batch_normalization':\n",
    "#             part = functools.partial(tf.layers.batch_normalization, **layer['args'], fused=False)\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, training=batchnorm_flag, trainable=trainable)\n",
    "#         elif layer['layer_type'] == 'tf.slice':\n",
    "#             part = functools.partial(tf.slice, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'tf.transpose':\n",
    "#             part = functools.partial(tf.transpose, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'tfnnresample':\n",
    "#             def tfnnresample_wrapper(tensor_input,\n",
    "#                                      sr_input,\n",
    "#                                      sr_output,\n",
    "#                                      kwargs_nnresample_poly_filter={},\n",
    "#                                      **kwargs):\n",
    "#                 \"\"\"Wrapper designed to ignore layer['args']['name']\"\"\"\n",
    "#                 return util_stimuli.tfnnresample(\n",
    "#                     tensor_input,\n",
    "#                     sr_input,\n",
    "#                     sr_output,\n",
    "#                     kwargs_nnresample_poly_filter=kwargs_nnresample_poly_filter)\n",
    "#             part = functools.partial(tfnnresample_wrapper, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'hpool':\n",
    "#             part = functools.partial(hanning_pooling, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'tf.layers.flatten':\n",
    "#             part = functools.partial(tf.layers.flatten, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "#         elif layer['layer_type'] == 'tf.layers.dense':\n",
    "#             part = functools.partial(tf.layers.dense, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "#         elif layer['layer_type'] == 'tf.layers.dropout':\n",
    "#             part = functools.partial(tf.layers.dropout, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, training=dropout_flag)\n",
    "#         elif layer['layer_type'] == 'fc_top_classification':\n",
    "#             part = functools.partial(fc_top_classification, n_classes_dict=n_classes_dict, **layer['args'])\n",
    "#             list_brain_arch_partial.append(part)\n",
    "#             dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "#         else:\n",
    "#             raise NotImplementedError(\"layer_type `{}` is not supported\".format(layer['layer_type']))\n",
    "#         # Update the input tensor for the next layer\n",
    "#         layer_input = dict_brain_arch_tensors[layer['args']['name']]\n",
    "#     output_tensor = layer_input\n",
    "#     return output_tensor, dict_brain_arch_tensors\n",
    "\n",
    "\n",
    "# def hanning_pooling(\n",
    "#     input_layer,\n",
    "#     strides=2,\n",
    "#     pool_size=8,\n",
    "#     padding='SAME',\n",
    "#     name=None,\n",
    "#     sqrt_window=False,\n",
    "#     normalize=False):\n",
    "#     \"\"\"\n",
    "#     Add a layer using a hanning kernel for pooling\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     input_layer : tensorflow tensor\n",
    "#         layer to add hanning pooling to\n",
    "#     strides : int\n",
    "#         proportion downsampling\n",
    "#     top_node : string\n",
    "#         specify the node after which the spectemp filters will be added and used as input for the FFT.\n",
    "#     sqrt_window : boolean\n",
    "#         if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "#     normalize : boolean\n",
    "#         if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "#     name : False or string\n",
    "#         name for the layer. If false appends \"_hpool\" to the top_node name\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     output_layer : tensorflow tensor\n",
    "#         input_layer with hanning pooling applied\n",
    "#     \"\"\"\n",
    "#     n_channels = input_layer.get_shape().as_list()[3]\n",
    "#     hanning_window_tensor = make_hanning_kernel_tensor_no_depthwise(n_channels, strides=strides, pool_size=pool_size, sqrt_window=sqrt_window, normalize=normalize, name='%s_hpool_kernel'%name)\n",
    "#     if type(strides)!=list and type(strides)==int:\n",
    "#         strides = [strides, strides] # using square filters\n",
    "#     output_layer = conv2d_for_hpool_valid_width_wrapper(input_layer, filters=hanning_window_tensor, strides=[1, strides[0], strides[1], 1], padding=padding, name=name)\n",
    "#     return output_layer\n",
    "\n",
    "\n",
    "# def make_hanning_kernel_tensor_no_depthwise(\n",
    "#     n_channels,\n",
    "#     strides=2,\n",
    "#     pool_size=8,\n",
    "#     sqrt_window=False,\n",
    "#     normalize=False,\n",
    "#     name=None):\n",
    "#     \"\"\"\n",
    "#     Make a tensor containing the symmetric 2d hanning kernel to use for the pooling filters\n",
    "#     For strides=2, using pool_size=8 gives a reduction of -24.131545969216841 at 0.25 cycles\n",
    "#     For strides=3, using pool_size=12 gives a reduction of -28.607805482176282 at 1/6 cycles\n",
    "\n",
    "#     This version uses the normal conv2d operation and fills most of the smoothing tensor with zeros. Depthwise convolution\n",
    "#     does not have a second order gradient, and cannot be used with some functions.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     n_channels : int\n",
    "#         number of channels to copy the kernel into\n",
    "#     strides : int\n",
    "#         proportion downsampling\n",
    "#     pool_size : int\n",
    "#         how large of a window to use\n",
    "#     sqrt_window : boolean\n",
    "#         if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "#     normalize : boolean\n",
    "#         if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "#     name : False or string\n",
    "#         name for the layer. If false appends \"_hpool\" to the top_node name\n",
    "\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     hanning_tensor : tensorflow tensor\n",
    "#         tensorflow tensor containing the hanning kernel with size [1 pool_size pool_size n_channels]\n",
    "\n",
    "#     \"\"\"\n",
    "#     hanning_kernel = make_hanning_kernel(strides=strides,pool_size=pool_size,sqrt_window=sqrt_window, normalize=normalize).astype(np.float32)\n",
    "#     hanning_kernel = np.expand_dims(np.expand_dims(hanning_kernel,0),0) * np.expand_dims(np.expand_dims(np.eye(n_channels),3),3) # [width, width, n_channels, n_channels]\n",
    "#     hanning_tensor = tf.constant(hanning_kernel, dtype=tf.float32, name=name)\n",
    "#     hanning_tensor = tf.transpose(hanning_tensor, [2,3,0,1])\n",
    "#     return hanning_tensor\n",
    "\n",
    "\n",
    "# def make_hanning_kernel(\n",
    "#     strides=2,\n",
    "#     pool_size=8,\n",
    "#     sqrt_window=False,\n",
    "#     normalize=False):\n",
    "#     \"\"\"\n",
    "#     Make the symmetric 2d hanning kernel to use for the pooling filters\n",
    "#     For strides=2, using pool_size=8 gives a reduction of -24.131545969216841 at 0.25 cycles\n",
    "#     For strides=3, using pool_size=12 gives a reduction of -28.607805482176282 at 1/6 cycles\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     strides : int\n",
    "#         proportion downsampling\n",
    "#     pool_size : int\n",
    "#         how large of a window to use\n",
    "#     sqrt_window : boolean\n",
    "#         if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "#     normalize : boolean\n",
    "#         if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     two_dimensional_kernel : numpy array\n",
    "#         hanning kernel in 2d to use as a kernel for filtering\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     if type(strides)!=list and type(strides)==int:\n",
    "#         strides = [strides, strides] # using square filters\n",
    " \n",
    "#     if type(pool_size)!=list and type(pool_size)==int: \n",
    "#         if pool_size > 1:\n",
    "#             window = 0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size)) / (pool_size - 1)))\n",
    "#             if sqrt_window: \n",
    "#                 two_dimensional_kernel = np.sqrt(np.outer(window, window))\n",
    "#             else: \n",
    "#                 two_dimensional_kernel = np.outer(window, window)\n",
    "#         else: \n",
    "#             window = np.ones((1,1))\n",
    "#             two_dimensional_kernel = window # [1x1 kernel]\n",
    "#     elif type(pool_size)==list:\n",
    "#         if pool_size[0] > 1:\n",
    "#             window_h = np.expand_dims(0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size[0])) / (pool_size[0] - 1))),0)\n",
    "#         else:\n",
    "#             window_h = np.ones((1,1))\n",
    "#         if pool_size[1] > 1:\n",
    "#             window_w = np.expand_dims(0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size[1])) / (pool_size[1] - 1))),1)\n",
    "#         else:\n",
    "#             window_w = np.ones((1,1))\n",
    " \n",
    "#         if sqrt_window:\n",
    "#             two_dimensional_kernel = np.sqrt(np.outer(window_h, window_w))\n",
    "#         else:  \n",
    "#             two_dimensional_kernel = np.outer(window_h, window_w)\n",
    "\n",
    "#     if normalize:\n",
    "#         two_dimensional_kernel = two_dimensional_kernel/(sum(two_dimensional_kernel.ravel()))        \n",
    "    \n",
    "#     return two_dimensional_kernel\n",
    "\n",
    "\n",
    "# def conv2d_valid_width_wrapper(inputs,kernel_size,strides,padding,**kwargs):\n",
    "#     \"\"\"\n",
    "#     Wraps tf.layers.conv2d to allow valid convolution across signal width and\n",
    "#     'same' convolution across signal height when padding is set to \"valid_time\"\n",
    "    \n",
    "#   Arguments:\n",
    "#     inputs (TF Tensor): Tensor input.\n",
    "#     kernel_size (int or tuple/list): An integer or tuple/list of 2 integers, specifying the\n",
    "#       height and width of the 2D convolution window.\n",
    "#       Can be a single integer to specify the same value for\n",
    "#       all spatial dimensions.\n",
    "#     strides (int or tuple/list) : An integer or tuple/list of 2 integers,\n",
    "#       specifying the strides of the convolution along the height and width.\n",
    "#       Can be a single integer to specify the same value for\n",
    "#       all spatial dimensions.\n",
    "#       Specifying any stride value != 1 is incompatible with specifying\n",
    "#       any `dilation_rate` value != 1.\n",
    "#     padding (string): One of `\"valid\"`, `\"same\"`, or `\"valid_time\"` (case-insensitive).\n",
    "#     kwargs (dictionary): Specifies all other arguments required by\n",
    "#     tf.layers.conv2d. Passes these directly to function without modification.\n",
    "#         See Tensorflow documentation for further details.\n",
    "\n",
    "#   Returns:\n",
    "#       (TF Tensor): Output of tf.layers.conv2d.\n",
    "#     \"\"\"\n",
    "\n",
    "#     #Collects relvant parameters    \n",
    "#     size=inputs.get_shape()\n",
    "#     filter_height = kernel_size[0]\n",
    "#     in_height = size[1]\n",
    "\n",
    "#     #Calculates according to SAME padding formula\n",
    "#     if (in_height % strides[0] == 0):\n",
    "#         pad_along_height = max(filter_height - strides[0], 0)\n",
    "#     else:\n",
    "#         pad_along_height = max(filter_height - (in_height % strides[0]), 0)\n",
    "#     pad_top = pad_along_height // 2\n",
    "#     pad_bottom = pad_along_height - pad_top\n",
    "\n",
    "#     #Pads signal if VALID_TIME is selected and padding is necessary\n",
    "#     #Otherwise, pass inputs through and allow specified convolutioon\n",
    "#     if pad_along_height == 0 or padding.upper() != 'VALID_TIME':\n",
    "#         padding = 'VALID' if padding.upper() == 'VALID_TIME' else padding\n",
    "#         output_tensor = tf.layers.conv2d(inputs,kernel_size=kernel_size,\n",
    "#                                          strides=strides,padding=padding,\n",
    "#                                          **kwargs)\n",
    "#     else:\n",
    "#         #Pads input tensor and moves conv2d to valid padding\n",
    "#         paddings = tf.constant([[0,0],[pad_top, pad_bottom], [0, 0],[0,0]])\n",
    "#         input_padded = tf.pad(inputs,paddings)\n",
    "#         output_tensor=tf.layers.conv2d(input_padded,kernel_size=kernel_size,\n",
    "#                                        strides=strides, padding=\"VALID\",\n",
    "#                                        **kwargs)\n",
    "#     return output_tensor\n",
    "\n",
    "\n",
    "# def conv2d_for_hpool_valid_width_wrapper(inputs,filters,strides,padding,**kwargs):\n",
    "#     \"\"\"\n",
    "#     Wraps tf.layers.conv2d to allow valid convolution across signal width and\n",
    "#     'same' convolution across signal height when padding is set to \"valid_time\"\n",
    "    \n",
    "#   Arguments:\n",
    "#     inputs (TF Tensor): Tensor input.\n",
    "#     filters (TF Tensor):  Must have the same type as input.\n",
    "#       A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "#     strides (int or tuple/list) : An integer or tuple/list of 2 integers,\n",
    "#       specifying the strides of the convolution along the height and width.\n",
    "#       Can be a single integer to specify the same value for\n",
    "#       all spatial dimensions.\n",
    "#       Specifying any stride value != 1 is incompatible with specifying\n",
    "#       any `dilation_rate` value != 1.\n",
    "#     padding (string): One of `\"valid\"`, `\"same\"`, or `\"valid_time\"` (case-insensitive).\n",
    "#     kwargs (dictionary): Specifies all other arguments required by\n",
    "#     tf.layers.conv2d. Passes these directly to function without modification.\n",
    "#         See Tensorflow documentation for further details.\n",
    "\n",
    "#   Returns:\n",
    "#       (TF Tensor): Output of tf.layers.conv2d.\n",
    "#     \"\"\"\n",
    "\n",
    "#     #Collects relvant parameters    \n",
    "#     size=inputs.get_shape()\n",
    "#     kernel_size = filters.get_shape()\n",
    "#     filter_height = int(kernel_size[0])\n",
    "#     in_height = int(size[1])\n",
    "\n",
    "#     #Calculates according to SAME padding formula\n",
    "#     if (in_height % strides[0] == 0):\n",
    "#         pad_along_height = max(filter_height - strides[0], 0)\n",
    "#     else:\n",
    "#         pad_along_height = max(filter_height - (in_height % strides[0]), 0)\n",
    "#     pad_top = pad_along_height // 2\n",
    "#     pad_bottom = pad_along_height - pad_top\n",
    "\n",
    "#     #Pads signal if VALID_TIME is selected and padding is necessary\n",
    "#     #Otherwise, pass inputs through and allow specified convolutioon\n",
    "#     if pad_along_height == 0 or padding.upper() != 'VALID_TIME':\n",
    "#         padding = 'VALID' if padding.upper() == 'VALID_TIME' else padding\n",
    "#         output_tensor = tf.nn.conv2d(inputs,filter=filters,\n",
    "#                                          strides=strides,padding=padding,\n",
    "#                                          **kwargs)\n",
    "#     else:\n",
    "#         #Pads input tensor and moves conv2d to valid padding\n",
    "#         paddings = tf.constant([[0,0],[pad_top, pad_bottom], [0, 0],[0,0]])\n",
    "#         input_padded = tf.pad(inputs,paddings)\n",
    "#         output_tensor=tf.nn.conv2d(input_padded,filter=filters,\n",
    "#                                        strides=strides, padding=\"VALID\",\n",
    "#                                        **kwargs)\n",
    "#     return output_tensor\n",
    "\n",
    "\n",
    "# def fc_top_classification(input_tensor, n_classes_dict, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Builds an fc layer at the top of the network for classification, parses n_classes_dict.\n",
    "\n",
    "#     Args\n",
    "#     ----\n",
    "#     input_tensor (tensorflow tensor) : the input layer for each of the added fc layers\n",
    "#     n_classes_dict (dict) : contains the number of classes (number of FC units) for each of the tasks\n",
    "#     kwargs : keyword arguments to pass into tf.layers.dense\n",
    "\n",
    "#     Outputs\n",
    "#     -------\n",
    "#     output_tensor (tensorflow tensor) : an fc layer with the number of classes\n",
    " \n",
    "#     \"\"\"\n",
    "\n",
    "#     assert len(list(n_classes_dict.keys())) == 1, \"Multiple tasks specified but only one FC layer can be constructed with 'fc_top_classification', please check network configuration.\"\n",
    "#     (task_name, task_classes), = n_classes_dict.items()\n",
    "#     output_tensor = tf.layers.dense(input_tensor, units=task_classes, **kwargs)\n",
    "#     return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tfnnresample] interpreting `tensor_input.shape` as [batch, freq, time, channels]\n",
      "[tfnnresample] using up=1 rather than up=5 for nnresample_poly_filter\n",
      "[tfnnresample] using down=4 rather than down=8 for nnresample_poly_filter\n",
      "[tfnnresample] using window_length=8000 for nnresample_poly_filter\n",
      "[tfnnresample] using cutoff frequency near 4000.0 Hz for anti-aliasing lowpass filter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'coch_relu_1:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       " {'coch_conv_0': <tf.Tensor 'coch_conv_0/BiasAdd:0' shape=(1, 1, 1600, 100) dtype=float32>,\n",
       "  'coch_relu_0': <tf.Tensor 'coch_relu_0:0' shape=(1, 100, 1600, 1) dtype=float32>,\n",
       "  'coch_relu_1': <tf.Tensor 'coch_relu_1:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_slice_0': <tf.Tensor 'coch_slice_0:0' shape=(1, 1, 2400, 1) dtype=float32>,\n",
       "  'coch_tfnnresample_0': <tf.Tensor 'Conv2D:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_transpose_0': <tf.Tensor 'coch_transpose_0:0' shape=(1, 100, 1600, 1) dtype=float32>})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 1, 4800, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "\n",
    "list_brain_arch_tmp = [\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_slice_0',\n",
    "            'begin': [0, 0, 2160, 0],\n",
    "            'size': [-1, -1, 2400, -1],\n",
    "        },\n",
    "        'layer_type': 'tf.slice'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'activation': None,\n",
    "            'dilation_rate': [1, 1],\n",
    "            'filters': 100,\n",
    "            'kernel_size': [1, 801],\n",
    "            'name': 'coch_conv_0',\n",
    "            'padding': 'VALID',\n",
    "            'strides': [1, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.layers.conv2d'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_transpose_0',\n",
    "            'perm': [0, 3, 2, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.transpose'\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_0\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_tfnnresample_0\",\n",
    "            \"sr_input\": 32e3,\n",
    "            \"sr_output\": 20e3,\n",
    "            \"kwargs_nnresample_poly_filter\": {\n",
    "                \"down\": 4,\n",
    "                \"up\": 1\n",
    "            },\n",
    "        },\n",
    "        \"layer_type\": \"tfnnresample\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_1\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# list_brain_arch_tmp = list_brain_arch_tmp + list_brain_arch\n",
    "\n",
    "import importlib\n",
    "importlib.reload(functions_brain_network)\n",
    "\n",
    "output_tensor, nets = functions_brain_network.make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch_tmp)\n",
    "\n",
    "output_tensor, nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(?, 1, 4800, 1) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [None, 4800]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "\n",
    "input_tensor = input_tensor[:, tf.newaxis, :, tf.newaxis]\n",
    "input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4471 80.4471\n",
      "0.07\n",
      "2240 -320\n",
      "50.397247\n"
     ]
    }
   ],
   "source": [
    "regex_fn = '/om/scratch/Thu/msaddler/data_pitchnet/PND_v08/noise_TLAS_snr_neg10pos10/PND_*.hdf5'\n",
    "list_fn = glob.glob(regex_fn)\n",
    "fn = list_fn[0]\n",
    "\n",
    "# for k in util_misc.get_hdf5_dataset_key_list(fn):\n",
    "#     print(k)\n",
    "\n",
    "with h5py.File(fn, 'r') as f:\n",
    "    IDX = -50\n",
    "    idx0 = f['nopad_start_index'][IDX] - f['segment_start_index'][IDX]\n",
    "    idx1 = f['nopad_end_index'][IDX] - f['segment_end_index'][IDX]\n",
    "    \n",
    "    print(f['f0'][IDX], f['nopad_f0_mean'][IDX])\n",
    "    print(f['stimuli/signal_in_noise'][IDX, idx0:idx1].shape[0] / f['sr'][0])\n",
    "    print(idx0, idx1)\n",
    "    \n",
    "    print(f['stimuli/signal_in_noise_dBSPL'][IDX])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### /om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (72600, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (83391, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (83304, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (24576, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (36864, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (73728, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (134328, 4800), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "list_fn =[\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim.hdf5',\n",
    "]\n",
    "for fn in list_fn:\n",
    "    list_k = util_misc.get_hdf5_dataset_key_list(fn)\n",
    "    fn_new = fn.replace('.hdf5', '_waveform.hdf5')\n",
    "    with h5py.File(fn, 'r') as f:\n",
    "        print('###', fn)\n",
    "        print('###', fn_new)\n",
    "        list_candidate_signal_k = [k for k in list_k if f[k].shape[-1] == 4800]\n",
    "        list_other_k = [k for k in list_k if not f[k].shape[-1] == 4800]\n",
    "        if len(list_candidate_signal_k) > 1:\n",
    "            list_candidate_signal_k = [k for k in list_candidate_signal_k if 'noise' in k]\n",
    "        assert len(list_candidate_signal_k) == 1\n",
    "        \n",
    "        assert not fn_new == fn\n",
    "#         with h5py.File(fn_new, 'w') as f_new:\n",
    "#             for k in list_other_k:\n",
    "#                 f_new.create_dataset(k, data=f[k][:])\n",
    "#             f_new.create_dataset('stimuli/signal_in_noise', data=f[list_candidate_signal_k[0]][:])\n",
    "#             print(f_new['stimuli/signal_in_noise'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append('/code_location/multi_gpu')\n",
    "import functions_parameter_handling\n",
    "importlib.reload(functions_parameter_handling)\n",
    "\n",
    "list_brain_arch_prepend = [\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_slice_0',\n",
    "            'begin': [0, 0, 2160, 0],\n",
    "            'size': [-1, -1, 2400, -1],\n",
    "        },\n",
    "        'layer_type': 'tf.slice'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'activation': None,\n",
    "            'dilation_rate': [1, 1],\n",
    "            'filters': 100,\n",
    "            'kernel_size': [1, 801],\n",
    "            'name': 'coch_conv_0',\n",
    "            'padding': 'VALID',\n",
    "            'strides': [1, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.layers.conv2d'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_transpose_0',\n",
    "            'perm': [0, 3, 2, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.transpose'\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_0\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_tfnnresample_0\",\n",
    "            \"sr_input\": 32e3,\n",
    "            \"sr_output\": 20e3,\n",
    "            \"kwargs_nnresample_poly_filter\": {\n",
    "                \"down\": 8,\n",
    "                \"up\": 5,\n",
    "                \"window_length\": 161\n",
    "            },\n",
    "        },\n",
    "        \"layer_type\": \"tfnnresample\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_1\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "regex_src_dir = '/saved_models/arch_search_v02_topN/TEMPLATE/arch_0???'\n",
    "list_src_dir = glob.glob(regex_src_dir)\n",
    "\n",
    "for src_dir in list_src_dir:\n",
    "    dst_dir = src_dir.replace('TEMPLATE', 'cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10')\n",
    "    fn_src_config = os.path.join(src_dir, 'config.json')\n",
    "    fn_src_arch = os.path.join(src_dir, 'brain_arch.json')\n",
    "    fn_dst_config = os.path.join(dst_dir, 'config.json')\n",
    "    fn_dst_arch = os.path.join(dst_dir, 'brain_arch.json')\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.mkdir(dst_dir)\n",
    "    \n",
    "    with open(fn_src_config, 'r') as f:\n",
    "        CONFIG = json.load(f)\n",
    "    \n",
    "    CONFIG['signal_rate'] = 32e3\n",
    "    CONFIG['BRAIN_PARAMS'].pop('save_pckl_path')\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_parsing_dict'].pop('nervegram_meanrates')\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_parsing_dict']['stimuli/signal_in_noise'] = {\n",
    "        \"dtype\": \"tf.float32\",\n",
    "        \"shape\": [4800]\n",
    "    }\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_signal_path'] = 'stimuli/signal_in_noise'\n",
    "    with open(fn_dst_config, 'w') as f:\n",
    "        json.dump(CONFIG, f, indent=4, sort_keys=True)\n",
    "    \n",
    "    functions_parameter_handling.migrate_config_to_new_output_directory(\n",
    "        fn_dst_config,\n",
    "        dst_dir,\n",
    "        force_overwrite=True)\n",
    "    \n",
    "    with open(fn_src_arch, 'r') as f:\n",
    "        BRAIN_ARCH = json.load(f)\n",
    "    \n",
    "    BRAIN_ARCH = list_brain_arch_prepend + BRAIN_ARCH\n",
    "    with open(fn_dst_arch, 'w') as f:\n",
    "        json.dump(BRAIN_ARCH, f, indent=4, sort_keys=True)\n",
    "\n",
    "# print(json.dumps(CONFIG, indent=4, sort_keys=True))\n",
    "# print(json.dumps(BRAIN_ARCH, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
