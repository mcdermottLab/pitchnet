{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/ibm_hearing_aid/ibmHearingAid/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/python-packages/msutil')\n",
    "import util_figures_cnn\n",
    "import util_stimuli\n",
    "import util_misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_brain_arch = '/saved_models/arch_search_v02_topN/f0_label_192/arch_0302/brain_arch.json'\n",
    "with open(fn_brain_arch, 'r') as f:\n",
    "    list_brain_arch = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:133: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 100, 1000, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "output_tensor, nets = make_brain_net(#functions_brain_network.make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_brain_net(\n",
    "    input_tensor,\n",
    "    n_classes_dict,\n",
    "    list_brain_arch,\n",
    "    trainable=True,\n",
    "    batchnorm_flag=True,\n",
    "    dropout_flag=True):\n",
    "    '''\n",
    "    '''\n",
    "    list_brain_arch_partial = []\n",
    "    dict_brain_arch_tensors = {}\n",
    "    layer_input = input_tensor\n",
    "    for layer_idx, layer in enumerate(list_brain_arch):\n",
    "        msg = \"Brain architecture should not have multiple layers with the same name.\"\n",
    "        assert (layer['args']['name'] not in dict_brain_arch_tensors.keys()), msg\n",
    "        if layer['layer_type'] == 'tf.layers.conv2d':\n",
    "            part = functools.partial(conv2d_valid_width_wrapper, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "        elif layer['layer_type'] == 'tf.nn.relu':\n",
    "            part = functools.partial(tf.nn.relu, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'tf.layers.batch_normalization':\n",
    "            part = functools.partial(tf.layers.batch_normalization, **layer['args'], fused=False)\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, training=batchnorm_flag, trainable=trainable)\n",
    "        elif layer['layer_type'] == 'tf.slice':\n",
    "            part = functools.partial(tf.slice, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'tf.transpose':\n",
    "            part = functools.partial(tf.transpose, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'tfnnresample':\n",
    "            def tfnnresample_wrapper(tensor_input,\n",
    "                                     sr_input,\n",
    "                                     sr_output,\n",
    "                                     kwargs_nnresample_poly_filter={},\n",
    "                                     **kwargs):\n",
    "                \"\"\"Wrapper designed to ignore layer['args']['name']\"\"\"\n",
    "                return util_stimuli.tfnnresample(\n",
    "                    tensor_input,\n",
    "                    sr_input,\n",
    "                    sr_output,\n",
    "                    kwargs_nnresample_poly_filter=kwargs_nnresample_poly_filter)\n",
    "            part = functools.partial(tfnnresample_wrapper, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'hpool':\n",
    "            part = functools.partial(hanning_pooling, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'tf.layers.flatten':\n",
    "            part = functools.partial(tf.layers.flatten, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input)\n",
    "        elif layer['layer_type'] == 'tf.layers.dense':\n",
    "            part = functools.partial(tf.layers.dense, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "        elif layer['layer_type'] == 'tf.layers.dropout':\n",
    "            part = functools.partial(tf.layers.dropout, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, training=dropout_flag)\n",
    "        elif layer['layer_type'] == 'fc_top_classification':\n",
    "            part = functools.partial(fc_top_classification, n_classes_dict=n_classes_dict, **layer['args'])\n",
    "            list_brain_arch_partial.append(part)\n",
    "            dict_brain_arch_tensors[layer['args']['name']] = part(layer_input, trainable=trainable)\n",
    "        else:\n",
    "            raise NotImplementedError(\"layer_type `{}` is not supported\".format(layer['layer_type']))\n",
    "        # Update the input tensor for the next layer\n",
    "        layer_input = dict_brain_arch_tensors[layer['args']['name']]\n",
    "    output_tensor = layer_input\n",
    "    return output_tensor, dict_brain_arch_tensors\n",
    "\n",
    "\n",
    "def hanning_pooling(\n",
    "    input_layer,\n",
    "    strides=2,\n",
    "    pool_size=8,\n",
    "    padding='SAME',\n",
    "    name=None,\n",
    "    sqrt_window=False,\n",
    "    normalize=False):\n",
    "    \"\"\"\n",
    "    Add a layer using a hanning kernel for pooling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_layer : tensorflow tensor\n",
    "        layer to add hanning pooling to\n",
    "    strides : int\n",
    "        proportion downsampling\n",
    "    top_node : string\n",
    "        specify the node after which the spectemp filters will be added and used as input for the FFT.\n",
    "    sqrt_window : boolean\n",
    "        if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "    normalize : boolean\n",
    "        if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "    name : False or string\n",
    "        name for the layer. If false appends \"_hpool\" to the top_node name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_layer : tensorflow tensor\n",
    "        input_layer with hanning pooling applied\n",
    "    \"\"\"\n",
    "    n_channels = input_layer.get_shape().as_list()[3]\n",
    "    hanning_window_tensor = make_hanning_kernel_tensor_no_depthwise(n_channels, strides=strides, pool_size=pool_size, sqrt_window=sqrt_window, normalize=normalize, name='%s_hpool_kernel'%name)\n",
    "    if type(strides)!=list and type(strides)==int:\n",
    "        strides = [strides, strides] # using square filters\n",
    "    output_layer = conv2d_for_hpool_valid_width_wrapper(input_layer, filters=hanning_window_tensor, strides=[1, strides[0], strides[1], 1], padding=padding, name=name)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "def make_hanning_kernel_tensor_no_depthwise(\n",
    "    n_channels,\n",
    "    strides=2,\n",
    "    pool_size=8,\n",
    "    sqrt_window=False,\n",
    "    normalize=False,\n",
    "    name=None):\n",
    "    \"\"\"\n",
    "    Make a tensor containing the symmetric 2d hanning kernel to use for the pooling filters\n",
    "    For strides=2, using pool_size=8 gives a reduction of -24.131545969216841 at 0.25 cycles\n",
    "    For strides=3, using pool_size=12 gives a reduction of -28.607805482176282 at 1/6 cycles\n",
    "\n",
    "    This version uses the normal conv2d operation and fills most of the smoothing tensor with zeros. Depthwise convolution\n",
    "    does not have a second order gradient, and cannot be used with some functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_channels : int\n",
    "        number of channels to copy the kernel into\n",
    "    strides : int\n",
    "        proportion downsampling\n",
    "    pool_size : int\n",
    "        how large of a window to use\n",
    "    sqrt_window : boolean\n",
    "        if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "    normalize : boolean\n",
    "        if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "    name : False or string\n",
    "        name for the layer. If false appends \"_hpool\" to the top_node name\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hanning_tensor : tensorflow tensor\n",
    "        tensorflow tensor containing the hanning kernel with size [1 pool_size pool_size n_channels]\n",
    "\n",
    "    \"\"\"\n",
    "    hanning_kernel = make_hanning_kernel(strides=strides,pool_size=pool_size,sqrt_window=sqrt_window, normalize=normalize).astype(np.float32)\n",
    "    hanning_kernel = np.expand_dims(np.expand_dims(hanning_kernel,0),0) * np.expand_dims(np.expand_dims(np.eye(n_channels),3),3) # [width, width, n_channels, n_channels]\n",
    "    hanning_tensor = tf.constant(hanning_kernel, dtype=tf.float32, name=name)\n",
    "    hanning_tensor = tf.transpose(hanning_tensor, [2,3,0,1])\n",
    "    return hanning_tensor\n",
    "\n",
    "\n",
    "def make_hanning_kernel(\n",
    "    strides=2,\n",
    "    pool_size=8,\n",
    "    sqrt_window=False,\n",
    "    normalize=False):\n",
    "    \"\"\"\n",
    "    Make the symmetric 2d hanning kernel to use for the pooling filters\n",
    "    For strides=2, using pool_size=8 gives a reduction of -24.131545969216841 at 0.25 cycles\n",
    "    For strides=3, using pool_size=12 gives a reduction of -28.607805482176282 at 1/6 cycles\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strides : int\n",
    "        proportion downsampling\n",
    "    pool_size : int\n",
    "        how large of a window to use\n",
    "    sqrt_window : boolean\n",
    "        if true, takes the sqrt of the window (old version), normal window generation has sqrt_window=False\n",
    "    normalize : boolean\n",
    "        if true, divide the filter by the sum of its values, so that the smoothed signal is the same amplitude as the original.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    two_dimensional_kernel : numpy array\n",
    "        hanning kernel in 2d to use as a kernel for filtering\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if type(strides)!=list and type(strides)==int:\n",
    "        strides = [strides, strides] # using square filters\n",
    " \n",
    "    if type(pool_size)!=list and type(pool_size)==int: \n",
    "        if pool_size > 1:\n",
    "            window = 0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size)) / (pool_size - 1)))\n",
    "            if sqrt_window: \n",
    "                two_dimensional_kernel = np.sqrt(np.outer(window, window))\n",
    "            else: \n",
    "                two_dimensional_kernel = np.outer(window, window)\n",
    "        else: \n",
    "            window = np.ones((1,1))\n",
    "            two_dimensional_kernel = window # [1x1 kernel]\n",
    "    elif type(pool_size)==list:\n",
    "        if pool_size[0] > 1:\n",
    "            window_h = np.expand_dims(0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size[0])) / (pool_size[0] - 1))),0)\n",
    "        else:\n",
    "            window_h = np.ones((1,1))\n",
    "        if pool_size[1] > 1:\n",
    "            window_w = np.expand_dims(0.5 * (1 - np.cos(2.0 * np.pi * (np.arange(pool_size[1])) / (pool_size[1] - 1))),1)\n",
    "        else:\n",
    "            window_w = np.ones((1,1))\n",
    " \n",
    "        if sqrt_window:\n",
    "            two_dimensional_kernel = np.sqrt(np.outer(window_h, window_w))\n",
    "        else:  \n",
    "            two_dimensional_kernel = np.outer(window_h, window_w)\n",
    "\n",
    "    if normalize:\n",
    "        two_dimensional_kernel = two_dimensional_kernel/(sum(two_dimensional_kernel.ravel()))        \n",
    "    \n",
    "    return two_dimensional_kernel\n",
    "\n",
    "\n",
    "def conv2d_valid_width_wrapper(inputs,kernel_size,strides,padding,**kwargs):\n",
    "    \"\"\"\n",
    "    Wraps tf.layers.conv2d to allow valid convolution across signal width and\n",
    "    'same' convolution across signal height when padding is set to \"valid_time\"\n",
    "    \n",
    "  Arguments:\n",
    "    inputs (TF Tensor): Tensor input.\n",
    "    kernel_size (int or tuple/list): An integer or tuple/list of 2 integers, specifying the\n",
    "      height and width of the 2D convolution window.\n",
    "      Can be a single integer to specify the same value for\n",
    "      all spatial dimensions.\n",
    "    strides (int or tuple/list) : An integer or tuple/list of 2 integers,\n",
    "      specifying the strides of the convolution along the height and width.\n",
    "      Can be a single integer to specify the same value for\n",
    "      all spatial dimensions.\n",
    "      Specifying any stride value != 1 is incompatible with specifying\n",
    "      any `dilation_rate` value != 1.\n",
    "    padding (string): One of `\"valid\"`, `\"same\"`, or `\"valid_time\"` (case-insensitive).\n",
    "    kwargs (dictionary): Specifies all other arguments required by\n",
    "    tf.layers.conv2d. Passes these directly to function without modification.\n",
    "        See Tensorflow documentation for further details.\n",
    "\n",
    "  Returns:\n",
    "      (TF Tensor): Output of tf.layers.conv2d.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collects relvant parameters    \n",
    "    size=inputs.get_shape()\n",
    "    filter_height = kernel_size[0]\n",
    "    in_height = size[1]\n",
    "\n",
    "    #Calculates according to SAME padding formula\n",
    "    if (in_height % strides[0] == 0):\n",
    "        pad_along_height = max(filter_height - strides[0], 0)\n",
    "    else:\n",
    "        pad_along_height = max(filter_height - (in_height % strides[0]), 0)\n",
    "    pad_top = pad_along_height // 2\n",
    "    pad_bottom = pad_along_height - pad_top\n",
    "\n",
    "    #Pads signal if VALID_TIME is selected and padding is necessary\n",
    "    #Otherwise, pass inputs through and allow specified convolutioon\n",
    "    if pad_along_height == 0 or padding.upper() != 'VALID_TIME':\n",
    "        padding = 'VALID' if padding.upper() == 'VALID_TIME' else padding\n",
    "        output_tensor = tf.layers.conv2d(inputs,kernel_size=kernel_size,\n",
    "                                         strides=strides,padding=padding,\n",
    "                                         **kwargs)\n",
    "    else:\n",
    "        #Pads input tensor and moves conv2d to valid padding\n",
    "        paddings = tf.constant([[0,0],[pad_top, pad_bottom], [0, 0],[0,0]])\n",
    "        input_padded = tf.pad(inputs,paddings)\n",
    "        output_tensor=tf.layers.conv2d(input_padded,kernel_size=kernel_size,\n",
    "                                       strides=strides, padding=\"VALID\",\n",
    "                                       **kwargs)\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def conv2d_for_hpool_valid_width_wrapper(inputs,filters,strides,padding,**kwargs):\n",
    "    \"\"\"\n",
    "    Wraps tf.layers.conv2d to allow valid convolution across signal width and\n",
    "    'same' convolution across signal height when padding is set to \"valid_time\"\n",
    "    \n",
    "  Arguments:\n",
    "    inputs (TF Tensor): Tensor input.\n",
    "    filters (TF Tensor):  Must have the same type as input.\n",
    "      A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    strides (int or tuple/list) : An integer or tuple/list of 2 integers,\n",
    "      specifying the strides of the convolution along the height and width.\n",
    "      Can be a single integer to specify the same value for\n",
    "      all spatial dimensions.\n",
    "      Specifying any stride value != 1 is incompatible with specifying\n",
    "      any `dilation_rate` value != 1.\n",
    "    padding (string): One of `\"valid\"`, `\"same\"`, or `\"valid_time\"` (case-insensitive).\n",
    "    kwargs (dictionary): Specifies all other arguments required by\n",
    "    tf.layers.conv2d. Passes these directly to function without modification.\n",
    "        See Tensorflow documentation for further details.\n",
    "\n",
    "  Returns:\n",
    "      (TF Tensor): Output of tf.layers.conv2d.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collects relvant parameters    \n",
    "    size=inputs.get_shape()\n",
    "    kernel_size = filters.get_shape()\n",
    "    filter_height = int(kernel_size[0])\n",
    "    in_height = int(size[1])\n",
    "\n",
    "    #Calculates according to SAME padding formula\n",
    "    if (in_height % strides[0] == 0):\n",
    "        pad_along_height = max(filter_height - strides[0], 0)\n",
    "    else:\n",
    "        pad_along_height = max(filter_height - (in_height % strides[0]), 0)\n",
    "    pad_top = pad_along_height // 2\n",
    "    pad_bottom = pad_along_height - pad_top\n",
    "\n",
    "    #Pads signal if VALID_TIME is selected and padding is necessary\n",
    "    #Otherwise, pass inputs through and allow specified convolutioon\n",
    "    if pad_along_height == 0 or padding.upper() != 'VALID_TIME':\n",
    "        padding = 'VALID' if padding.upper() == 'VALID_TIME' else padding\n",
    "        output_tensor = tf.nn.conv2d(inputs,filter=filters,\n",
    "                                         strides=strides,padding=padding,\n",
    "                                         **kwargs)\n",
    "    else:\n",
    "        #Pads input tensor and moves conv2d to valid padding\n",
    "        paddings = tf.constant([[0,0],[pad_top, pad_bottom], [0, 0],[0,0]])\n",
    "        input_padded = tf.pad(inputs,paddings)\n",
    "        output_tensor=tf.nn.conv2d(input_padded,filter=filters,\n",
    "                                       strides=strides, padding=\"VALID\",\n",
    "                                       **kwargs)\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def fc_top_classification(input_tensor, n_classes_dict, **kwargs):\n",
    "    \"\"\"\n",
    "    Builds an fc layer at the top of the network for classification, parses n_classes_dict.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    input_tensor (tensorflow tensor) : the input layer for each of the added fc layers\n",
    "    n_classes_dict (dict) : contains the number of classes (number of FC units) for each of the tasks\n",
    "    kwargs : keyword arguments to pass into tf.layers.dense\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    output_tensor (tensorflow tensor) : an fc layer with the number of classes\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    assert len(list(n_classes_dict.keys())) == 1, \"Multiple tasks specified but only one FC layer can be constructed with 'fc_top_classification', please check network configuration.\"\n",
    "    (task_name, task_classes), = n_classes_dict.items()\n",
    "    output_tensor = tf.layers.dense(input_tensor, units=task_classes, **kwargs)\n",
    "    return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tfnnresample] interpreting `tensor_input.shape` as [batch, freq, time, channels]\n",
      "[tfnnresample] using up=1 rather than up=5 for nnresample_poly_filter\n",
      "[tfnnresample] using down=4 rather than down=8 for nnresample_poly_filter\n",
      "[tfnnresample] using window_length=8000 for nnresample_poly_filter\n",
      "[tfnnresample] using cutoff frequency near 4000.0 Hz for anti-aliasing lowpass filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:155: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'fc_top/BiasAdd:0' shape=(1, 700) dtype=float32>,\n",
       " {'batch_norm_0': <tf.Tensor 'batch_norm_0/batchnorm/add_1:0' shape=(1, 100, 151, 32) dtype=float32>,\n",
       "  'batch_norm_1': <tf.Tensor 'batch_norm_1/batchnorm/add_1:0' shape=(1, 82, 21, 64) dtype=float32>,\n",
       "  'batch_norm_2': <tf.Tensor 'batch_norm_2/batchnorm/add_1:0' shape=(1, 24, 13, 128) dtype=float32>,\n",
       "  'batch_norm_3': <tf.Tensor 'batch_norm_3/batchnorm/add_1:0' shape=(1, 18, 7, 256) dtype=float32>,\n",
       "  'batch_norm_4': <tf.Tensor 'batch_norm_4/batchnorm/add_1:0' shape=(1, 5, 5, 512) dtype=float32>,\n",
       "  'batch_norm_fc_intermediate': <tf.Tensor 'batch_norm_fc_intermediate/batchnorm/add_1:0' shape=(1, 1024) dtype=float32>,\n",
       "  'coch_conv_0': <tf.Tensor 'coch_conv_0/BiasAdd:0' shape=(1, 1, 1600, 100) dtype=float32>,\n",
       "  'coch_relu_0': <tf.Tensor 'coch_relu_0:0' shape=(1, 100, 1600, 1) dtype=float32>,\n",
       "  'coch_relu_1': <tf.Tensor 'coch_relu_1:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_slice_0': <tf.Tensor 'coch_slice_0:0' shape=(1, 1, 3200, 1) dtype=float32>,\n",
       "  'coch_tfnnresample_0': <tf.Tensor 'Conv2D:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_transpose_0': <tf.Tensor 'coch_transpose_0:0' shape=(1, 100, 1600, 1) dtype=float32>,\n",
       "  'conv_0': <tf.Tensor 'conv_0/BiasAdd:0' shape=(1, 100, 751, 32) dtype=float32>,\n",
       "  'conv_1': <tf.Tensor 'conv_1/BiasAdd:0' shape=(1, 82, 141, 64) dtype=float32>,\n",
       "  'conv_2': <tf.Tensor 'conv_2/BiasAdd:0' shape=(1, 71, 13, 128) dtype=float32>,\n",
       "  'conv_3': <tf.Tensor 'conv_3/BiasAdd:0' shape=(1, 18, 7, 256) dtype=float32>,\n",
       "  'conv_4': <tf.Tensor 'conv_4/BiasAdd:0' shape=(1, 14, 5, 512) dtype=float32>,\n",
       "  'dropout': <tf.Tensor 'dropout/dropout/mul:0' shape=(1, 1024) dtype=float32>,\n",
       "  'fc_intermediate': <tf.Tensor 'fc_intermediate/BiasAdd:0' shape=(1, 1024) dtype=float32>,\n",
       "  'fc_top': <tf.Tensor 'fc_top/BiasAdd:0' shape=(1, 700) dtype=float32>,\n",
       "  'flatten_end_conv': <tf.Tensor 'flatten_end_conv/Reshape:0' shape=(1, 12800) dtype=float32>,\n",
       "  'pool_0': <tf.Tensor 'pool_0:0' shape=(1, 100, 151, 32) dtype=float32>,\n",
       "  'pool_1': <tf.Tensor 'pool_1:0' shape=(1, 82, 21, 64) dtype=float32>,\n",
       "  'pool_2': <tf.Tensor 'pool_2:0' shape=(1, 24, 13, 128) dtype=float32>,\n",
       "  'pool_3': <tf.Tensor 'pool_3:0' shape=(1, 18, 7, 256) dtype=float32>,\n",
       "  'pool_4': <tf.Tensor 'pool_4:0' shape=(1, 5, 5, 512) dtype=float32>,\n",
       "  'relu_0': <tf.Tensor 'relu_0:0' shape=(1, 100, 751, 32) dtype=float32>,\n",
       "  'relu_1': <tf.Tensor 'relu_1:0' shape=(1, 82, 141, 64) dtype=float32>,\n",
       "  'relu_2': <tf.Tensor 'relu_2:0' shape=(1, 71, 13, 128) dtype=float32>,\n",
       "  'relu_3': <tf.Tensor 'relu_3:0' shape=(1, 18, 7, 256) dtype=float32>,\n",
       "  'relu_4': <tf.Tensor 'relu_4:0' shape=(1, 14, 5, 512) dtype=float32>,\n",
       "  'relu_fc_intermediate': <tf.Tensor 'relu_fc_intermediate:0' shape=(1, 1024) dtype=float32>})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 1, 4800, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "\n",
    "list_brain_arch_tmp = [\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_slice_0',\n",
    "            'begin': [0, 0, 1600, 0],\n",
    "            'size': [-1, -1, 3200, -1],\n",
    "        },\n",
    "        'layer_type': 'tf.slice'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'activation': None,\n",
    "            'dilation_rate': [1, 1],\n",
    "            'filters': 100,\n",
    "            'kernel_size': [1, 1601],\n",
    "            'name': 'coch_conv_0',\n",
    "            'padding': 'VALID',\n",
    "            'strides': [1, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.layers.conv2d'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_transpose_0',\n",
    "            'perm': [0, 3, 2, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.transpose'\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_0\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_tfnnresample_0\",\n",
    "            \"sr_input\": 32e3,\n",
    "            \"sr_output\": 20e3,\n",
    "            \"kwargs_nnresample_poly_filter\": {\n",
    "                \"down\": 4,\n",
    "                \"up\": 1\n",
    "            },\n",
    "        },\n",
    "        \"layer_type\": \"tfnnresample\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_1\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "]\n",
    "\n",
    "list_brain_arch_tmp = list_brain_arch_tmp + list_brain_arch\n",
    "\n",
    "output_tensor, nets = make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch_tmp)\n",
    "\n",
    "output_tensor, nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4471 80.4471\n",
      "0.07\n",
      "2240 -320\n"
     ]
    }
   ],
   "source": [
    "regex_fn = '/om/scratch/Thu/msaddler/data_pitchnet/PND_v08/noise_TLAS_snr_neg10pos10/PND_*.hdf5'\n",
    "list_fn = glob.glob(regex_fn)\n",
    "fn = list_fn[0]\n",
    "\n",
    "# for k in util_misc.get_hdf5_dataset_key_list(fn):\n",
    "#     print(k)\n",
    "\n",
    "with h5py.File(fn, 'r') as f:\n",
    "    IDX = -50\n",
    "    idx0 = f['nopad_start_index'][IDX] - f['segment_start_index'][IDX]\n",
    "    idx1 = f['nopad_end_index'][IDX] - f['segment_end_index'][IDX]\n",
    "    \n",
    "    print(f['f0'][IDX], f['nopad_f0_mean'][IDX])\n",
    "    print(f['stimuli/signal_in_noise'][IDX, idx0:idx1].shape[0] / f['sr'][0])\n",
    "    print(idx0, idx1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2400, 2401, 2402, ..., 3997, 3998, 3999])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(0, 4800)\n",
    "X[2240:-320].shape\n",
    "\n",
    "Y = X[1600:]\n",
    "Y[800:-800]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4800-320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
