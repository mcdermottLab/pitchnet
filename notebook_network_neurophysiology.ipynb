{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "sys.path.append('ibmHearingAid/multi_gpu')\n",
    "import pitchnet_evaluate_best\n",
    "import functions_graph_assembly as fga\n",
    "\n",
    "sys.path.append('/om4/group/mcdermott/user/msaddler/pitchnet_dataset/pitchnetDataset/pitchnetDataset')\n",
    "import dataset_util\n",
    "\n",
    "sys.path.append('assets_psychophysics')\n",
    "import util_figures\n",
    "\n",
    "sys.path.append('assets_datasets')\n",
    "import util_stimuli\n",
    "\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_directory = '/saved_models/arch_0628/PND_v04_TLAS_classification1'\n",
    "# output_directory = '/saved_models/arch_0628/PND_v04_JWSS_highpass_v00_classification2'\n",
    "output_directory = '/saved_models/models_sr20000/arch_0302/PND_v08_TLAS_snr_neg10pos10_AN_BW10eN1_IHC3000Hz_classification0'\n",
    "# output_directory = '/saved_models/models_sr20000/arch_0302/PND_v08_TLAS_snr_neg10pos10_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0'\n",
    "# output_directory = '/saved_models/models_sr20000/arch_0302/PND_synthetic_noise_UMNm_snr_neg10pos10_phase0_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0'\n",
    "\n",
    "config_fn = os.path.join(output_directory, 'config.json')\n",
    "validation_metrics_fn = os.path.join(output_directory, 'validation_metrics.json')\n",
    "\n",
    "tfrecords_regex = '/om/user/msaddler/data_pitchnet/bernox2005/FixedFilter_f0min100_f0max300/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/*.tfrecords'\n",
    "\n",
    "with open(config_fn) as f: CONFIG = json.load(f)\n",
    "\n",
    "ckpt_num = pitchnet_evaluate_best.get_best_checkpoint_number(validation_metrics_fn,\n",
    "                                                             metric_key='f0_label:accuracy',\n",
    "                                                             maximize=True,\n",
    "                                                             checkpoint_number_key='step')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATOR_PARAMS = CONFIG['ITERATOR_PARAMS']\n",
    "batch_size = 128\n",
    "bytesList_decoding_dict = {\"meanrates\": {\"dtype\": \"tf.float32\", \"shape\": [100, 1000]}}\n",
    "feature_parsing_dict = pitchnet_evaluate_best.get_feature_parsing_dict_from_tfrecords(tfrecords_regex,\n",
    "                                                                                      bytesList_decoding_dict)\n",
    "\n",
    "ITERATOR_PARAMS['feature_parsing_dict'] = feature_parsing_dict\n",
    "N_CLASSES_DICT = CONFIG['N_CLASSES_DICT']\n",
    "BRAIN_PARAMS = CONFIG['BRAIN_PARAMS']\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# BUILD TFRECORDS ITERATOR GRAPH\n",
    "iterator, dataset, _ = fga.build_tfrecords_iterator(tfrecords_regex,\n",
    "                                                    num_epochs=1, shuffle_flag=False,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    iterator_type='one-shot',\n",
    "                                                    **ITERATOR_PARAMS)\n",
    "input_tensor_dict = iterator.get_next()\n",
    "\n",
    "### BUILD BRAIN NETWORK GRAPH\n",
    "batch_subbands = input_tensor_dict[ITERATOR_PARAMS['feature_signal_path']]\n",
    "while len(batch_subbands.shape) < 4: batch_subbands = tf.expand_dims(batch_subbands, axis=-1)\n",
    "batch_out_dict, brain_container = fga.build_brain_graph(batch_subbands, N_CLASSES_DICT, **BRAIN_PARAMS)\n",
    "\n",
    "### START SESSION AND INITIALIZE GRAPH\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "### BUILD SAVER GRAPH TO LOAD CHECKPOINT\n",
    "brain_var_scope = 'brain_network'\n",
    "brain_ckpt_prefix_name = BRAIN_PARAMS.get('save_ckpt_path', 'brain_model.ckpt')\n",
    "restore_model_path = os.path.join(output_directory, brain_ckpt_prefix_name + '-{}'.format(ckpt_num))\n",
    "brain_globals = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=brain_var_scope)\n",
    "brain_locals = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=brain_var_scope)\n",
    "brain_variables =  brain_globals + brain_locals\n",
    "saver_brain_net, out_ckpt_loc_brain_net, brain_net_ckpt = fga.build_saver(\n",
    "    sess, brain_variables, output_directory,\n",
    "    restore_model_path=restore_model_path,\n",
    "    ckpt_prefix_name=brain_ckpt_prefix_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_var = brain_variables[0] # conv0 filter kernels\n",
    "tf_var_value = np.transpose(np.squeeze(sess.run(tf_var)))\n",
    "tf_var_name = tf_var.name\n",
    "\n",
    "sr = 20000\n",
    "print(tf_var_name)\n",
    "\n",
    "N = tf_var_value.shape[0]\n",
    "\n",
    "NCOLS = 8\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=NROWS,\n",
    "                       ncols=NCOLS,\n",
    "                       figsize=(2.5*NCOLS, 2.5*NROWS),\n",
    "                       sharex=True,\n",
    "                       sharey=True)\n",
    "ax = ax.flatten()\n",
    "for idx in range(N):\n",
    "    x = tf_var_value[idx]\n",
    "    t = 1e3 * np.arange(0, len(x)) / sr\n",
    "    ax[idx].plot(t, x, 'k-', lw=0.5)\n",
    "    (str_xlabel, str_ylabel) = (None, None)\n",
    "    if idx % NCOLS == 0:\n",
    "        str_ylabel = 'Pa'\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        str_xlabel = 'Time (ms)'\n",
    "    ax[idx] = util_figures.format_axes(ax[idx],\n",
    "                                        str_xlabel=str_xlabel,\n",
    "                                        str_ylabel=str_ylabel,\n",
    "                                        fontsize_labels=12,\n",
    "                                        fontsize_ticks=12,\n",
    "                                        fontweight_labels=None,\n",
    "                                        xscale='linear',\n",
    "                                        yscale='linear',\n",
    "                                        xlimits=None,\n",
    "                                        ylimits=None,\n",
    "                                        xticks=None,\n",
    "                                        yticks=None,\n",
    "                                        xticks_minor=None,\n",
    "                                        yticks_minor=None,\n",
    "                                        xticklabels=None,\n",
    "                                        yticklabels=None,\n",
    "                                        spines_to_hide=[],\n",
    "                                        major_tick_params_kwargs_update={},\n",
    "                                        minor_tick_params_kwargs_update={})\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=NROWS,\n",
    "                       ncols=NCOLS,\n",
    "                       figsize=(2.5*NCOLS, 2.5*NROWS),\n",
    "                       sharex=True,\n",
    "                       sharey=True)\n",
    "ax = ax.flatten()\n",
    "for idx in range(N):\n",
    "    x = tf_var_value[idx]\n",
    "    fxx, pxx = util_stimuli.power_spectrum(x, sr)\n",
    "    ax[idx].plot(fxx, pxx, 'k-', lw=0.5)\n",
    "    (str_xlabel, str_ylabel) = (None, None)\n",
    "    if idx % NCOLS == 0:\n",
    "        str_ylabel = 'PSD (dB/Hz SPL)'\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        str_xlabel = 'Frequency (Hz)'\n",
    "    ax[idx] = util_figures.format_axes(ax[idx],\n",
    "                                        str_xlabel=str_xlabel,\n",
    "                                        str_ylabel=str_ylabel,\n",
    "                                        fontsize_labels=12,\n",
    "                                        fontsize_ticks=12,\n",
    "                                        fontweight_labels=None,\n",
    "                                        xscale='linear',\n",
    "                                        yscale='linear',\n",
    "                                        xlimits=[0, 10000],\n",
    "                                        ylimits=None,\n",
    "                                        xticks=None,\n",
    "                                        yticks=None,\n",
    "                                        xticks_minor=None,\n",
    "                                        yticks_minor=None,\n",
    "                                        xticklabels=None,\n",
    "                                        yticklabels=None,\n",
    "                                        spines_to_hide=[],\n",
    "                                        major_tick_params_kwargs_update={},\n",
    "                                        minor_tick_params_kwargs_update={})\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUATION ROUTINE + STORE ACTIVATIONS\n",
    "tensors_to_evaluate = {}\n",
    "\n",
    "metadata_keys = ['f0', 'f0_label', 'low_harm', 'phase_mode']\n",
    "for key in metadata_keys:\n",
    "    tensors_to_evaluate[key] = input_tensor_dict[key]\n",
    "\n",
    "mean_axis = [1, 2]\n",
    "for key in brain_container.keys():\n",
    "    if 'relu' in key:\n",
    "        activations = brain_container[key]\n",
    "        if len(activations.shape) == 4:\n",
    "            tensors_to_evaluate[key] = tf.reduce_mean(activations, axis=mean_axis)\n",
    "        else:\n",
    "            tensors_to_evaluate[key] = activations\n",
    "\n",
    "output_dict = {}\n",
    "for key in tensors_to_evaluate.keys():\n",
    "    output_dict[key] = []\n",
    "\n",
    "display_step = 100\n",
    "batch_count = 0\n",
    "try:\n",
    "    while True:\n",
    "        evaluated_batch = sess.run(tensors_to_evaluate)\n",
    "        for key in set(output_dict.keys()).intersection(evaluated_batch.keys()):\n",
    "            key_val = np.array(evaluated_batch[key]).tolist()\n",
    "            if not isinstance(key_val, list): key_val = [key_val]\n",
    "            output_dict[key].extend(key_val)\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % display_step == 0: print(batch_count)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('End of evaluation dataset reached.')\n",
    "\n",
    "for key in output_dict.keys():\n",
    "    output_dict[key] = np.array(output_dict[key])\n",
    "    print(key, output_dict[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = output_dict['phase_mode'] == 0\n",
    "for key in output_dict.keys():\n",
    "    output_dict[key] = output_dict[key][mask]\n",
    "\n",
    "sort_idx = np.argsort(output_dict['f0'])\n",
    "for key in output_dict.keys():\n",
    "    output_dict[key] = output_dict[key][sort_idx]\n",
    "    print(key, output_dict[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tuning_tensor(output_dict,\n",
    "                          key_act='relu_1',\n",
    "                          key_x='low_harm',\n",
    "                          key_y='f0_label_coarse'):\n",
    "    \n",
    "    x_unique = np.unique(output_dict[key_x])\n",
    "    y_unique = np.unique(output_dict[key_y])\n",
    "    shape = [x_unique.shape[0], y_unique.shape[0], output_dict[key_act].shape[1]]\n",
    "    dtype = output_dict[key_act].dtype\n",
    "    tuning_tensor = np.zeros(shape, dtype=dtype)\n",
    "    tuning_tensor_counts = np.zeros(shape[:-1] + [1], dtype=int)\n",
    "    \n",
    "    x_value_indexes = np.digitize(output_dict[key_x], x_unique, right=True)\n",
    "    y_value_indexes = np.digitize(output_dict[key_y], y_unique, right=True)\n",
    "    for idx in range(output_dict[key_act].shape[0]):\n",
    "        x_idx = x_value_indexes[idx]\n",
    "        y_idx = y_value_indexes[idx]\n",
    "        act = output_dict[key_act][idx]\n",
    "        \n",
    "        tuning_tensor[x_idx, y_idx, :] += act\n",
    "        tuning_tensor_counts[x_idx, y_idx] += 1\n",
    "    \n",
    "    tuning_tensor = tuning_tensor / tuning_tensor_counts\n",
    "    return tuning_tensor\n",
    "\n",
    "\n",
    "coarse_f0_bins = dataset_util.get_f0_bins(f0_min=80., f0_max=1e3, binwidth_in_octaves=1/24)\n",
    "output_dict['f0']\n",
    "output_dict['f0_label_coarse'] = dataset_util.f0_to_label(output_dict['f0'], coarse_f0_bins)\n",
    "\n",
    "tuning_tensor = compute_tuning_tensor(output_dict, key_act='relu_4')\n",
    "print('computed tuning_tensor:', tuning_tensor.shape)\n",
    "\n",
    "f0_tuning_array = np.mean(tuning_tensor, axis=0)\n",
    "print('computed f0_tuning_array:', f0_tuning_array.shape)\n",
    "\n",
    "low_harm_tuning_array = np.mean(tuning_tensor, axis=1)\n",
    "print('computed low_harm_tuning_array:', low_harm_tuning_array.shape)\n",
    "\n",
    "sort_idx_f0_tuning = np.argsort(np.argmax(f0_tuning_array, axis=0))\n",
    "sort_idx_low_harm_tuning = np.argsort(np.argmax(low_harm_tuning_array, axis=0))\n",
    "\n",
    "\n",
    "tuning_tensor = tuning_tensor[:, :, sort_idx_low_harm_tuning]\n",
    "f0_tuning_array = f0_tuning_array[:, sort_idx_low_harm_tuning]\n",
    "low_harm_tuning_array = low_harm_tuning_array[:, sort_idx_low_harm_tuning]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_f0_bins = dataset_util.get_f0_bins(f0_min=80., f0_max=1e3, binwidth_in_octaves=1/24)\n",
    "coarse_f0_bins = dataset_util.get_f0_bins(f0_min=80., f0_max=1e3)\n",
    "output_dict['f0']\n",
    "output_dict['f0_label_coarse'] = dataset_util.f0_to_label(output_dict['f0'], coarse_f0_bins)\n",
    "\n",
    "key_act_list = [\n",
    "    'relu_0',\n",
    "    'relu_1',\n",
    "    'relu_2',\n",
    "    'relu_3',\n",
    "    'relu_4',\n",
    "]\n",
    "\n",
    "for unit_idx in [0, 1, 2, 3, 'mean']:\n",
    "    NCOLS = len(key_act_list)\n",
    "    NROWS = 1\n",
    "    fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(3.0*NCOLS, 3.0*NROWS))\n",
    "    ax = np.array(ax).flatten()\n",
    "\n",
    "    for idx, key_act in enumerate(key_act_list):\n",
    "        tuning_tensor = compute_tuning_tensor(output_dict, key_act=key_act)\n",
    "\n",
    "        f0_bin_values = [coarse_f0_bins[idx] for idx in np.unique(output_dict['f0_label_coarse'])]\n",
    "        f0_bin_values = np.array(f0_bin_values)\n",
    "        f0_idx = np.linspace(2, f0_bin_values.shape[0]-3, num=5, dtype=int)\n",
    "        f0_labels = ['{:.0f}'.format(f0_bin_values[idx]) for idx in f0_idx]\n",
    "\n",
    "        low_harm_values = np.unique(output_dict['low_harm'])\n",
    "        low_harm_idx = np.linspace(0, low_harm_values.shape[0]-1, num=5, dtype=int)\n",
    "        low_harm_labels = ['{:.0f}'.format(low_harm_values[idx]) for idx in low_harm_idx]\n",
    "\n",
    "        if isinstance(unit_idx, int):\n",
    "            tuning_tensor_idx = unit_idx\n",
    "            Z = tuning_tensor[:, :, unit_idx].T\n",
    "        elif isinstance(unit_idx, str):\n",
    "            if unit_idx == 'mean':\n",
    "                tuning_tensor_idx = 'MEAN'\n",
    "                Z = np.mean(tuning_tensor, axis=2).T\n",
    "            else:\n",
    "                tuning_tensor_idx = np.random.randint(tuning_tensor.shape[2])\n",
    "                Z = tuning_tensor[:, :, tuning_tensor_idx].T\n",
    "        else:\n",
    "            raise ValueError('`type(unit_idx)={}` is not supported'.format(type(unit_idx)))\n",
    "        str_title = '{}: unit {}'.format(key_act, tuning_tensor_idx)\n",
    "        ax[idx].set_title(str_title, fontsize=12)\n",
    "        ax[idx].imshow(Z,\n",
    "                       origin='lower',\n",
    "                       aspect='auto',\n",
    "                       extent=[0, Z.shape[1], 0, Z.shape[0]],\n",
    "                       cmap=plt.cm.gray)\n",
    "        ax[idx] = util_figures.format_axes(ax[idx],\n",
    "                                            str_xlabel='Lowest harmonic',\n",
    "                                            str_ylabel='F0 (Hz)',\n",
    "                                            fontsize_labels=12,\n",
    "                                            fontsize_ticks=12,\n",
    "                                            fontweight_labels=None,\n",
    "                                            xscale='linear',\n",
    "                                            yscale='linear',\n",
    "                                            xlimits=None,\n",
    "                                            ylimits=None,\n",
    "                                            xticks=low_harm_idx,\n",
    "                                            yticks=f0_idx,\n",
    "                                            xticks_minor=None,\n",
    "                                            yticks_minor=None,\n",
    "                                            xticklabels=low_harm_labels,\n",
    "                                            yticklabels=f0_labels,\n",
    "                                            spines_to_hide=[],\n",
    "                                            major_tick_params_kwargs_update={},\n",
    "                                            minor_tick_params_kwargs_update={})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f0_bin_values = [coarse_f0_bins[idx] for idx in np.unique(output_dict['f0_label_coarse'])]\n",
    "f0_bin_values = np.array(f0_bin_values)\n",
    "f0_idx = np.linspace(2, f0_bin_values.shape[0]-3, num=3, dtype=int)\n",
    "f0_labels = ['{:.0f}'.format(f0_bin_values[idx]) for idx in f0_idx]\n",
    "\n",
    "low_harm_values = np.unique(output_dict['low_harm'])\n",
    "low_harm_idx = np.linspace(0, low_harm_values.shape[0]-1, num=3, dtype=int)\n",
    "low_harm_labels = ['{:.0f}'.format(low_harm_values[idx]) for idx in low_harm_idx]\n",
    "\n",
    "N = tuning_tensor.shape[-1]\n",
    "\n",
    "NCOLS = 16\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(1.0*NCOLS, 1.0*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "for idx in range(N):\n",
    "    Z = tuning_tensor[:, :, idx].T\n",
    "    ax[idx].imshow(Z, origin='lower', aspect='auto', extent=[0, Z.shape[1], 0, Z.shape[0]])\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])\n",
    "    if idx % NCOLS == 0:\n",
    "        ax[idx].set_yticks(f0_idx)\n",
    "        ax[idx].set_yticklabels(f0_labels)\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        ax[idx].set_xticks(low_harm_idx)\n",
    "        ax[idx].set_xticklabels(low_harm_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f0_bin_values = [coarse_f0_bins[idx] for idx in np.unique(output_dict['f0_label_coarse'])]\n",
    "f0_bin_values = np.array(f0_bin_values)\n",
    "f0_idx = np.linspace(2, f0_bin_values.shape[0]-3, num=3, dtype=int)\n",
    "f0_labels = ['{:.0f}'.format(f0_bin_values[idx]) for idx in f0_idx]\n",
    "\n",
    "N = f0_tuning_array.shape[-1]\n",
    "\n",
    "NCOLS = 16\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(1.0*NCOLS, 1.0*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "for idx in range(N):\n",
    "    ax[idx].plot(np.arange(0, f0_tuning_array.shape[0]), f0_tuning_array[:, idx])\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])\n",
    "#     if idx % NCOLS == 0:\n",
    "#         ax[idx].set_yticks(f0_idx)\n",
    "#         ax[idx].set_yticklabels(f0_labels)\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        ax[idx].set_xticks(f0_idx)\n",
    "        ax[idx].set_xticklabels(f0_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "low_harm_values = np.unique(output_dict['low_harm'])\n",
    "low_harm_idx = np.linspace(0, low_harm_values.shape[0]-1, num=3, dtype=int)\n",
    "low_harm_labels = ['{:.0f}'.format(low_harm_values[idx]) for idx in low_harm_idx]\n",
    "\n",
    "N = low_harm_tuning_array.shape[-1]\n",
    "\n",
    "NCOLS = 16\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(1.0*NCOLS, 1.0*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "for idx in range(N):\n",
    "    Z = tuning_tensor[:, :, idx].T\n",
    "    ax[idx].plot(np.arange(0, low_harm_tuning_array.shape[0]), low_harm_tuning_array[:, idx])\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])\n",
    "#     if idx % NCOLS == 0:\n",
    "#         ax[idx].set_yticks(f0_idx)\n",
    "#         ax[idx].set_yticklabels(f0_labels)\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        ax[idx].set_xticks(low_harm_idx)\n",
    "        ax[idx].set_xticklabels(low_harm_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_octave_bins(octave_min=-2.0,\n",
    "                    octave_max=2.0,\n",
    "                    num_bins=4*12*16+1):\n",
    "    return np.linspace(octave_min, octave_max, num_bins)\n",
    "\n",
    "\n",
    "def compute_octave_tuning_array(output_dict,\n",
    "                                key_act='relu_5',\n",
    "                                kwargs_f0_bins={},\n",
    "                                kwargs_octave_bins={},\n",
    "                                shuffle=False):\n",
    "    ### Compute generic tuning tensor (low_harm and f0 tuning)\n",
    "    coarse_f0_bins = dataset_util.get_f0_bins(**kwargs_f0_bins)\n",
    "    output_dict['f0_label_coarse'] = dataset_util.f0_to_label(output_dict['f0'],\n",
    "                                                              coarse_f0_bins)\n",
    "    tuning_tensor = compute_tuning_tensor(output_dict,\n",
    "                                          key_act=key_act,\n",
    "                                          key_x='low_harm',\n",
    "                                          key_y='f0_label_coarse')\n",
    "    \n",
    "    ### Collapse tuning tensor along low_harm axis to get f0 tuning\n",
    "    f0_tuning_array = np.mean(tuning_tensor, axis=0)\n",
    "    sort_idx_f0_tuning = np.argsort(np.argmax(f0_tuning_array, axis=0))\n",
    "    tuning_tensor = tuning_tensor[:, :, sort_idx_f0_tuning]\n",
    "    f0_tuning_array = f0_tuning_array[:, sort_idx_f0_tuning]\n",
    "    f0_bin_values = np.array([coarse_f0_bins[idx]\n",
    "                              for idx in np.unique(output_dict['f0_label_coarse'])])\n",
    "    \n",
    "    ### If specified, shuffle the f0 axis to get null distribution\n",
    "    if shuffle:\n",
    "        indexes = np.arange(0, f0_tuning_array.shape[0])\n",
    "        np.random.shuffle(indexes)\n",
    "        f0_tuning_array = f0_tuning_array[indexes]\n",
    "    \n",
    "    ### Compute best f0s and setup octave tuning array\n",
    "    best_f0s = f0_bin_values[np.argmax(f0_tuning_array, axis=0)]\n",
    "    octave_bins = get_octave_bins(**kwargs_octave_bins)\n",
    "    octave_tuning_array = -1 * np.ones([octave_bins.shape[0], f0_tuning_array.shape[1]])\n",
    "    \n",
    "    ### Populate octave tuning array\n",
    "    for itr1 in range(f0_tuning_array.shape[1]):\n",
    "        best_f0 = best_f0s[itr1]\n",
    "        f0_tuning = f0_tuning_array[:, itr1]\n",
    "        octaves_re_best_f0 = np.log2(f0_bin_values / best_f0)\n",
    "        octave_indexes = np.digitize(octaves_re_best_f0, octave_bins)\n",
    "        values = np.zeros_like(octave_bins)\n",
    "        counts = np.zeros_like(octave_bins)\n",
    "        for itr0, oct_idx in enumerate(octave_indexes):\n",
    "            values[oct_idx] += f0_tuning_array[itr0, itr1]\n",
    "            counts[oct_idx] += 1\n",
    "        valid_indexes = counts > 0\n",
    "        octave_tuning_array[valid_indexes, itr1] = values[valid_indexes] / counts[valid_indexes]\n",
    "\n",
    "    return octave_bins, octave_tuning_array\n",
    "\n",
    "\n",
    "def average_tuning_array(bins, tuning_array, normalize=True):\n",
    "    assert bins.shape[0] == tuning_array.shape[0]\n",
    "    if normalize:\n",
    "        for itr1 in range(tuning_array.shape[1]):\n",
    "            valid_indexes = tuning_array[:, itr1] >= 0\n",
    "            tuning_array[valid_indexes, itr1] -= np.min(tuning_array[valid_indexes, itr1])\n",
    "            tuning_array[valid_indexes, itr1] /= np.max(tuning_array[valid_indexes, itr1])\n",
    "    \n",
    "    tuning_array_mean = -1 * np.ones_like(bins)\n",
    "    tuning_array_err = -1 * np.ones_like(bins)\n",
    "    for itr0 in range(bins.shape[0]):\n",
    "        valid_indexes = tuning_array[itr0, :] >= 0\n",
    "        if any(valid_indexes):\n",
    "            tuning_array_mean[itr0] = np.mean(tuning_array[itr0, valid_indexes])\n",
    "            tuning_array_err[itr0] = np.std(tuning_array[itr0, valid_indexes])# / np.sqrt(np.sum(valid_indexes))\n",
    "    \n",
    "    valid_indexes = tuning_array_mean >= 0\n",
    "    tuning_array_mean = tuning_array_mean[valid_indexes]\n",
    "    tuning_array_err = tuning_array_err[valid_indexes]\n",
    "    tuning_array_mean_bins = bins[valid_indexes]\n",
    "    return tuning_array_mean_bins, tuning_array_mean, tuning_array_err\n",
    "\n",
    "\n",
    "kwargs_octave_bins = {\n",
    "    'octave_min': -2,\n",
    "    'octave_max': 2,\n",
    "    'num_bins': 4*12*4+1,\n",
    "}\n",
    "\n",
    "# condition_dict = {\n",
    "#     'control': {'key_act': 'relu_4', 'shuffle': True},\n",
    "#     'conv0': {'key_act': 'relu_0', 'shuffle': False},\n",
    "#     'conv1': {'key_act': 'relu_1', 'shuffle': False},\n",
    "#     'conv2': {'key_act': 'relu_2', 'shuffle': False},\n",
    "#     'conv3': {'key_act': 'relu_3', 'shuffle': False},\n",
    "#     'conv4': {'key_act': 'relu_4', 'shuffle': False},\n",
    "# }\n",
    "condition_dict = {\n",
    "    'relu_0': {'key_act': 'relu_0', 'shuffle': False},\n",
    "    'relu_0_shuffle': {'key_act': 'relu_0', 'shuffle': True},\n",
    "    'relu_1': {'key_act': 'relu_1', 'shuffle': False},\n",
    "    'relu_1_shuffle': {'key_act': 'relu_1', 'shuffle': True},\n",
    "    'relu_2': {'key_act': 'relu_2', 'shuffle': False},\n",
    "    'relu_2_shuffle': {'key_act': 'relu_2', 'shuffle': True},\n",
    "    'relu_3': {'key_act': 'relu_3', 'shuffle': False},\n",
    "    'relu_3_shuffle': {'key_act': 'relu_3', 'shuffle': True},\n",
    "    'relu_4': {'key_act': 'relu_4', 'shuffle': False},\n",
    "    'relu_4_shuffle': {'key_act': 'relu_4', 'shuffle': True},\n",
    "}\n",
    "\n",
    "results_dicts = {}\n",
    "\n",
    "for key in sorted(condition_dict.keys()):\n",
    "    print(key, condition_dict[key])\n",
    "    oct_bins, oct_array = compute_octave_tuning_array(output_dict,\n",
    "                                                      kwargs_octave_bins=kwargs_octave_bins,\n",
    "                                                      **condition_dict[key])\n",
    "    oct_array_mean_bins, oct_array_mean, oct_array_err = average_tuning_array(oct_bins, \n",
    "                                                                              oct_array,\n",
    "                                                                              normalize=True)\n",
    "    results_dicts[key] = {\n",
    "        'oct_bins': oct_bins,\n",
    "        'oct_array': oct_array,\n",
    "        'oct_array_mean_bins': oct_array_mean_bins,\n",
    "        'oct_array_mean': oct_array_mean,\n",
    "        'oct_array_err': oct_array_err,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_act_list = [\n",
    "    'relu_0',\n",
    "    'relu_1',\n",
    "    'relu_2',\n",
    "    'relu_3',\n",
    "    'relu_4',\n",
    "]\n",
    "\n",
    "COLOR_LIST = [\n",
    "    [0, 0.5, 0],\n",
    "    [0, 0, 0],\n",
    "]\n",
    "\n",
    "NCOLS = len(key_act_list)\n",
    "NROWS = 1\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(3.0*NCOLS, 3.0*NROWS))\n",
    "ax = np.array(ax).flatten()\n",
    "\n",
    "xlimits=[-1.25, 1.25]\n",
    "ylimits=[-0.05, 1.45]\n",
    "\n",
    "for idx, key_act in enumerate(key_act_list):\n",
    "\n",
    "    for cidx, key in enumerate([key_act + '_shuffle', key_act]):\n",
    "        rd = results_dicts[key]\n",
    "        xval = rd['oct_array_mean_bins']\n",
    "        yval = rd['oct_array_mean']\n",
    "        yerr = rd['oct_array_err']\n",
    "        plot_kwargs = {\n",
    "            'lw': 1,\n",
    "            'color': COLOR_LIST[cidx],\n",
    "            'label': key,\n",
    "        }\n",
    "        if cidx > 0:\n",
    "            ax[idx].fill_between(xval, yval-yerr, yval+yerr,\n",
    "                                 alpha=0.20,\n",
    "                                 facecolor=plot_kwargs.get('color', 'k'))\n",
    "        ax[idx].plot(xval, yval, **plot_kwargs)\n",
    "    \n",
    "    kwargs_legend = {\n",
    "        'loc': 'upper right',\n",
    "        'frameon': False,\n",
    "        'fontsize': 12,\n",
    "        'handlelength': 0.5,\n",
    "        'borderpad': 0.5,\n",
    "        'borderaxespad': 0.1,\n",
    "    }\n",
    "    leg = ax[idx].legend(**kwargs_legend)\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(4.0)\n",
    "    \n",
    "    ax[idx] = util_figures.format_axes(ax[idx],\n",
    "                                        str_xlabel='Octaves above best F0',\n",
    "                                        str_ylabel='Normalized activation',\n",
    "                                        fontsize_labels=12,\n",
    "                                        fontsize_ticks=12,\n",
    "                                        fontweight_labels=None,\n",
    "                                        xscale='linear',\n",
    "                                        yscale='linear',\n",
    "                                        xlimits=xlimits,\n",
    "                                        ylimits=ylimits,\n",
    "                                        xticks=np.arange(-1, 1.01, 0.5),\n",
    "                                        yticks=None,\n",
    "                                        xticks_minor=None,\n",
    "                                        yticks_minor=None,\n",
    "                                        xticklabels=None,\n",
    "                                        yticklabels=None,\n",
    "                                        spines_to_hide=[],\n",
    "                                        major_tick_params_kwargs_update={},\n",
    "                                        minor_tick_params_kwargs_update={})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colors = 10#len(condition_dict.keys())\n",
    "cmap_name = 'tab10'\n",
    "COLOR_LIST = util_figures.get_color_list(num_colors, cmap_name=cmap_name)\n",
    "\n",
    "color_condition_list = [\n",
    "    ([0.5]*3, 'control'),\n",
    "#     (0, 'relu_1_shuffle_F0'),\n",
    "    (0, 'conv0'),\n",
    "    (1, 'conv1'),\n",
    "#     (0, 'relu_3_shuffle_F0'),\n",
    "    (2, 'conv2'),\n",
    "    (3, 'conv3'),\n",
    "    (4, 'conv4'),\n",
    "]\n",
    "\n",
    "figsize=(6, 4.5)\n",
    "fontsize_labels=16\n",
    "fontsize_legend=13\n",
    "fontsize_ticks=13\n",
    "\n",
    "xlimits=[-1.25, 1.25]\n",
    "ylimits=[-0.05, 1.05]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "\n",
    "for (cidx, key) in color_condition_list:\n",
    "    rd = results_dicts[key]\n",
    "    xval = rd['oct_array_mean_bins']\n",
    "    yval = rd['oct_array_mean']\n",
    "    yerr = rd['oct_array_err']\n",
    "    \n",
    "    if isinstance(cidx, int): color = COLOR_LIST[cidx]\n",
    "    else: color = cidx\n",
    "    \n",
    "#     plot_kwargs = {\n",
    "#         'lw': 0.1,\n",
    "#         'color': color,\n",
    "#         'label': None,\n",
    "#     }\n",
    "#     if 'control' not in key:\n",
    "#         N = rd['oct_array'].shape[1]\n",
    "#         for itr1 in range(N):\n",
    "#             tuning_curve = rd['oct_array'][:, itr1]\n",
    "#             octave_bins = rd['oct_bins']\n",
    "#             valid_idx = tuning_curve >= 0\n",
    "#             y = tuning_curve[valid_idx]\n",
    "#             x = octave_bins[valid_idx]\n",
    "#             ax.plot(x, y, **plot_kwargs)\n",
    "    \n",
    "    plot_kwargs = {\n",
    "        'lw': 4,\n",
    "        'color': color,\n",
    "        'label': key,\n",
    "    }\n",
    "    \n",
    "    ax.fill_between(xval, yval-yerr, yval+yerr,\n",
    "                    alpha=0.10,\n",
    "                    facecolor=plot_kwargs.get('color', 'k'))\n",
    "    ax.plot(xval, yval, **plot_kwargs)\n",
    "    \n",
    "legend_plot_kwargs = {\n",
    "    'loc':'upper right',\n",
    "    'frameon':False,\n",
    "    'fontsize':fontsize_legend,\n",
    "    'handlelength': 0.5,\n",
    "    'bbox_to_anchor': [1.04, 1.04],\n",
    "}\n",
    "ax.legend(**legend_plot_kwargs)\n",
    "\n",
    "ax.set_xlabel('Octaves above best F0', fontsize=fontsize_labels)\n",
    "ax.set_ylabel('Normalized activation', fontsize=fontsize_labels)\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(-1, 1.01, 0.5), minor=False)\n",
    "ax.set_xticks(np.arange(xlimits[0], xlimits[1]+0.01, 0.25), minor=True)\n",
    "# ax.set_yticks(np.arange(0, ylimits[-1]+0.1, yticks), minor=False)\n",
    "# ax.set_yticks(np.arange(ylimits[0], ylimits[-1]+0.1, 0.1), minor=True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_ticks, length=4)\n",
    "ax.tick_params(axis='both', which='minor', length=2)\n",
    "ax.set_xlim(xlimits)\n",
    "ax.set_ylim(ylimits)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/'\n",
    "# save_fn = os.path.join(save_dir, 'neurophysiology_f0_tuning_relu0relu2relu4_stddev_arch_0302_PND_synthetic_noise_UMNm_snr_neg10pos10_phase0_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0.pdf')\n",
    "# fig.savefig(save_fn, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(output_dict,\n",
    "                      key_act='relu_5',\n",
    "                      kwargs_f0_bins={},\n",
    "                      use_argmax=True):\n",
    "    \n",
    "    coarse_f0_bins = dataset_util.get_f0_bins(**kwargs_f0_bins)\n",
    "    output_dict['f0_label_coarse'] = dataset_util.f0_to_label(output_dict['f0'],\n",
    "                                                              coarse_f0_bins)\n",
    "    tuning_tensor = compute_tuning_tensor(output_dict,\n",
    "                                          key_act=key_act,\n",
    "                                          key_x='low_harm',\n",
    "                                          key_y='f0_label_coarse')\n",
    "    \n",
    "    f0_bin_values = np.array([coarse_f0_bins[idx]\n",
    "                              for idx in np.unique(output_dict['f0_label_coarse'])])\n",
    "    lh_bin_values = np.unique(output_dict['low_harm'])\n",
    "    \n",
    "    centroid_f0_list = []\n",
    "    centroid_lh_list = []\n",
    "    for itr2 in range(tuning_tensor.shape[2]):\n",
    "        tuning_array = tuning_tensor[:, :, itr2]\n",
    "        \n",
    "        if use_argmax:\n",
    "            ind = np.unravel_index(np.argmax(tuning_array, axis=None), tuning_array.shape)\n",
    "            centroid_f0 = f0_bin_values[ind[1]]\n",
    "            centroid_lh = lh_bin_values[ind[0]]\n",
    "        else:\n",
    "            weights_f0 = np.mean(tuning_array, axis=0)\n",
    "            centroid_f0 = np.sum(weights_f0 * f0_bin_values) / np.sum(weights_f0)\n",
    "\n",
    "            weights_lh = np.mean(tuning_array, axis=1)\n",
    "            centroid_lh = np.sum(weights_lh * lh_bin_values) / np.sum(weights_lh)\n",
    "            \n",
    "        centroid_f0_list.append(centroid_f0)\n",
    "        centroid_lh_list.append(centroid_lh)\n",
    "    \n",
    "    centroid_f0_list = np.array(centroid_f0_list)\n",
    "    centroid_lh_list = np.array(centroid_lh_list)\n",
    "    return centroid_f0_list, centroid_lh_list, f0_bin_values, lh_bin_values\n",
    "\n",
    "\n",
    "kwargs_f0_bins = {'f0_min':80., 'f0_max':1e3, 'binwidth_in_octaves':1/(12*4)}\n",
    "condition_list = ['relu_0', 'relu_1', 'relu_2', 'relu_3', 'relu_4']\n",
    "results_dicts = {}\n",
    "for key in condition_list:\n",
    "    \n",
    "    centroid_f0_list, centroid_lh_list, f0_bin_values, lh_bin_values = compute_centroids(\n",
    "        output_dict, key_act=key, kwargs_f0_bins=kwargs_f0_bins, use_argmax=True)\n",
    "    \n",
    "    results_dicts[key] = {\n",
    "        'f0_bin_values': f0_bin_values,\n",
    "        'lh_bin_values': lh_bin_values,\n",
    "        'centroid_f0_list': centroid_f0_list,\n",
    "        'centroid_lh_list': centroid_lh_list,\n",
    "        'centroid_f0_indexes': np.digitize(centroid_f0_list, f0_bin_values, right=True),\n",
    "        'centroid_lh_indexes': np.digitize(centroid_lh_list, lh_bin_values, right=True),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colors = 10#len(condition_dict.keys())\n",
    "cmap_name = 'tab10'\n",
    "COLOR_LIST = util_figures.get_color_list(num_colors, cmap_name=cmap_name)\n",
    "\n",
    "color_condition_list = [\n",
    "    (0, 'relu_0'),\n",
    "    (1, 'relu_1'),\n",
    "    (2, 'relu_2'),\n",
    "    (3, 'relu_3'),\n",
    "    (4, 'relu_4'),\n",
    "]\n",
    "\n",
    "figsize=(3, 3)\n",
    "fontsize_labels=12\n",
    "fontsize_legend=12\n",
    "fontsize_ticks=12\n",
    "fontsize_title=12\n",
    "\n",
    "NCOLS = 1\n",
    "NROWS = len(color_condition_list)\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(figsize[0]*NCOLS, figsize[1]*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ax_idx, (cidx, key) in enumerate(color_condition_list):\n",
    "    rd = results_dicts[key]\n",
    "    xidx = rd['centroid_lh_indexes']\n",
    "    yidx = rd['centroid_f0_indexes']\n",
    "    xbin = rd['lh_bin_values']\n",
    "    ybin = rd['f0_bin_values']\n",
    "    \n",
    "    plot_kwargs = {\n",
    "        'color': COLOR_LIST[cidx],\n",
    "        'marker': '.',\n",
    "        'ms': 6,\n",
    "        'ls': '',\n",
    "    }\n",
    "\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "    ax[ax_idx].plot(xidx, yidx, **plot_kwargs)\n",
    "    \n",
    "    ax[ax_idx].set_xlabel('Lowest harmonic', fontsize=fontsize_labels)\n",
    "    ax[ax_idx].set_ylabel('F0 (Hz)', fontsize=fontsize_labels)\n",
    "    ax[ax_idx].set_title(key, fontsize=fontsize_title)\n",
    "    \n",
    "    lh_idx = np.linspace(0, xbin.shape[0]-2, num=5, dtype=int)\n",
    "    lh_labels = ['{:.0f}'.format(xbin[idx]) for idx in lh_idx]\n",
    "    ax[ax_idx].set_xticks(lh_idx)\n",
    "    ax[ax_idx].set_xticklabels(lh_labels)\n",
    "    \n",
    "    f0_idx = np.linspace(0, ybin.shape[0]-1, num=5, dtype=int)\n",
    "    f0_labels = ['{:.0f}'.format(ybin[idx]) for idx in f0_idx]\n",
    "    ax[ax_idx].set_yticks(f0_idx)\n",
    "    ax[ax_idx].set_yticklabels(f0_labels)\n",
    "    \n",
    "    ax[ax_idx].set_xlim([-1, len(xbin)])\n",
    "    ax[ax_idx].set_ylim([-1, len(ybin)])\n",
    "    \n",
    "    ax[ax_idx].tick_params(axis='both', which='major', labelsize=fontsize_ticks, length=4)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "#     save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/'\n",
    "#     save_fn = os.path.join(save_dir, 'neurophysiology_scatterplot_tuning_peaks_arch_0302_PND_synthetic_noise_UMNm_snr_neg10pos10_phase0_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0_{}.pdf'.format(key))\n",
    "#     print(save_fn)\n",
    "#     fig.savefig(save_fn, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_f0_bins = dataset_util.get_f0_bins(f0_min=80., f0_max=1e3, binwidth_in_octaves=1/(12*4))\n",
    "output_dict['f0']\n",
    "output_dict['f0_label_coarse'] = dataset_util.f0_to_label(output_dict['f0'], coarse_f0_bins)\n",
    "\n",
    "tuning_tensor = compute_tuning_tensor(output_dict, key_act='relu_1')\n",
    "print('computed tuning_tensor:', tuning_tensor.shape)\n",
    "\n",
    "f0_tuning_array = np.mean(tuning_tensor, axis=0)\n",
    "print('computed f0_tuning_array:', f0_tuning_array.shape)\n",
    "\n",
    "low_harm_tuning_array = np.mean(tuning_tensor, axis=1)\n",
    "print('computed low_harm_tuning_array:', low_harm_tuning_array.shape)\n",
    "\n",
    "sort_idx_f0_tuning = np.argsort(np.argmax(f0_tuning_array, axis=0))\n",
    "sort_idx_low_harm_tuning = np.argsort(np.argmax(low_harm_tuning_array, axis=0))\n",
    "\n",
    "\n",
    "tuning_tensor = tuning_tensor[:, :, sort_idx_low_harm_tuning]\n",
    "f0_tuning_array = f0_tuning_array[:, sort_idx_low_harm_tuning]\n",
    "low_harm_tuning_array = low_harm_tuning_array[:, sort_idx_low_harm_tuning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "\n",
    "\n",
    "f0_bin_values = [coarse_f0_bins[idx] for idx in np.unique(output_dict['f0_label_coarse'])]\n",
    "f0_bin_values = np.array(f0_bin_values)\n",
    "f0_idx = np.linspace(2, f0_bin_values.shape[0]-3, num=3, dtype=int)\n",
    "f0_labels = ['{:.0f}'.format(f0_bin_values[idx]) for idx in f0_idx]\n",
    "\n",
    "low_harm_values = np.unique(output_dict['low_harm'])\n",
    "low_harm_idx = np.linspace(0, low_harm_values.shape[0]-1, num=3, dtype=int)\n",
    "low_harm_labels = ['{:.0f}'.format(low_harm_values[idx]) for idx in low_harm_idx]\n",
    "\n",
    "N = tuning_tensor.shape[-1]\n",
    "\n",
    "NCOLS = 16\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(1.0*NCOLS, 1.0*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "for idx in range(N):\n",
    "    Z = tuning_tensor[:, :, idx].T\n",
    "    ax[idx].imshow(Z, origin='lower', aspect='auto', extent=[0, Z.shape[1], 0, Z.shape[0]],\n",
    "                   cmap=matplotlib.cm.gray)\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])\n",
    "    ax[idx].set_title(idx, fontsize=8)\n",
    "    if idx % NCOLS == 0:\n",
    "        ax[idx].set_yticks(f0_idx)\n",
    "        ax[idx].set_yticklabels(f0_labels)\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        ax[idx].set_xticks(low_harm_idx)\n",
    "        ax[idx].set_xticklabels(low_harm_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_bin_values = np.array([coarse_f0_bins[idx]\n",
    "                          for idx in np.unique(output_dict['f0_label_coarse'])])\n",
    "low_harm_values = np.unique(output_dict['low_harm'])\n",
    "\n",
    "figsize=(2.6*0.85, 2.4*.85)\n",
    "fontsize_labels=14\n",
    "fontsize_legend=13\n",
    "fontsize_ticks=12\n",
    "\n",
    "idx_list = [10, 22] # Relu_1\n",
    "# idx_list = [12, 99] # Relu_3\n",
    "# idx_list = [340, 508] # Relu_5\n",
    "\n",
    "for idx in idx_list:\n",
    "    \n",
    "    Z = tuning_tensor[:, :, idx].T\n",
    "    xbin = low_harm_values\n",
    "    ybin = f0_bin_values\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "    \n",
    "    ax.imshow(Z, origin='lower', aspect='auto', extent=[0, Z.shape[1], 0, Z.shape[0]],\n",
    "               cmap=matplotlib.cm.gray)\n",
    "        \n",
    "    ax.set_xlabel('Lowest harm.', fontsize=fontsize_labels)\n",
    "    ax.set_ylabel('F0 (Hz)', fontsize=fontsize_labels)\n",
    "    \n",
    "    lh_idx = np.linspace(0, xbin.shape[0]-2, num=5, dtype=int)\n",
    "    lh_labels = ['{:.0f}'.format(xbin[idx]) for idx in lh_idx]\n",
    "    ax.set_xticks(lh_idx)\n",
    "    ax.set_xticklabels(lh_labels)\n",
    "    \n",
    "    f0_idx = np.linspace(0, ybin.shape[0]-1, num=5, dtype=int)\n",
    "    f0_labels = ['{:.0f}'.format(ybin[idx]) for idx in f0_idx]\n",
    "    ax.set_yticks(f0_idx)\n",
    "    ax.set_yticklabels(f0_labels)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize_ticks, length=4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "#     save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_10_17_APAN_poster/'\n",
    "#     save_fn = os.path.join(save_dir, 'neurophysiology_relu1_unit{:03d}.pdf'.format(idx))\n",
    "#     print(save_fn)\n",
    "#     fig.savefig(save_fn, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
