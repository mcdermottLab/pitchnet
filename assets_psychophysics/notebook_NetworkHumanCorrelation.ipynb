{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : bernox2005 ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_bernox2005(average_conditions=True)\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v00/arch_*/EVAL_bernox2005_FixedFilter_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_bernox2005(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(valid_metric_list, human_comparison_metric_list, 'k.')\n",
    "plt.xlabel('validation_accuracy')\n",
    "plt.ylabel('model-human comparison metric')\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats\n",
    "print(scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE PLOTS : bernox2005 ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_threshold_plot(ax, results_dict, title_str=None, legend_on=True,\n",
    "                        sine_plot_kwargs={}, rand_plot_kwargs={},\n",
    "                        xlabel='Lowest harmonic number',\n",
    "                        ylabel='F0 discrimination threshold (%F0)'):\n",
    "    phase_mode_list = np.array(results_dict['phase_mode'])\n",
    "    low_harm_list = np.array(results_dict['low_harm'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    unique_phase_modes = np.unique(phase_mode_list)\n",
    "    for phase_mode in unique_phase_modes:\n",
    "        x = low_harm_list[phase_mode_list == phase_mode]\n",
    "        y = f0dl_list[phase_mode_list == phase_mode]\n",
    "        \n",
    "        if phase_mode == 0:\n",
    "            plot_kwargs = {'label': 'sine', 'color': 'b', 'ls':'-', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(sine_plot_kwargs)\n",
    "        else:\n",
    "            plot_kwargs = {'label': 'rand', 'color': 'b', 'ls':'--', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(rand_plot_kwargs)\n",
    "        \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1e-1, 3e2])\n",
    "    ax.set_xlim([0, 32])\n",
    "    ax.set_xlabel(xlabel, fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    if title_str is not None: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower right', frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'n_layers={:d}, valid_acc={:.4f},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        arch_stat_list[model_idx],\n",
    "        valid_metric_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_threshold_plot(ax, human_results_dict, title_str=None, legend_on=False,\n",
    "                        sine_plot_kwargs={'color':'r', 'lw':0.5}, rand_plot_kwargs={'color':'r', 'lw':0.5})\n",
    "    make_threshold_plot(ax, results_dict, title_str=title_str, legend_on=True,\n",
    "                        sine_plot_kwargs={'color':'k', 'lw':2}, rand_plot_kwargs={'color':'b', 'lw':2},\n",
    "                        ylabel='F0DL (%F0)')\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_08_28_archSearch00_RSBpsychophysics/2019AUG28_arch_search_v00_bernox2005_nlayers8.pdf', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : transposed tones ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_transposedtones()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v00/arch_*/EVAL_oxenham2004_080to320Hz_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_transposedtones(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(valid_metric_list, human_comparison_metric_list, 'k.')\n",
    "plt.xlabel('validation_accuracy')\n",
    "plt.ylabel('model-human comparison metric')\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats\n",
    "print(scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE PLOTS : transposed tones ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_TT_threshold_plot(ax, results_dict, title_str=None, legend_on=True):\n",
    "    f0_ref = np.array(results_dict['f0_ref'])\n",
    "    f_carrier_list = np.array(results_dict['f_carrier'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    unique_f_carrier_list = np.unique(f_carrier_list)\n",
    "    for f_carrier in unique_f_carrier_list:\n",
    "        x = f0_ref[f_carrier_list == f_carrier]\n",
    "        y = f0dl_list[f_carrier_list == f_carrier]\n",
    "        \n",
    "        if f_carrier > 0:\n",
    "            label = '{}-Hz TT'.format(int(f_carrier))\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'w'}\n",
    "            if int(f_carrier) == 10080: plot_kwargs['marker'] = 'D'\n",
    "            if int(f_carrier) == 6350: plot_kwargs['marker'] = '^'\n",
    "            if int(f_carrier) == 4000: plot_kwargs['marker'] = 's'\n",
    "        else:\n",
    "            label = 'Pure tone'\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'k'}\n",
    "            \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([5e-1, 3e1])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim([40, 500])\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency difference (%)', fontsize=10)\n",
    "    if title_str is not None: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower left', frameon=False, fontsize=8, handlelength=0)\n",
    "\n",
    "\n",
    "        \n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'n_layers={:d}, valid_acc={:.4f},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        arch_stat_list[model_idx],\n",
    "        valid_metric_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_TT_threshold_plot(ax, results_dict, title_str=title_str, legend_on=True)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : freq-shifted complexes ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v00/arch_*/EVAL_mooremoore2003_080to480Hz_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_freqshiftedcomplexes(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':False, 'metric':'pearsonr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(valid_metric_list, human_comparison_metric_list, 'k.')\n",
    "plt.xlabel('validation_accuracy')\n",
    "plt.ylabel('model-human comparison metric')\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats\n",
    "print(scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE PLOTS : freq-shifted complexes ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_freqshiftedcomplexes_plot(ax, results_dict, title_str=None, legend_on=True):\n",
    "    key_to_label_map={5:'RES', 11:'INT', 16:'UNRES'}\n",
    "    filter_key='spectral_envelope_centered_harmonic'\n",
    "    for key in sorted(results_dict[filter_key].keys()):\n",
    "        xval = results_dict[filter_key][key]['f0_shift']\n",
    "        yval = results_dict[filter_key][key]['f0_pred_shift_median']\n",
    "        yerr = results_dict[filter_key][key]['f0_pred_shift_stddev']\n",
    "        ax.plot(xval, yval, '.-', label=key_to_label_map.get(key, key))\n",
    "\n",
    "    if legend_on: ax.legend(loc=2, frameon=False, fontsize=10)\n",
    "    if title_str: ax.set_title(title_str, fontsize=10)\n",
    "    ax.set_xlabel('Component shift (%F0)', fontsize=10)\n",
    "    ax.set_ylabel('Shift in pred F0 (%F0)', fontsize=10)\n",
    "    ax.set_xlim([-0.5, 24.5])\n",
    "    ax.set_ylim([-4, 12])\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'n_layers={:d}, valid_acc={:.4f},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        arch_stat_list[model_idx],\n",
    "        valid_metric_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_freqshiftedcomplexes_plot(ax, results_dict, title_str=title_str, legend_on=True)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : mistuned harmonics ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_mistunedharmonics()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Mon/msaddler/pitchnet/saved_models/arch_search_v00/arch_*/EVAL_MistunedHarm_v00_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_mistunedharmonics(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_bar_graph={}, kwargs_compare={'log_scale':False, 'metric':'pearsonr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(valid_metric_list, human_comparison_metric_list, 'k.')\n",
    "plt.xlabel('validation_accuracy')\n",
    "plt.ylabel('model-human comparison metric')\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats\n",
    "print(scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE PLOTS : mistuned harmonics ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0,\n",
    "                                      pitch_shift_key='f0_pred_pct_median',\n",
    "                                      title_str=None, legend_on=True, barwidth=0.12):\n",
    "    '''\n",
    "    '''\n",
    "    bar_graph_results_dict = util_human_model_comparison.get_mistuned_harmonics_bar_graph_results_dict(\n",
    "        results_dict,\n",
    "        mistuned_pct=mistuned_pct,\n",
    "        pitch_shift_key=pitch_shift_key,\n",
    "        harmonic_list=[1,2,3,4,5,6])\n",
    "\n",
    "    num_groups = len(bar_graph_results_dict.keys())\n",
    "    group_xoffsets = np.arange(num_groups) - np.mean(np.arange(num_groups))\n",
    "    \n",
    "    for group_idx, group_key in enumerate(sorted(bar_graph_results_dict.keys())):\n",
    "        bars_per_group = len(bar_graph_results_dict[group_key]['f0_ref'])\n",
    "        xvals = np.arange(bars_per_group)\n",
    "        yvals = np.array(bar_graph_results_dict[group_key][pitch_shift_key])\n",
    "        \n",
    "        xvals = xvals + barwidth*group_xoffsets[group_idx]\n",
    "        ax.bar(xvals, yvals, width=barwidth, edgecolor='white', label=group_key)\n",
    "\n",
    "    base_xvals = np.arange(bars_per_group)\n",
    "    f0_ref_values = bar_graph_results_dict[group_key]['f0_ref']\n",
    "    \n",
    "    if title_str: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='upper right', frameon=False, fontsize=8, handlelength=0.5)\n",
    "    ax.set_xlim([barwidth*group_xoffsets[0]-0.5,\n",
    "                 np.max(base_xvals) + barwidth*group_xoffsets[-1] + 1])\n",
    "    ax.set_xlabel('F0 (Hz)')\n",
    "    ax.set_xticks(base_xvals)\n",
    "    ax.set_xticklabels(f0_ref_values)\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'n_layers={:d}, valid_acc={:.4f},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        arch_stat_list[model_idx],\n",
    "        valid_metric_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0,\n",
    "                                      pitch_shift_key='f0_pred_pct_median',\n",
    "                                      title_str=title_str, legend_on=True, barwidth=0.12)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bernox2005\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_bernox2005(average_conditions=True)\n",
    "\n",
    "\n",
    "def make_threshold_plot(ax, results_dict, title_str=None, legend_on=True,\n",
    "                        sine_plot_kwargs={}, rand_plot_kwargs={},\n",
    "                        xlabel='Lowest harmonic number',\n",
    "                        ylabel='F0 discrimination threshold (%F0)'):\n",
    "    phase_mode_list = np.array(results_dict['phase_mode'])\n",
    "    low_harm_list = np.array(results_dict['low_harm'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    unique_phase_modes = np.unique(phase_mode_list)\n",
    "    for phase_mode in unique_phase_modes:\n",
    "        x = low_harm_list[phase_mode_list == phase_mode]\n",
    "        y = f0dl_list[phase_mode_list == phase_mode]\n",
    "        \n",
    "        if phase_mode == 0:\n",
    "            plot_kwargs = {'label': 'sine', 'color': 'b', 'ls':'-', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(sine_plot_kwargs)\n",
    "        else:\n",
    "            plot_kwargs = {'label': 'rand', 'color': 'b', 'ls':'--', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(rand_plot_kwargs)\n",
    "        \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1e-1, 3e2])\n",
    "    ax.set_xlim([0, 32])\n",
    "    ax.set_xlabel(xlabel, fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    if title_str is not None: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower right', frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "make_threshold_plot(ax, human_results_dict, title_str=None, legend_on=True,\n",
    "                    sine_plot_kwargs={}, rand_plot_kwargs={},\n",
    "                    xlabel='Lowest harmonic number',\n",
    "                    ylabel='F0 discrimination threshold (%F0)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "util_human_model_comparison.compare_bernox2005(\n",
    "    human_results_dict, human_results_dict,\n",
    "    kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'dist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposed tones\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_transposedtones()\n",
    "\n",
    "\n",
    "def make_TT_threshold_plot(ax, results_dict, title_str=None, legend_on=True):\n",
    "    f0_ref = np.array(results_dict['f0_ref'])\n",
    "    f_carrier_list = np.array(results_dict['f_carrier'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    unique_f_carrier_list = np.unique(f_carrier_list)\n",
    "    for f_carrier in unique_f_carrier_list:\n",
    "        x = f0_ref[f_carrier_list == f_carrier]\n",
    "        y = f0dl_list[f_carrier_list == f_carrier]\n",
    "        \n",
    "        if f_carrier > 0:\n",
    "            label = '{}-Hz TT'.format(int(f_carrier))\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'w'}\n",
    "            if int(f_carrier) == 10080: plot_kwargs['marker'] = 'D'\n",
    "            if int(f_carrier) == 6350: plot_kwargs['marker'] = '^'\n",
    "            if int(f_carrier) == 4000: plot_kwargs['marker'] = 's'\n",
    "        else:\n",
    "            label = 'Pure tone'\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'k'}\n",
    "            \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([5e-1, 3e1])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim([40, 500])\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency difference (%)', fontsize=10)\n",
    "    if title_str is not None: ax.set_title(model_name, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower left', frameon=False, fontsize=8, handlelength=0)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "make_TT_threshold_plot(ax, human_results_dict, title_str=None, legend_on=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq-shifted complexes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes()\n",
    "results_dict_list = [human_results_dict]\n",
    "\n",
    "\n",
    "for results_dict in results_dict_list:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,3))\n",
    "    key_to_label_map={5:'RES', 11:'INT', 16:'UNRES'}\n",
    "    filter_key='spectral_envelope_centered_harmonic'\n",
    "    for key in sorted(results_dict[filter_key].keys()):\n",
    "        xval = results_dict[filter_key][key]['f0_shift']\n",
    "        yval = results_dict[filter_key][key]['f0_pred_shift_median']\n",
    "        \n",
    "        assert results_dict[filter_key][key]['f0_pred_shift_median'] == results_dict[filter_key][key]['f0_pred_shift_mean']\n",
    "        \n",
    "        yerr = results_dict[filter_key][key]['f0_pred_shift_stddev']\n",
    "        ax.plot(xval, yval, '.-', label=key_to_label_map.get(key, key))\n",
    "\n",
    "    ax.legend(loc=2, frameon=False)\n",
    "    ax.set_xlabel('Component shift (%F0)')\n",
    "    ax.set_ylabel('Shift in predicted F0 (%F0)')\n",
    "    ax.set_xlim([-0.5, 24.5])\n",
    "    ax.set_ylim([-4, 12])\n",
    "    plt.show()\n",
    "\n",
    "human_results_dict\n",
    "human_results_dict['spectral_envelope_centered_harmonic'][5]\n",
    "\n",
    "util_human_model_comparison.compare_freqshiftedcomplexes(human_results_dict, human_results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistuned harmonics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_mistunedharmonics()\n",
    "results_dict_list = [human_results_dict]\n",
    "\n",
    "fn_results_dict = '/om2/user/msaddler/pitchnet/saved_models/PND_v04_JWSS_halfbandpass_classification2/EVAL_MistunedHarm_v00_bestckpt_results_dict.json'\n",
    "with open(fn_results_dict) as f:\n",
    "    results_dict = json.load(f)\n",
    "\n",
    "results_dict_list.append(results_dict)\n",
    "\n",
    "\n",
    "def make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0,\n",
    "                                      pitch_shift_key='f0_pred_pct_median',\n",
    "                                      legend_on=True, barwidth=0.12):\n",
    "    '''\n",
    "    '''\n",
    "    bar_graph_results_dict = util_human_model_comparison.get_mistuned_harmonics_bar_graph_results_dict(\n",
    "        results_dict,\n",
    "        mistuned_pct=mistuned_pct,\n",
    "        pitch_shift_key=pitch_shift_key,\n",
    "        harmonic_list=[1,2,3,4,5,6])\n",
    "\n",
    "    num_groups = len(bar_graph_results_dict.keys())\n",
    "    group_xoffsets = np.arange(num_groups) - np.mean(np.arange(num_groups))\n",
    "    \n",
    "    for group_idx, group_key in enumerate(sorted(bar_graph_results_dict.keys())):\n",
    "        bars_per_group = len(bar_graph_results_dict[group_key]['f0_ref'])\n",
    "        xvals = np.arange(bars_per_group)\n",
    "        yvals = np.array(bar_graph_results_dict[group_key][pitch_shift_key])\n",
    "        \n",
    "        xvals = xvals + barwidth*group_xoffsets[group_idx]\n",
    "        ax.bar(xvals, yvals, width=barwidth, edgecolor='white', label=group_key)\n",
    "\n",
    "    base_xvals = np.arange(bars_per_group)\n",
    "    f0_ref_values = bar_graph_results_dict[group_key]['f0_ref']\n",
    "    \n",
    "    ax.set_xlim([barwidth*group_xoffsets[0]-0.5,\n",
    "                 np.max(base_xvals) + barwidth*group_xoffsets[-1] + 1])\n",
    "    ax.set_xlabel('F0 (Hz)')\n",
    "    ax.set_xticks(base_xvals)\n",
    "    ax.set_xticklabels(f0_ref_values)\n",
    "    \n",
    "    if legend_on: ax.legend(loc='upper right', frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 3\n",
    "NROWS = int(np.ceil(len(results_dict_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(4*NCOLS, 3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for idx, results_dict in enumerate(results_dict_list):\n",
    "    ax = ax_arr[idx]\n",
    "    make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0)\n",
    "    \n",
    "for idx in range(len(results_dict_list), len(ax_arr)): ax_arr[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "util_human_model_comparison.get_mistuned_harmonics_bar_graph_results_dict(results_dict)\n",
    "\n",
    "util_human_model_comparison.compare_mistunedharmonics(\n",
    "    human_results_dict, results_dict_list[0],\n",
    "    kwargs_bar_graph={}, kwargs_compare={'log_scale':False, 'metric':'spearmanr'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt-phase complexes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import f0dl_bernox\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_altphasecomplexes()\n",
    "results_dict_list = [human_results_dict]\n",
    "\n",
    "# results_dict_list = util_human_model_comparison.get_human_results_dict_altphasecomplexes(average_conditions=False)\n",
    "\n",
    "NCOLS = 3\n",
    "NROWS = int(np.ceil(len(results_dict_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(3.5*NCOLS, 3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for idx, results_dict in enumerate(results_dict_list):\n",
    "    ax = ax_arr[idx]\n",
    "    \n",
    "    for key in sorted(results_dict['filter_fl_bin_means'].keys()):\n",
    "        ax.plot(results_dict['f0_bin_centers'], results_dict['filter_fl_bin_means'][key], 'o-', label=key)\n",
    "    \n",
    "    ax.legend(loc=0, frameon=False, handlelength=2, markerscale=0, fontsize=8)\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "\n",
    "for idx in range(len(results_dict_list), len(ax_arr)): ax_arr[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
