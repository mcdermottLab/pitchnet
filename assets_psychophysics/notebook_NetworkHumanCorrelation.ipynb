{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : averaging psychophysical results across architectures ###\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import f0dl_bernox\n",
    "import util_human_model_comparison\n",
    "import util_psychophysics_figures\n",
    "importlib.reload(util_psychophysics_figures)\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_f0_error(valid_pred_fn,\n",
    "                  f0_label_true_key='f0',\n",
    "                  f0_label_pred_key='f0_label:labels_pred',\n",
    "                  f0_error_key='f0_pct_error_median'):\n",
    "    '''\n",
    "    '''\n",
    "    assert 'results_dict' not in valid_pred_fn\n",
    "    results_dict_fn = valid_pred_fn.replace('.json', '_results_dict.json')\n",
    "    if os.path.exists(results_dict_fn):\n",
    "        with open(results_dict_fn, 'r') as f:\n",
    "            results_dict = json.load(f)\n",
    "    else:\n",
    "        with open(valid_pred_fn, 'r') as f:\n",
    "            valid_pred_dict = json.load(f)\n",
    "        valid_pred_dict[f0_label_true_key] = np.array(valid_pred_dict[f0_label_true_key])\n",
    "        valid_pred_dict[f0_label_pred_key] = np.array(valid_pred_dict[f0_label_pred_key])\n",
    "        valid_pred_dict = f0dl_bernox.add_f0_estimates_to_expt_dict(valid_pred_dict,\n",
    "                                                                    f0_label_true_key=f0_label_true_key,\n",
    "                                                                    f0_label_pred_key=f0_label_pred_key,\n",
    "                                                                    kwargs_f0_bins={},\n",
    "                                                                    kwargs_f0_octave={},\n",
    "                                                                    kwargs_f0_normalization={},\n",
    "                                                                    kwargs_f0_prior={})\n",
    "        f0_true = valid_pred_dict['f0']\n",
    "        f0_pred = valid_pred_dict['f0_pred']\n",
    "        f0_error = 100.0 * np.abs(f0_pred - f0_true) / f0_true\n",
    "        results_dict = {\n",
    "            'f0_pct_error_median': np.median(f0_error),\n",
    "            'f0_pct_error_mean': np.mean(f0_error)\n",
    "        }\n",
    "        with open(results_dict_fn, 'w') as f:\n",
    "            json.dump(results_dict, f, sort_keys=True)\n",
    "    return results_dict[f0_error_key]\n",
    "\n",
    "\n",
    "### Specify scope of all models to compare (regex must grab all model output directories)\n",
    "regex_model_dir = '/om/scratch/*/msaddler/pitchnet/saved_models/arch_search_v01/arch_*/'\n",
    "# regex_model_dir = '/om/scratch/*/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/'\n",
    "# regex_model_dir = '/om/scratch/*/msaddler/pitchnet/saved_models/IHC0050Hz_arch_search_v01_arch_0302_manipulations/arch_*/'\n",
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "basename_arch_config = 'brain_arch.json'\n",
    "basename_valid_pred = 'EVAL_validation_bestckpt.json'\n",
    "\n",
    "### Specify results_dict basenames for each experiment\n",
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_bernox2005_FixedFilter_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_oxenham2004_080to320Hz_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_mooremoore2003_080to480Hz_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_MistunedHarm_v00_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_AltPhase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict for each experiment\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'transposedtones',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'altphasecomplexes'\n",
    "]\n",
    "list_valid_metric = []\n",
    "list_f0_error = []\n",
    "list_model_dir = []\n",
    "disp_step = 100\n",
    "\n",
    "for idx, model_dir in enumerate(sorted(glob.glob(regex_model_dir))):\n",
    "    fn_valid_metric = os.path.join(model_dir, basename_valid_metrics)\n",
    "    fn_arch_config = os.path.join(model_dir, basename_arch_config)\n",
    "    fn_valid_pred = os.path.join(model_dir, basename_valid_pred)\n",
    "    fn_result_dict = {}\n",
    "    for ek in experiment_keys:\n",
    "        fn_result_dict[ek] = os.path.join(model_dir, experiment_to_basename_map[ek])\n",
    "    \n",
    "    include_model_flag = True\n",
    "    if not os.path.exists(fn_valid_metric): include_model_flag = False\n",
    "    if not os.path.exists(fn_arch_config): include_model_flag = False\n",
    "    for ek in experiment_keys:\n",
    "        if not os.path.exists(fn_result_dict[ek]):\n",
    "            include_model_flag = False \n",
    "    \n",
    "    if include_model_flag:\n",
    "        list_model_dir.append(model_dir)\n",
    "        list_valid_metric.append(calc_best_metric(fn_valid_metric))\n",
    "        if os.path.exists(fn_valid_pred):\n",
    "            list_f0_error.append(calc_f0_error(fn_valid_pred))\n",
    "    \n",
    "    if idx % disp_step == 0:\n",
    "        print(model_dir, include_model_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(util_psychophysics_figures)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "\n",
    "# sort_idx = np.flip(np.argsort(list_valid_metric))\n",
    "sort_idx = np.argsort(list_f0_error)\n",
    "sorted_list_valid_metric = np.array(list_valid_metric)[sort_idx]\n",
    "sorted_list_f0_error = np.array(list_f0_error)[sort_idx]\n",
    "sorted_list_model_dir = np.array(list_model_dir)[sort_idx]\n",
    "top_model_dirs = sorted_list_model_dir[352:392]\n",
    "# top_model_dirs = sorted_list_model_dir[:]\n",
    "print(len(top_model_dirs))\n",
    "\n",
    "experiment_to_plot_fcn_map = {\n",
    "    'bernox2005': util_psychophysics_figures.make_bernox_threshold_plot,\n",
    "    'transposedtones': util_psychophysics_figures.make_TT_threshold_plot,\n",
    "    'freqshiftedcomplexes': util_psychophysics_figures.make_freqshiftedcomplexes_plot,\n",
    "    'mistunedharmonics': util_psychophysics_figures.make_mistuned_harmonics_bar_graph,\n",
    "    'altphasecomplexes': util_psychophysics_figures.make_altphase_histogram_plot,\n",
    "}\n",
    "\n",
    "top_model_results_dicts = {key: [] for key in experiment_keys}\n",
    "for key in experiment_keys:\n",
    "    for model_dir in top_model_dirs:\n",
    "        results_dict_fn = os.path.join(model_dir, experiment_to_basename_map[key])\n",
    "        with open(results_dict_fn) as f:\n",
    "            top_model_results_dicts[key].append(json.load(f))\n",
    "\n",
    "results_dicts = top_model_results_dicts\n",
    "\n",
    "\n",
    "NROWS = len(experiment_keys)\n",
    "NCOLS = 1\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(4*NCOLS, 3*NROWS))\n",
    "\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "for ax_idx, key in enumerate(experiment_keys):\n",
    "    plot_fcn = experiment_to_plot_fcn_map[key]\n",
    "    kwargs = {\n",
    "        'include_yerr': True,\n",
    "        'kwargs_bootstrap': {}\n",
    "    }\n",
    "    if ('bernox' in key) or ('transposed' in key):\n",
    "        kwargs['threshold_cap'] = 100\n",
    "    if ('freqshifted' in key) or ('mistuned' in key):\n",
    "        kwargs['use_relative_shift'] = True\n",
    "    plot_fcn(ax[ax_idx], results_dicts[key], **kwargs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2020_02_03_pitchnet_paper_figures/'\n",
    "# save_fn = os.path.join(save_dir, 'all_psychophysics____arch_search_v01_rank352to392_by_median_f0_error.pdf')\n",
    "# fig.savefig(save_fn, bbox_inches='tight')\n",
    "# print(save_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "correlation, pvalue = scipy.stats.spearmanr(list_valid_metric, list_f0_error)\n",
    "\n",
    "plot_kwargs = {\n",
    "    'marker': '.',\n",
    "    'ms': 3,\n",
    "    'ls': '',\n",
    "    'color': 'k'\n",
    "}\n",
    "\n",
    "fig, ax_arr = plt.subplots(nrows=1, ncols=2, figsize=(6, 2.5), sharey=True)\n",
    "\n",
    "ax_arr[0].set_yticks(np.arange(0.5, 1.2, 0.05), minor=True)\n",
    "ax_arr[0].set_yticks(np.arange(0.5, 1.2, 0.1), minor=False)\n",
    "ax_arr[0].grid(color='k', linestyle='-', linewidth=0.1, which='both')\n",
    "ax_arr[0].plot(list_valid_metric, list_f0_error, **plot_kwargs, label='r={:.3f}'.format(correlation))\n",
    "ax_arr[0].set_ylim([0.5, 1.2])\n",
    "ax_arr[0].set_xlim([0.1, 0.26])\n",
    "ax_arr[0].set_ylabel('Median f0 error (%)')\n",
    "ax_arr[0].set_xlabel('Validation accuracy')\n",
    "ax_arr[0].legend(loc='upper right')\n",
    "\n",
    "sort_idx = np.argsort(list_f0_error)\n",
    "ax_arr[1].set_yticks(np.arange(0.5, 1.2, 0.05), minor=True)\n",
    "ax_arr[1].set_yticks(np.arange(0.5, 1.2, 0.1), minor=False)\n",
    "ax_arr[1].grid(color='k', linestyle='-', linewidth=0.1, which='both')\n",
    "ax_arr[1].plot(np.arange(0, len(sort_idx)), np.array(list_f0_error)[sort_idx], **plot_kwargs)\n",
    "ax_arr[1].set_xlabel('Model rank')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_arch_search_v01_arch_0302_manipulations_validAcc_vs_medianF0Error.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize_labels = 12\n",
    "fontsize_ticks = 12\n",
    "plot_kwargs = {\n",
    "    'marker': '.',\n",
    "    'ms': 3,\n",
    "    'ls': '',\n",
    "    'color': 'k'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 2))\n",
    "\n",
    "ylimits = [0.5, 10.0]\n",
    "xlimits = [0, len(sort_idx)-1]\n",
    "ax.set_xlim(xlimits)\n",
    "ax.set_ylim(ylimits)\n",
    "ax.set_yscale('log')\n",
    "yticks_major = [0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "sort_idx = np.argsort(list_f0_error)\n",
    "ax.set_yticks(yticks_major)\n",
    "ax.set_yticklabels(yticks_major)\n",
    "ax.tick_params(axis='both', labelsize=fontsize_ticks)\n",
    "ax.set_ylabel('Median F0 error (%)', fontsize=fontsize_labels)\n",
    "ax.set_xlabel('Model rank', fontsize=fontsize_labels)\n",
    "\n",
    "ax.grid(color='k', linestyle='-', linewidth=0.1, which='both')\n",
    "ax.plot(np.arange(0, len(sort_idx)), np.array(list_f0_error)[sort_idx], **plot_kwargs)\n",
    "\n",
    "y1 = [ylimits[0], ylimits[0]]\n",
    "y2 = [ylimits[1], ylimits[1]]\n",
    "for xshadelim in [(0,40), (176, 216), (352,392)]:\n",
    "    ax.fill_between(xshadelim, y1, y2, color='k', alpha=0.10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2020_02_03_pitchnet_paper_figures/'\n",
    "# save_fn = os.path.join(save_dir, 'arch_search_v01___model_ranking_by_median_f0_error.pdf')\n",
    "# fig.savefig(save_fn, bbox_inches='tight')\n",
    "# print(save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : bernox2005 ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_bernox2005(average_conditions=True)\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Sat/msaddler/pitchnet/saved_models/IHC0050Hz_arch_search_v01_arch_0302_manipulations/arch_*/EVAL_SOFTMAX_bernox2005_FixedFilter_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    if idx % 50 == 0: print(idx)\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_bernox2005(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "\n",
    "for current_arc_metric in unique_arc_metrics:\n",
    "    IDX = arc_metrics == current_arc_metric\n",
    "    label = '{} conv layers'.format(current_arc_metric)\n",
    "    ax.plot(val_metrics[IDX], hum_metrics[IDX], ls='', marker='.', markersize=6, label=label)\n",
    "\n",
    "ax.set_xlabel('validation_accuracy')\n",
    "ax.set_ylabel('model-human comparison metric (spearmanr)')\n",
    "ax.set_title('Spearman correlation coefficient R={:.04f}'.format(correlation))\n",
    "ax.legend(ncol=2, loc='lower right', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_12_05_PNDv08_archSearch01/2019DEC04_arch_search_v01_bernox2005_NetworkHumanCorrelation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MAKE PLOTS : bernox2005 ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if True:#tmp_arch_stat_list[idx] == 9: #human_comparison_metric_list[idx] < 0.9:#tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "        \n",
    "model_idx_list = model_idx_list[:]\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "#for idx in model_idx_list: print(arch_dict_fn_list[idx])\n",
    "\n",
    "\n",
    "def make_threshold_plot(ax, results_dict, title_str=None, legend_on=True,\n",
    "                        sine_plot_kwargs={}, rand_plot_kwargs={},\n",
    "                        xlabel='Lowest harmonic number',\n",
    "                        ylabel='F0 discrimination threshold (%F0)'):\n",
    "    phase_mode_list = np.array(results_dict['phase_mode'])\n",
    "    low_harm_list = np.array(results_dict['low_harm'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    CAP = 100.0\n",
    "    f0dl_list[f0dl_list > CAP] = CAP\n",
    "    unique_phase_modes = np.unique(phase_mode_list)\n",
    "    for phase_mode in unique_phase_modes:\n",
    "        x = low_harm_list[phase_mode_list == phase_mode]\n",
    "        y = f0dl_list[phase_mode_list == phase_mode]\n",
    "        \n",
    "        if phase_mode == 0:\n",
    "            plot_kwargs = {'label': 'sine', 'color': 'b', 'ls':'-', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(sine_plot_kwargs)\n",
    "        else:\n",
    "            plot_kwargs = {'label': 'rand', 'color': 'b', 'ls':'--', 'lw':2, 'ms':8, 'marker':''}\n",
    "            plot_kwargs.update(rand_plot_kwargs)\n",
    "        \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1e-1, 3e2])\n",
    "    ax.set_xlim([0, 32])\n",
    "    ax.set_xlabel(xlabel, fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    if title_str is not None: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower right', frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'valid_acc={:.4f}. n_layers={:d},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        valid_metric_list[model_idx],\n",
    "        arch_stat_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_threshold_plot(ax, human_results_dict, title_str=None, legend_on=False,\n",
    "                        sine_plot_kwargs={'color':'r', 'lw':0.5}, rand_plot_kwargs={'color':'r', 'lw':0.5})\n",
    "    make_threshold_plot(ax, results_dict, title_str=title_str, legend_on=True,\n",
    "                        sine_plot_kwargs={'color':'k', 'lw':2}, rand_plot_kwargs={'color':'b', 'lw':2},\n",
    "                        ylabel='F0DL (%F0)')\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC20_IHC0050Hz_arch_search_v01_arch_0302_manipulations_bernox2005_sortedByValidAcc.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : transposed tones ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_transposedtones()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Sat/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/EVAL_SOFTMAX_oxenham2004_080to320Hz_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_transposedtones(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "\n",
    "for current_arc_metric in unique_arc_metrics:\n",
    "    IDX = arc_metrics == current_arc_metric\n",
    "    label = '{} conv layers'.format(current_arc_metric)\n",
    "    ax.plot(val_metrics[IDX], hum_metrics[IDX], ls='', marker='.', markersize=6, label=label)\n",
    "\n",
    "ax.set_xlabel('validation_accuracy')\n",
    "ax.set_ylabel('model-human comparison metric (spearmanr)')\n",
    "ax.set_title('Spearman correlation coefficient R={:.04f}'.format(correlation))\n",
    "ax.legend(ncol=2, loc='lower right', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_12_05_PNDv08_archSearch01/2019DEC05_arch_search_v01_TransposedTones_NetworkHumanCorrelation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MAKE PLOTS : transposed tones ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if True:#tmp_arch_stat_list[idx] == 9: #human_comparison_metric_list[idx] < 0.9:#tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "        \n",
    "model_idx_list = model_idx_list[:]\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_TT_threshold_plot(ax, results_dict, title_str=None, legend_on=True):\n",
    "    f0_ref = np.array(results_dict['f0_ref'])\n",
    "    f_carrier_list = np.array(results_dict['f_carrier'])\n",
    "    f0dl_list = np.array(results_dict['f0dl'])\n",
    "    unique_f_carrier_list = np.unique(f_carrier_list)\n",
    "    for f_carrier in unique_f_carrier_list:\n",
    "        x = f0_ref[f_carrier_list == f_carrier]\n",
    "        y = f0dl_list[f_carrier_list == f_carrier]\n",
    "        \n",
    "        if f_carrier > 0:\n",
    "            label = '{}-Hz TT'.format(int(f_carrier))\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'w'}\n",
    "            if int(f_carrier) == 10080: plot_kwargs['marker'] = 'D'\n",
    "            if int(f_carrier) == 6350: plot_kwargs['marker'] = '^'\n",
    "            if int(f_carrier) == 4000: plot_kwargs['marker'] = 's'\n",
    "        else:\n",
    "            label = 'Pure tone'\n",
    "            plot_kwargs = {'label': label, 'color': 'k', 'ls':'-', 'lw':2, 'ms':6,\n",
    "                           'marker':'o', 'markerfacecolor': 'k'}\n",
    "            \n",
    "        if not legend_on: plot_kwargs['label'] = None\n",
    "        ax.plot(x, y, **plot_kwargs)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([5e-1, 3e1])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim([40, 500])\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency difference (%)', fontsize=10)\n",
    "    if title_str is not None: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='lower left', frameon=False, fontsize=8, handlelength=0)\n",
    "\n",
    "\n",
    "        \n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'valid_acc={:.4f}. n_layers={:d},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        valid_metric_list[model_idx],\n",
    "        arch_stat_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_TT_threshold_plot(ax, results_dict, title_str=title_str, legend_on=True)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_arch_search_v01_arch_0302_manipulations_transposedtones_sortedByValidAcc.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : freq-shifted complexes ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import util_human_model_comparison\n",
    "import util_psychophysics_figures\n",
    "importlib.reload(util_psychophysics_figures)\n",
    "\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Sat/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/EVAL_SOFTMAX_mooremoore2003_080to480Hz_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_freqshiftedcomplexes(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_interp={}, kwargs_compare={'log_scale':False, 'metric':'pearsonr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "\n",
    "for current_arc_metric in unique_arc_metrics:\n",
    "    IDX = arc_metrics == current_arc_metric\n",
    "    label = '{} conv layers'.format(current_arc_metric)\n",
    "    ax.plot(val_metrics[IDX], hum_metrics[IDX], ls='', marker='.', markersize=6, label=label)\n",
    "\n",
    "ax.set_xlabel('validation_accuracy')\n",
    "ax.set_ylabel('model-human comparison metric (spearmanr)')\n",
    "ax.set_title('Spearman correlation coefficient R={:.04f}'.format(correlation))\n",
    "ax.legend(ncol=2, loc='lower right', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_12_05_PNDv08_archSearch01/2019DEC05_arch_search_v01_FreqShifted_NetworkHumanCorrelation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MAKE PLOTS : freq-shifted complexes ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if True:#tmp_arch_stat_list[idx] == 9: #human_comparison_metric_list[idx] < 0.9:#tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "        \n",
    "model_idx_list = model_idx_list[:]\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "# def make_freqshiftedcomplexes_plot(ax, results_dict, title_str=None, legend_on=True):\n",
    "#     key_to_label_map={5:'RES', 11:'INT', 16:'UNRES'}\n",
    "#     filter_key='spectral_envelope_centered_harmonic'\n",
    "#     for key in sorted(results_dict[filter_key].keys()):\n",
    "#         xval = results_dict[filter_key][key]['f0_shift']\n",
    "#         yval = results_dict[filter_key][key]['f0_pred_shift_median']\n",
    "#         yerr = results_dict[filter_key][key]['f0_pred_shift_stddev']\n",
    "#         ax.plot(xval, yval, '.-', label=key_to_label_map.get(key, key))\n",
    "\n",
    "#     if legend_on: ax.legend(loc=2, frameon=False, fontsize=10)\n",
    "#     if title_str: ax.set_title(title_str, fontsize=10)\n",
    "#     ax.set_xlabel('Component shift (%F0)', fontsize=10)\n",
    "#     ax.set_ylabel('Shift in pred F0 (%F0)', fontsize=10)\n",
    "#     ax.set_xlim([-0.5, 24.5])\n",
    "#     ax.set_ylim([-4, 12])\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'valid_acc={:.4f}. n_layers={:d},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        valid_metric_list[model_idx],\n",
    "        arch_stat_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "#     make_freqshiftedcomplexes_plot(ax, results_dict, title_str=title_str, legend_on=True)\n",
    "    util_psychophysics_figures.make_freqshiftedcomplexes_plot(ax, results_dict,\n",
    "                                                              use_relative_shift=True,\n",
    "                                                              title_str=title_str,\n",
    "                                                              legend_on=True,\n",
    "                                                              fontsize_title=10,\n",
    "                                                              fontsize_labels=10,\n",
    "                                                              fontsize_legend=8,\n",
    "                                                              fontsize_ticks=8)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_arch_search_v01_arch_0302_manipulations_freqshifted_sortedByValidAcc.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : mistuned harmonics ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_mistunedharmonics()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Sat/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/EVAL_SOFTMAX_MistunedHarm_v00_bestckpt_results_dict.json'\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "    (corr_value, pval) = util_human_model_comparison.compare_mistunedharmonics(\n",
    "        human_results_dict, results_dict,\n",
    "        kwargs_bar_graph={}, kwargs_compare={'log_scale':False, 'metric':'pearsonr'})\n",
    "    \n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "\n",
    "print(len(results_dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.pearsonr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "\n",
    "for current_arc_metric in unique_arc_metrics:\n",
    "    IDX = arc_metrics == current_arc_metric\n",
    "    label = '{} conv layers'.format(current_arc_metric)\n",
    "    ax.plot(val_metrics[IDX], hum_metrics[IDX], ls='', marker='.', markersize=6, label=label)\n",
    "\n",
    "ax.set_xlabel('validation_accuracy')\n",
    "ax.set_ylabel('model-human comparison metric (spearmanr)')\n",
    "ax.set_title('Spearman correlation coefficient R={:.04f}'.format(correlation))\n",
    "ax.legend(ncol=2, loc='lower right', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_12_05_PNDv08_archSearch01/2019DEC05_arch_search_v01_MistunedHarmonics_NetworkHumanCorrelation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MAKE PLOTS : mistuned harmonics ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.flip(np.argsort(valid_metric_list)).tolist()\n",
    "# sort_idx = np.flip(np.argsort(human_comparison_metric_list)).tolist()\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if True:#tmp_arch_stat_list[idx] == 9: #human_comparison_metric_list[idx] < 0.9:#tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "        \n",
    "model_idx_list = model_idx_list[:]\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "def make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0,\n",
    "                                      pitch_shift_key='f0_pred_pct_median',\n",
    "                                      title_str=None, legend_on=True, barwidth=0.12):\n",
    "    '''\n",
    "    '''\n",
    "    bar_graph_results_dict = util_human_model_comparison.get_mistuned_harmonics_bar_graph_results_dict(\n",
    "        results_dict,\n",
    "        mistuned_pct=mistuned_pct,\n",
    "        pitch_shift_key=pitch_shift_key,\n",
    "        harmonic_list=[1,2,3,4,5,6])\n",
    "\n",
    "    num_groups = len(bar_graph_results_dict.keys())\n",
    "    group_xoffsets = np.arange(num_groups) - np.mean(np.arange(num_groups))\n",
    "    \n",
    "    for group_idx, group_key in enumerate(sorted(bar_graph_results_dict.keys())):\n",
    "        bars_per_group = len(bar_graph_results_dict[group_key]['f0_ref'])\n",
    "        xvals = np.arange(bars_per_group)\n",
    "        yvals = np.array(bar_graph_results_dict[group_key][pitch_shift_key])\n",
    "        \n",
    "        xvals = xvals + barwidth*group_xoffsets[group_idx]\n",
    "        ax.bar(xvals, yvals, width=barwidth, edgecolor='white', label=group_key)\n",
    "\n",
    "    base_xvals = np.arange(bars_per_group)\n",
    "    f0_ref_values = bar_graph_results_dict[group_key]['f0_ref']\n",
    "    \n",
    "    if title_str: ax.set_title(title_str, fontsize=10)\n",
    "    if legend_on: ax.legend(loc='upper right', frameon=False, fontsize=8, handlelength=0.5)\n",
    "    ax.set_xlim([barwidth*group_xoffsets[0]-0.5,\n",
    "                 np.max(base_xvals) + barwidth*group_xoffsets[-1] + 1])\n",
    "    ax.set_xlabel('F0 (Hz)')\n",
    "    ax.set_xticks(base_xvals)\n",
    "    ax.set_xticklabels(f0_ref_values)\n",
    "\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'valid_acc={:.4f}. n_layers={:d},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        valid_metric_list[model_idx],\n",
    "        arch_stat_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    make_mistuned_harmonics_bar_graph(ax, results_dict, mistuned_pct=3.0,\n",
    "                                      pitch_shift_key='f0_pred_pct_median',\n",
    "                                      title_str=title_str, legend_on=True, barwidth=0.12)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_arch_search_v01_arch_0302_manipulations_mistunedharmonics_sortedByValidAcc.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : alt-phase complexes ###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "import util_psychophysics_figures\n",
    "import importlib\n",
    "importlib.reload(util_human_model_comparison)\n",
    "importlib.reload(util_psychophysics_figures)\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_altphasecomplexes()\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_num_layers(brain_arch_fn):\n",
    "    with open(brain_arch_fn) as f: brain_arch = json.load(f)\n",
    "    num_conv_layers = 0\n",
    "    for layer_dict in brain_arch:\n",
    "        if layer_dict['layer_type'] == 'tf.layers.conv2d':\n",
    "            num_conv_layers = num_conv_layers + 1\n",
    "    return num_conv_layers\n",
    "\n",
    "\n",
    "results_dict_regex = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/EVAL_SOFTMAX_AltPhase_v01_bestckpt_results_dict.json'\n",
    "results_dict_regex = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01/arch_*/EVAL_SOFTMAX_AltPhase_v01_bestckpt_results_dict.json'\n",
    "\n",
    "results_dict_fn_list = sorted(glob.glob(results_dict_regex))\n",
    "valid_dict_fn_list = []\n",
    "arch_dict_fn_list = []\n",
    "for fn in results_dict_fn_list:\n",
    "    output_dir, _ = os.path.split(fn)\n",
    "    valid_dict_fn_list.append(os.path.join(output_dir, 'validation_metrics.json'))\n",
    "    arch_dict_fn_list.append(os.path.join(output_dir, 'brain_arch.json'))\n",
    "\n",
    "results_dict_list = []\n",
    "valid_metric_list = []\n",
    "arch_stat_list = []\n",
    "human_comparison_metric_list = []\n",
    "for idx, (rdfn, vfn, afn) in enumerate(zip(results_dict_fn_list, valid_dict_fn_list, arch_dict_fn_list)):\n",
    "    results_dict = load_results_dict(rdfn)\n",
    "    results_dict_list.append(results_dict)\n",
    "    valid_metric_list.append(calc_best_metric(vfn))\n",
    "    arch_stat_list.append(calc_num_layers(afn))\n",
    "    \n",
    "#     corr_value, pval = util_human_model_comparison.compare_altphasecomplexes_line(human_results_dict, results_dict)\n",
    "#     human_comparison_metric_list.append(corr_value)\n",
    "\n",
    "    corr_value, pval = util_human_model_comparison.compare_altphasecomplexes_hist(human_results_dict,\n",
    "                                                                                  results_dict,\n",
    "                                                                                  restrict_conditions_filter=[125.0, 1375.0, 3900.0],\n",
    "                                                                                  restrict_conditions_f0=[125.0, 250.0],\n",
    "                                                                                  kwargs_compare={'log_scale':False})\n",
    "    human_comparison_metric_list.append(corr_value)\n",
    "    \n",
    "human_comparison_metric_list = np.array(human_comparison_metric_list)\n",
    "print(human_comparison_metric_list.shape)\n",
    "\n",
    "\n",
    "# human_comparison_metric_list = -np.mean(human_comparison_metric_list, axis=1)\n",
    "# human_comparison_metric_list = -np.sqrt(np.sum(np.square(human_comparison_metric_list), axis=1))\n",
    "# human_comparison_metric_list = -scipy.stats.gmean(human_comparison_metric_list, axis=1)\n",
    "\n",
    "print(len(results_dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.spearmanr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "ax.plot(val_metrics, hum_metrics,\n",
    "        ls='', marker='.', markersize=6, color='k')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "\n",
    "for current_arc_metric in unique_arc_metrics:\n",
    "    IDX = arc_metrics == current_arc_metric\n",
    "    label = '{} conv layers'.format(current_arc_metric)\n",
    "    ax.plot(val_metrics[IDX], hum_metrics[IDX], ls='', marker='.', markersize=6, label=label)\n",
    "\n",
    "ax.set_xlabel('validation_accuracy')\n",
    "ax.set_ylabel('model-human comparison metric')\n",
    "ax.set_title('Spearman correlation coefficient R={:.04f}'.format(correlation))\n",
    "ax.legend(ncol=2, loc='lower right', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('figures/archive_2019_12_05_PNDv08_archSearch01/2019DEC05_arch_search_v01_AltPhase_NetworkHumanCorrelation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "correlation, pvalue = scipy.stats.spearmanr(valid_metric_list, human_comparison_metric_list)\n",
    "\n",
    "val_metrics = np.array(valid_metric_list)\n",
    "hum_metrics = np.array(human_comparison_metric_list)\n",
    "arc_metrics = np.array(arch_stat_list)\n",
    "\n",
    "unique_arc_metrics = np.unique(arc_metrics)\n",
    "\n",
    "x = np.arange(0, 100)\n",
    "y = np.random.randn(x.shape[0])\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "# ax.plot(np.argsort(x), np.argsort(y),\n",
    "#         ls='', marker='.', markersize=6, color='k')\n",
    "# plt.show()\n",
    "\n",
    "np.argsort(x), np.argsort(x)[np.argsort(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### MAKE PLOTS : alt-phase complexes ###\n",
    "\n",
    "tmp_valid_metric_list = valid_metric_list.copy()\n",
    "tmp_arch_stat_list = arch_stat_list.copy()\n",
    "sort_idx = np.argsort(valid_metric_list).tolist()\n",
    "sort_idx = np.argsort(human_comparison_metric_list)\n",
    "\n",
    "model_idx_list = []\n",
    "for idx in sort_idx:\n",
    "    if True:#tmp_arch_stat_list[idx] == 9: #human_comparison_metric_list[idx] < 0.9:#tmp_arch_stat_list[idx] == 6:\n",
    "        model_idx_list.append(idx)\n",
    "        \n",
    "model_idx_list = model_idx_list[-10:]\n",
    "print('generating {} plots'.format(len(model_idx_list)))\n",
    "\n",
    "\n",
    "NCOLS = 6\n",
    "NROWS = int(np.ceil(len(model_idx_list) / NCOLS))\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(0.75*4*NCOLS, 0.75*3*NROWS))\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for ax_idx, model_idx in enumerate(model_idx_list):\n",
    "    \n",
    "    results_dict = results_dict_list[model_idx]\n",
    "    \n",
    "    title_str = 'valid_acc={:.4f}. n_layers={:d},\\nhuman_comparison_metric={:.3f}'.format(\n",
    "        valid_metric_list[model_idx],\n",
    "        arch_stat_list[model_idx],\n",
    "        human_comparison_metric_list[model_idx])\n",
    "    \n",
    "    ax = ax_arr[ax_idx]\n",
    "    util_psychophysics_figures.make_altphase_histogram_plot(ax, results_dict,\n",
    "                                                            title_str=title_str, legend_on=False)\n",
    "#     util_psychophysics_figures.make_altphase_line_plot(ax, results_dict,\n",
    "#                                                        title_str=title_str, legend_on=False)\n",
    "\n",
    "for ax_idx in range(len(model_idx_list), len(ax_arr)): ax_arr[ax_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_arch_search_v01_arch_0302_manipulations_altphase_sortedByValidAcc.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(util_human_model_comparison)\n",
    "human_results_dict = util_human_model_comparison.get_human_results_dict_altphasecomplexes()\n",
    "\n",
    "results_dict = results_dict_list[sort_idx[0]]\n",
    "d = util_human_model_comparison.compare_altphasecomplexes_hist(human_results_dict, results_dict,\n",
    "                                                      restrict_conditions_filter=[125.0, 1375.0, 3900.0],\n",
    "                                                      restrict_conditions_f0=[125.0, 250.0],\n",
    "                                                      kwargs_histogram={},\n",
    "                                                      kwargs_compare={'log_scale':False})\n",
    "print(d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "util_psychophysics_figures.make_altphase_histogram_plot(ax, human_results_dict)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "util_psychophysics_figures.make_altphase_histogram_plot(ax, results_dict)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import glob\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "import util_psychophysics_figures\n",
    "importlib.reload(util_psychophysics_figures)\n",
    "\n",
    "\n",
    "### Specify scope of all models to compare (regex must grab all model output directories)\n",
    "regex_model_dir = '/om/scratch/Sat/msaddler/pitchnet/saved_models/arch_search_v01_arch_0302_manipulations/arch_*/'\n",
    "regex_model_dir = '/om/scratch/Sat/msaddler/pitchnet/saved_models/IHC0050Hz_arch_search_v01_arch_0302_manipulations/arch_*/'\n",
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "basename_arch_config = 'brain_arch.json'\n",
    "\n",
    "### Specify results_dict basenames for each experiment\n",
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_bernox2005_FixedFilter_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_oxenham2004_080to320Hz_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_mooremoore2003_080to480Hz_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_MistunedHarm_v00_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_AltPhase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict for each experiment\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict vs. model results_dict comparison functions\n",
    "experiment_to_compfunc_map = {\n",
    "    'bernox2005': lambda x1, x2: util_human_model_comparison.compare_bernox2005(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'}),\n",
    "    'transposedtones': lambda x1, x2: util_human_model_comparison.compare_transposedtones(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'}),\n",
    "    'freqshiftedcomplexes': lambda x1, x2: util_human_model_comparison.compare_freqshiftedcomplexes(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "    'mistunedharmonics': lambda x1, x2: util_human_model_comparison.compare_mistunedharmonics(\n",
    "        x1, x2, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "    'altphasecomplexes': lambda x1, x2: util_human_model_comparison.compare_altphasecomplexes(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "#     'transposedtones',\n",
    "#     'freqshiftedcomplexes',\n",
    "#     'mistunedharmonics',\n",
    "#     'altphasecomplexes'\n",
    "]\n",
    "list_arch_dict = []\n",
    "list_valid_metric = []\n",
    "list_human_comparison_dict = {ek:[] for ek in experiment_keys}\n",
    "list_model_dir = sorted(glob.glob(regex_model_dir))\n",
    "disp_step = 20\n",
    "\n",
    "for idx, model_dir in enumerate(list_model_dir):\n",
    "    \n",
    "    fn_valid_metric = os.path.join(model_dir, basename_valid_metrics)\n",
    "    fn_arch_config = os.path.join(model_dir, basename_arch_config)\n",
    "    fn_result_dict = {}\n",
    "    for ek in experiment_keys:\n",
    "        fn_result_dict[ek] = os.path.join(model_dir, experiment_to_basename_map[ek])\n",
    "    \n",
    "    include_model_flag = True\n",
    "    if not os.path.exists(fn_arch_config): include_model_flag = False\n",
    "    if not os.path.exists(fn_valid_metric): include_model_flag = False\n",
    "    for ek in experiment_keys:\n",
    "        if not os.path.exists(fn_result_dict[ek]): include_model_flag = False \n",
    "    \n",
    "    if include_model_flag:\n",
    "        with open(fn_arch_config) as f: arch_dict = json.load(f)\n",
    "        list_arch_dict.append(arch_dict)\n",
    "        list_valid_metric.append(calc_best_metric(fn_valid_metric))\n",
    "        for ek in experiment_keys:\n",
    "            human_results_dict = experiment_to_human_results_map[ek]\n",
    "            results_dict = load_results_dict(fn_result_dict[ek])\n",
    "            comparison_metric = experiment_to_compfunc_map[ek](human_results_dict, results_dict)\n",
    "            if len(comparison_metric) == 2:\n",
    "                comparison_metric = comparison_metric[0]\n",
    "            list_human_comparison_dict[ek].append(comparison_metric)\n",
    "    \n",
    "    if idx % disp_step == 0:\n",
    "        print(model_dir, include_model_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_human_comparison_metrics(list_human_comparison_dict,\n",
    "                                     experiment_keys=None):\n",
    "    if experiment_keys is None:\n",
    "        experiment_keys = list(list_human_comparison_dict.keys())\n",
    "    combined_rankings = np.zeros_like(list_human_comparison_dict[experiment_keys[0]])\n",
    "    for ek in experiment_keys:\n",
    "        ek_sort_idx = np.argsort(list_human_comparison_dict[ek])\n",
    "        ek_rankings = np.empty_like(ek_sort_idx)\n",
    "        ek_rankings[ek_sort_idx] = np.arange(0, len(ek_sort_idx))\n",
    "        combined_rankings = combined_rankings + ek_rankings\n",
    "    return combined_rankings / len(experiment_keys)\n",
    "\n",
    "\n",
    "def compute_architecture_stats(arch_dict):\n",
    "    arch_stats = {\n",
    "        'num_conv_layers': 0,\n",
    "        'num_pool_layers': 0,\n",
    "        'num_total_layers': 0,\n",
    "        \n",
    "        'sum_conv_kernel_dim_freqtimefilt': 0,\n",
    "        'sum_conv_kernel_dim_freqtime': 0,\n",
    "        'sum_conv_kernel_dim_freq': 0,\n",
    "        'sum_conv_kernel_dim_time': 0,\n",
    "        'sum_conv_kernel_dim_filt': 0,\n",
    "        'max_conv_kernel_dim_freqtimefilt': 0,\n",
    "        'max_conv_kernel_dim_freqtime': 0,\n",
    "        'max_conv_kernel_dim_freq': 0,\n",
    "        'max_conv_kernel_dim_time': 0,\n",
    "        'max_conv_kernel_dim_filt': 0,\n",
    "        \n",
    "        'mul_pool_stride_dim_freqtime': 1,\n",
    "        'mul_pool_stride_dim_freq': 1,\n",
    "        'mul_pool_stride_dim_time': 1,\n",
    "        'max_pool_stride_dim_freqtime': 0,\n",
    "        'max_pool_stride_dim_freq': 0,\n",
    "        'max_pool_stride_dim_time': 0,\n",
    "        \n",
    "        'layer0_conv_kernel_dim_freqtimefilt': 0,\n",
    "        'layer0_conv_kernel_dim_freqtime': 0,\n",
    "        'layer0_conv_kernel_dim_freq': 0,\n",
    "        'layer0_conv_kernel_dim_time': 0,\n",
    "        'layer0_conv_kernel_dim_filt': 0,\n",
    "        \n",
    "        'layer0_pool_stride_dim_freqtime': 0,\n",
    "        'layer0_pool_stride_dim_freq': 0,\n",
    "        'layer0_pool_stride_dim_time': 0,\n",
    "        \n",
    "        'largest_bottleneck': 10,\n",
    "        \n",
    "        'layer0_conv_kernel_dim_time_over_freq': 0,\n",
    "        'avg_conv_kernel_dim_time_over_freq': 0,\n",
    "        'max_conv_kernel_dim_time_over_freq': 0,\n",
    "        'sum_conv_kernel_dim_time_over_freq': 0,\n",
    "    }\n",
    "    \n",
    "    num_filters_list = []\n",
    "    \n",
    "    for layer in arch_dict:\n",
    "        arch_stats['num_total_layers'] += 1\n",
    "        if 'conv2d' in layer['layer_type']:\n",
    "            arch_stats['num_conv_layers'] += 1\n",
    "            [kernel_dim_freq, kernel_dim_time] = layer['args']['kernel_size']\n",
    "            kernel_dim_filt = layer['args']['filters']\n",
    "            kernel_dim_freqtime = kernel_dim_freq * kernel_dim_time\n",
    "            kernel_dim_freqtimefilt = kernel_dim_freq * kernel_dim_time * kernel_dim_filt\n",
    "            kernel_dim_time_over_freq = kernel_dim_time / kernel_dim_freq\n",
    "            \n",
    "            num_filters_list.append(kernel_dim_filt)\n",
    "            \n",
    "            arch_stats['sum_conv_kernel_dim_freqtimefilt'] += kernel_dim_freqtimefilt\n",
    "            arch_stats['sum_conv_kernel_dim_freqtime'] += kernel_dim_freqtime\n",
    "            arch_stats['sum_conv_kernel_dim_freq'] += kernel_dim_freq\n",
    "            arch_stats['sum_conv_kernel_dim_time'] += kernel_dim_time\n",
    "            arch_stats['sum_conv_kernel_dim_filt'] += kernel_dim_filt\n",
    "            arch_stats['sum_conv_kernel_dim_time_over_freq'] += kernel_dim_time_over_freq\n",
    "            \n",
    "            arch_stats['max_conv_kernel_dim_freqtimefilt'] = max(arch_stats['max_conv_kernel_dim_freqtimefilt'],\n",
    "                                                             kernel_dim_freqtimefilt)\n",
    "            arch_stats['max_conv_kernel_dim_freqtime'] = max(arch_stats['max_conv_kernel_dim_freqtime'],\n",
    "                                                             kernel_dim_freqtime)\n",
    "            arch_stats['max_conv_kernel_dim_freq'] = max(arch_stats['max_conv_kernel_dim_freq'],\n",
    "                                                         kernel_dim_freq)\n",
    "            arch_stats['max_conv_kernel_dim_time'] = max(arch_stats['max_conv_kernel_dim_time'],\n",
    "                                                         kernel_dim_time)\n",
    "            arch_stats['max_conv_kernel_dim_filt'] = max(arch_stats['max_conv_kernel_dim_filt'],\n",
    "                                                         kernel_dim_filt)\n",
    "            arch_stats['max_conv_kernel_dim_time_over_freq'] = max(arch_stats['max_conv_kernel_dim_time_over_freq'],\n",
    "                                                                   kernel_dim_time_over_freq)\n",
    "            \n",
    "            if layer['args']['name'] == 'conv_0':\n",
    "                arch_stats['layer0_conv_kernel_dim_freqtimefilt'] = kernel_dim_freqtimefilt\n",
    "                arch_stats['layer0_conv_kernel_dim_freqtime'] = kernel_dim_freqtime\n",
    "                arch_stats['layer0_conv_kernel_dim_freq'] = kernel_dim_freq\n",
    "                arch_stats['layer0_conv_kernel_dim_time'] = kernel_dim_time\n",
    "                arch_stats['layer0_conv_kernel_dim_filt'] = kernel_dim_filt\n",
    "                arch_stats['layer0_conv_kernel_dim_time_over_freq'] = kernel_dim_time_over_freq\n",
    "            \n",
    "        elif 'pool' in layer['layer_type']:\n",
    "            arch_stats['num_pool_layers'] += 1\n",
    "            [stride_dim_freq, stride_dim_time] = layer['args']['strides']\n",
    "            [pool_dim_freq, pool_dim_time] = layer['args']['pool_size']\n",
    "            stride_dim_freqtime = stride_dim_freq * stride_dim_time\n",
    "            pool_dim_freqtime = pool_dim_freq * pool_dim_time\n",
    "            \n",
    "            arch_stats['mul_pool_stride_dim_freqtime'] *= stride_dim_freqtime\n",
    "            arch_stats['mul_pool_stride_dim_freq'] *= stride_dim_freq\n",
    "            arch_stats['mul_pool_stride_dim_time'] *= stride_dim_time\n",
    "            arch_stats['max_pool_stride_dim_freqtime'] = max(arch_stats['max_pool_stride_dim_freqtime'],\n",
    "                                                             stride_dim_freqtime)\n",
    "            arch_stats['max_pool_stride_dim_freq'] = max(arch_stats['max_pool_stride_dim_freq'],\n",
    "                                                         stride_dim_freq)\n",
    "            arch_stats['max_pool_stride_dim_time'] = max(arch_stats['max_pool_stride_dim_time'],\n",
    "                                                         stride_dim_time)\n",
    "            \n",
    "            if layer['args']['name'] == 'pool_0':\n",
    "                arch_stats['layer0_pool_stride_dim_freqtime'] = stride_dim_freqtime\n",
    "                arch_stats['layer0_pool_stride_dim_freq'] = stride_dim_freq\n",
    "                arch_stats['layer0_pool_stride_dim_time'] = stride_dim_time\n",
    "\n",
    "    for layer_idx in range(1, len(num_filters_list)-1):\n",
    "        bottleneck = np.max(num_filters_list[:layer_idx]) - np.min(num_filters_list[layer_idx:])\n",
    "        arch_stats['largest_bottleneck'] = max(arch_stats['largest_bottleneck'], bottleneck) \n",
    "    \n",
    "    arch_stats['avg_conv_kernel_dim_freqtimefilt'] = arch_stats['sum_conv_kernel_dim_freqtimefilt'] / arch_stats['num_conv_layers']\n",
    "    arch_stats['avg_conv_kernel_dim_freqtime'] = arch_stats['sum_conv_kernel_dim_freqtime'] / arch_stats['num_conv_layers']\n",
    "    arch_stats['avg_conv_kernel_dim_freq'] = arch_stats['sum_conv_kernel_dim_freq'] / arch_stats['num_conv_layers']\n",
    "    arch_stats['avg_conv_kernel_dim_time'] = arch_stats['sum_conv_kernel_dim_time'] / arch_stats['num_conv_layers']\n",
    "    arch_stats['avg_conv_kernel_dim_filt'] = arch_stats['sum_conv_kernel_dim_filt'] / arch_stats['num_conv_layers']\n",
    "    arch_stats['avg_conv_kernel_dim_time_over_freq'] = arch_stats['sum_conv_kernel_dim_time_over_freq'] / arch_stats['num_conv_layers']\n",
    "    \n",
    "    return arch_stats\n",
    "\n",
    "\n",
    "def compute_architecture_stats(arch_dict):\n",
    "    '''\n",
    "    REDO (2019DEC8)\n",
    "    '''\n",
    "    arch_stats = {\n",
    "        'total_conv_layers': 0,\n",
    "        'total_pool_layers': 0,\n",
    "    }\n",
    "    \n",
    "    conv_lidx = 0\n",
    "    pool_lidx = 0\n",
    "    for layer in arch_dict:\n",
    "        if 'conv2d' in layer['layer_type']:\n",
    "            arch_stats['total_conv_layers'] += 1\n",
    "            [conv_dim_freq, conv_dim_time] = layer['args']['kernel_size']\n",
    "            \n",
    "            arch_stats['conv_layer{}_dim_freq'.format(conv_lidx)] = conv_dim_freq\n",
    "            arch_stats['conv_layer{}_dim_time'.format(conv_lidx)] = conv_dim_time\n",
    "            arch_stats['conv_layer{}_dim_time/freq'.format(conv_lidx)] = conv_dim_time / conv_dim_freq\n",
    "            arch_stats['conv_layer{}_dim_time*freq'.format(conv_lidx)] = conv_dim_time * conv_dim_freq\n",
    "            conv_lidx += 1\n",
    "        elif 'pool' in layer['layer_type']:\n",
    "            [pool_dim_freq, pool_dim_time] = layer['args']['pool_size']\n",
    "            [pools_stride_freq, pools_stride_time] = layer['args']['strides']\n",
    "            if pools_stride_freq > 1 or pools_stride_time > 1:\n",
    "                arch_stats['total_pool_layers'] += 1\n",
    "            arch_stats['pool_layer{}_dim_freq'.format(pool_lidx)] = pool_dim_freq\n",
    "            arch_stats['pool_layer{}_dim_time'.format(pool_lidx)] = pool_dim_time\n",
    "            arch_stats['pool_layer{}_dim_time/freq'.format(pool_lidx)] = pool_dim_time / pool_dim_freq\n",
    "            arch_stats['pool_layer{}_dim_time*freq'.format(pool_lidx)] = pool_dim_time * pool_dim_freq\n",
    "            arch_stats['pool_layer{}_stride_freq'.format(pool_lidx)] = pools_stride_freq\n",
    "            arch_stats['pool_layer{}_stride_time'.format(pool_lidx)] = pools_stride_time\n",
    "            arch_stats['pool_layer{}_stride_time/freq'.format(pool_lidx)] = pools_stride_time / pools_stride_freq\n",
    "            arch_stats['pool_layer{}_stride_time*freq'.format(pool_lidx)] = pools_stride_time * pools_stride_freq\n",
    "            pool_lidx += 1\n",
    "    return arch_stats\n",
    "\n",
    "# compute_architecture_stats(list_arch_dict[408])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_human_similarity_ranking = combine_human_comparison_metrics(list_human_comparison_dict,\n",
    "                                                                 experiment_keys=None)#['bernox2005'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list_valid_metric, list_human_similarity_ranking, 'k.')\n",
    "plt.xlabel('valid_metric')\n",
    "plt.ylabel('human_similarity_ranking')\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats\n",
    "print(scipy.stats.spearmanr(list_valid_metric, list_human_similarity_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_human_similarity_ranking = combine_human_comparison_metrics(list_human_comparison_dict,\n",
    "                                                                 experiment_keys=None)#['bernox2005'])\n",
    "list_arch_stat_dict = {}\n",
    "for idx, arch_dict in enumerate(list_arch_dict):\n",
    "    arch_stats = compute_architecture_stats(arch_dict)\n",
    "    if idx == 0:\n",
    "        for key in arch_stats.keys():\n",
    "            list_arch_stat_dict[key] = []\n",
    "    for key in list_arch_stat_dict.keys():\n",
    "        list_arch_stat_dict[key].append(arch_stats[key])\n",
    "        \n",
    "\n",
    "NCOLS = 2\n",
    "NROWS = len(list_arch_stat_dict.keys())\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(6*NCOLS, 3*NROWS))\n",
    "\n",
    "plot_kwargs = {'marker':'.', 'ms':3, 'ls':'', 'color':'k'}\n",
    "fontsize = 12\n",
    "\n",
    "correlation_fcn = lambda x1, x2: list(scipy.stats.spearmanr(x1, x2))\n",
    "\n",
    "for ridx, arch_stat_key in enumerate(sorted(list_arch_stat_dict.keys())):\n",
    "    xval_name, xval = (arch_stat_key, list_arch_stat_dict[arch_stat_key])\n",
    "    yval_name_pair_list = [\n",
    "        ('validation_accuracy', list_valid_metric),\n",
    "        ('human_similarity', list_human_similarity_ranking),\n",
    "    ]\n",
    "    \n",
    "    for cidx, (yval_name, yval) in enumerate(yval_name_pair_list):\n",
    "        \n",
    "        ax[ridx, cidx].plot(xval, yval, **plot_kwargs)\n",
    "        corr_coef, p_val = correlation_fcn(xval, yval)\n",
    "        title_str = 'corr_coef={:.4f}, p_val={:.4f}'.format(corr_coef, p_val)\n",
    "        ax[ridx, cidx].set_title(title_str, fontsize=fontsize)\n",
    "        ax[ridx, cidx].set_xlabel(xval_name, fontsize=fontsize, fontweight='bold')\n",
    "        ax[ridx, cidx].set_ylabel(yval_name, fontsize=fontsize, fontweight='bold')\n",
    "        ax[ridx, cidx].set_xscale('log')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_10_05_archSearch00_parameterAnalysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019OCT03_arch_search_v00_archStat_vs_validAccAndHumanSimilarity_onlyBernox2005.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "list_arch_stat_dict = {}\n",
    "list_arch_val_dict = {}\n",
    "list_arch_hum_dict = {}\n",
    "for idx, arch_dict in enumerate(list_arch_dict):\n",
    "    arch_stats = compute_architecture_stats(arch_dict)\n",
    "    \n",
    "    for key in arch_stats.keys():\n",
    "        tmp_stat = list_arch_stat_dict.get(key, [])\n",
    "        tmp_stat.append(arch_stats[key])\n",
    "        list_arch_stat_dict[key] = tmp_stat\n",
    "        \n",
    "        tmp_val = list_arch_val_dict.get(key, [])\n",
    "        tmp_val.append(list_valid_metric[idx])\n",
    "        list_arch_val_dict[key] = tmp_val\n",
    "        \n",
    "        tmp_hum = list_arch_hum_dict.get(key, [])\n",
    "        tmp_hum_dict = {k: list_human_comparison_dict[k][idx] for k in list_human_comparison_dict.keys()}\n",
    "        tmp_hum.append(tmp_hum_dict)\n",
    "        list_arch_hum_dict[key] = tmp_hum\n",
    "\n",
    "for key in list_arch_hum_dict.keys():\n",
    "    hum_dict = list_arch_hum_dict[key]\n",
    "    new_hum_dict = {}\n",
    "    for ek in hum_dict[0].keys():\n",
    "        new_hum_dict[ek] = [hd[ek] for hd in hum_dict]\n",
    "    \n",
    "    list_arch_hum_dict[key] = combine_human_comparison_metrics(new_hum_dict, experiment_keys=['bernox2005'])\n",
    "    list_arch_val_dict[key] = np.argsort(np.argsort(list_arch_val_dict[key]))\n",
    "\n",
    "for key in list_arch_stat_dict.keys():\n",
    "    assert len(list_arch_stat_dict[key]) == len(list_arch_hum_dict[key])\n",
    "    assert len(list_arch_stat_dict[key]) == len(list_arch_val_dict[key])\n",
    "\n",
    "NCOLS = 4\n",
    "NROWS = int(np.ceil(len(list_arch_stat_dict.keys()) / NCOLS))\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(5*NCOLS, 3*NROWS))\n",
    "ax = ax.flatten()\n",
    "\n",
    "plot_kwargs = {'marker':'.', 'ms':4, 'ls':''}\n",
    "fontsize = 12\n",
    "\n",
    "correlation_fcn = lambda x1, x2: list(scipy.stats.spearmanr(x1, x2))\n",
    "use_log_scale = True\n",
    "\n",
    "for ax_idx, arch_stat_key in enumerate(sorted(list_arch_stat_dict.keys())):\n",
    "    xval_name, xval = (arch_stat_key, np.array(list_arch_stat_dict[arch_stat_key]))\n",
    "    \n",
    "    yval_name_color_list = [\n",
    "        ('val_acc', np.array(list_arch_val_dict[arch_stat_key]), 'k'),\n",
    "        ('hum_sim', np.array(list_arch_hum_dict[arch_stat_key]), 'r'),\n",
    "    ]\n",
    "    \n",
    "    for (yval_name, yval, ycolor) in yval_name_color_list:\n",
    "        corr_coef, p_val = correlation_fcn(xval, yval)\n",
    "        label = '{:s} (spearmanr={:.3f})'.format(yval_name, corr_coef)\n",
    "        ax[ax_idx].plot(xval, yval, color=ycolor, label=label, **plot_kwargs)\n",
    "        \n",
    "        fit_xval = np.unique(xval)\n",
    "        if len(fit_xval) > 1:\n",
    "            if use_log_scale:\n",
    "                fit_yval = np.poly1d(np.polyfit(np.log(xval), yval, 1))(np.log(fit_xval))\n",
    "            else:\n",
    "                fit_yval = np.poly1d(np.polyfit(xval, yval, 1))(fit_yval)\n",
    "\n",
    "            lw = np.abs(10*corr_coef)\n",
    "            ax[ax_idx].plot(fit_xval, fit_yval, color=ycolor, ls='-', lw=lw, ms=0)\n",
    "        \n",
    "    ax[ax_idx].set_xlabel(xval_name, fontsize=fontsize, fontweight='bold')\n",
    "    ax[ax_idx].set_ylabel('model_rank', fontsize=fontsize, fontweight='bold')\n",
    "    if use_log_scale: ax[ax_idx].set_xscale('log')\n",
    "    ax[ax_idx].legend(loc='best', frameon=True, fontsize=fontsize, framealpha=1)\n",
    "\n",
    "for idx in range(len(list_arch_stat_dict.keys()), len(ax)): ax[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2019_12_19_arch_hyperparam_analysis/'\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC08_hyperparam_psychophysics_analyses_arch_search_v01_allPsychophysicalTasks.pdf'), bbox_inches='tight')\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC08_hyperparam_psychophysics_analyses_arch_search_v01_bernox2005.pdf'), bbox_inches='tight')\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_hyperparam_psychophysics_arch_search_v01_arch_0302_manipulations_allPsychophysicalTasks.pdf'), bbox_inches='tight')\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC11_hyperparam_psychophysics_arch_search_v01_arch_0302_manipulations_bernox2005.pdf'), bbox_inches='tight')\n",
    "# fig.savefig(os.path.join(save_dir, '2019DEC20_hyperparam_psychophysics_IHC0050Hz_arch_search_v01_arch_0302_manipulations_bernox2005.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARCHITECTURE SEARCH : Compute all correlations with humans ###\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import f0dl_bernox\n",
    "import util_human_model_comparison\n",
    "import util_psychophysics_figures\n",
    "importlib.reload(util_human_model_comparison)\n",
    "importlib.reload(util_psychophysics_figures)\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    with open(valid_metrics_fn) as f: valid_metrics_dict = json.load(f)\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize: best_metric_value = np.max(metric_values)\n",
    "    else: best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "def calc_f0_error(valid_pred_fn,\n",
    "                  f0_label_true_key='f0',\n",
    "                  f0_label_pred_key='f0_label:labels_pred',\n",
    "                  f0_error_key='f0_pct_error_median'):\n",
    "    '''\n",
    "    '''\n",
    "    assert 'results_dict' not in valid_pred_fn\n",
    "    results_dict_fn = valid_pred_fn.replace('.json', '_results_dict.json')\n",
    "    if os.path.exists(results_dict_fn):\n",
    "        with open(results_dict_fn, 'r') as f:\n",
    "            results_dict = json.load(f)\n",
    "    else:\n",
    "        with open(valid_pred_fn, 'r') as f:\n",
    "            valid_pred_dict = json.load(f)\n",
    "        valid_pred_dict[f0_label_true_key] = np.array(valid_pred_dict[f0_label_true_key])\n",
    "        valid_pred_dict[f0_label_pred_key] = np.array(valid_pred_dict[f0_label_pred_key])\n",
    "        valid_pred_dict = f0dl_bernox.add_f0_estimates_to_expt_dict(valid_pred_dict,\n",
    "                                                                    f0_label_true_key=f0_label_true_key,\n",
    "                                                                    f0_label_pred_key=f0_label_pred_key,\n",
    "                                                                    kwargs_f0_bins={},\n",
    "                                                                    kwargs_f0_octave={},\n",
    "                                                                    kwargs_f0_normalization={},\n",
    "                                                                    kwargs_f0_prior={})\n",
    "        f0_true = valid_pred_dict['f0']\n",
    "        f0_pred = valid_pred_dict['f0_pred']\n",
    "        f0_error = 100.0 * np.abs(f0_pred - f0_true) / f0_true\n",
    "        results_dict = {\n",
    "            'f0_pct_error_median': np.median(f0_error),\n",
    "            'f0_pct_error_mean': np.mean(f0_error)\n",
    "        }\n",
    "        with open(results_dict_fn, 'w') as f:\n",
    "            json.dump(results_dict, f, sort_keys=True)\n",
    "    return results_dict[f0_error_key]\n",
    "\n",
    "\n",
    "\n",
    "### Specify scope of all models to compare (regex must grab all model output directories)\n",
    "regex_model_dir = '/om/scratch/Wed/msaddler/pitchnet/saved_models/arch_search_v01/arch_*/'\n",
    "# regex_model_dir = '/om/scratch/Wed/msaddler/pitchnet/saved_models/IHC0050Hz_arch_search_v01_arch_0302_manipulations/arch_*/'\n",
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "basename_arch_config = 'brain_arch.json'\n",
    "basename_valid_pred = 'EVAL_validation_bestckpt.json'\n",
    "\n",
    "### Specify results_dict basenames for each experiment\n",
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_bernox2005_FixedFilter_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_oxenham2004_080to320Hz_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_mooremoore2003_080to480Hz_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_MistunedHarm_v00_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_AltPhase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict for each experiment\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict vs. model results_dict comparison functions\n",
    "experiment_to_compfunc_map = {\n",
    "    'bernox2005': lambda x1, x2: util_human_model_comparison.compare_bernox2005(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'}),\n",
    "    'transposedtones': lambda x1, x2: util_human_model_comparison.compare_transposedtones(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':True, 'metric':'spearmanr'}),\n",
    "    'freqshiftedcomplexes': lambda x1, x2: util_human_model_comparison.compare_freqshiftedcomplexes(\n",
    "        x1, x2, kwargs_interp={}, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "    'mistunedharmonics': lambda x1, x2: util_human_model_comparison.compare_mistunedharmonics(\n",
    "        x1, x2, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "    'altphasecomplexes': lambda x1, x2: util_human_model_comparison.compare_altphasecomplexes_hist(\n",
    "        x1, x2, kwargs_compare={'log_scale':False, 'metric':'spearmanr'}),\n",
    "}\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'transposedtones',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'altphasecomplexes'\n",
    "]\n",
    "\n",
    "list_model_dir = []\n",
    "list_metric_valid = []\n",
    "list_metric_f0_error = []\n",
    "dict_list_metric_human_comparison = {ek: [] for ek in experiment_keys}\n",
    "disp_step = 10\n",
    "\n",
    "for idx, model_dir in enumerate(sorted(glob.glob(regex_model_dir))):\n",
    "    fn_valid_metric = os.path.join(model_dir, basename_valid_metrics) # Valid metrics file\n",
    "    fn_arch_config = os.path.join(model_dir, basename_arch_config) # Architecture config file\n",
    "    fn_valid_pred = os.path.join(model_dir, basename_valid_pred) # Validation set predictions file\n",
    "    fn_result_dict = {}\n",
    "    for ek in experiment_keys:\n",
    "        fn_result_dict[ek] = os.path.join(model_dir, experiment_to_basename_map[ek]) # Psychophysics results file\n",
    "    \n",
    "    include_model_flag = True\n",
    "    if not os.path.exists(fn_valid_metric): include_model_flag = False\n",
    "    if not os.path.exists(fn_arch_config): include_model_flag = False\n",
    "    if not os.path.exists(fn_valid_pred): include_model_flag = False\n",
    "    for ek in experiment_keys:\n",
    "        if not os.path.exists(fn_result_dict[ek]): include_model_flag = False \n",
    "    \n",
    "    if include_model_flag:\n",
    "        metric_valid = calc_best_metric(fn_valid_metric)\n",
    "        metric_f0_error = calc_f0_error(fn_valid_pred)\n",
    "        for ek in experiment_keys:\n",
    "            human_results_dict = experiment_to_human_results_map[ek]\n",
    "            model_results_dict = load_results_dict(fn_result_dict[ek])\n",
    "            metric_comparison = experiment_to_compfunc_map[ek](human_results_dict, model_results_dict)\n",
    "            if len(metric_comparison) == 2:\n",
    "                metric_comparison = metric_comparison[0]\n",
    "            dict_list_metric_human_comparison[ek].append(metric_comparison)\n",
    "        \n",
    "        list_model_dir.append(model_dir)\n",
    "        list_metric_valid.append(metric_valid)\n",
    "        list_metric_f0_error.append(metric_f0_error)\n",
    "    \n",
    "    if idx % disp_step == 0:\n",
    "        print(model_dir, include_model_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "fontsize_title=12\n",
    "fontsize_labels=12\n",
    "fontsize_legend=12\n",
    "fontsize_ticks=12\n",
    "kwargs = {\n",
    "    'ls': '',\n",
    "    'marker': '.',\n",
    "    'markersize': 4,\n",
    "    'color': 'k',\n",
    "}\n",
    "\n",
    "NROWS = len(experiment_keys)\n",
    "NCOLS = 1\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(4*NCOLS, 3*NROWS), sharex=False, sharey=True)\n",
    "\n",
    "for ax_idx, key in enumerate(experiment_keys):\n",
    "    xvals = 100.0 * np.array(list_metric_valid)\n",
    "    yvals = np.array(dict_list_metric_human_comparison[key])\n",
    "    correlation, pvalue = scipy.stats.spearmanr(xvals, yvals)\n",
    "    label = 'Spearman R = {:+.2f}'.format(correlation)\n",
    "    ax[ax_idx].plot(xvals, yvals, label=label, **kwargs)\n",
    "#     ax[ax_idx].set_xlim([0.02, 0.27])\n",
    "#     ax[ax_idx].set_ylim([-0.8, 1.1])\n",
    "    ax[ax_idx].tick_params(axis='both', labelsize=fontsize_ticks)\n",
    "    ax[ax_idx].legend(loc='lower right', markerscale=0, handlelength=0,\n",
    "                      frameon=False, fontsize=fontsize_legend)\n",
    "    ax[ax_idx].set_xlabel('Model validation set accuracy (%)', fontsize=fontsize_labels)\n",
    "    ax[ax_idx].set_ylabel('Human-model correlation\\n(Spearman R)', fontsize=fontsize_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2020_02_03_pitchnet_paper_figures/'\n",
    "# save_fn = os.path.join(save_dir, 'arch_search_v01___human_model_spearmanr_correlations_all_pscyhophysics.pdf')\n",
    "# fig.savefig(save_fn, bbox_inches='tight')\n",
    "# print(save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
