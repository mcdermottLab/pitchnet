{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import util_human_model_comparison\n",
    "import util_figures_psychophysics\n",
    "\n",
    "sys.path.append('/packages/msutil')\n",
    "import util_figures\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    if not os.path.exists(valid_metrics_fn):\n",
    "        return None\n",
    "    with open(valid_metrics_fn) as f:\n",
    "        valid_metrics_dict = json.load(f)\n",
    "    if metric_key not in valid_metrics_dict.keys():\n",
    "        # If metric_key does not exist in validation_metrics_dict, look for a similarly named key\n",
    "        for available_key in valid_metrics_dict.keys():\n",
    "            if all([mkp in available_key for mkp in metric_key.split(':')]):\n",
    "                metric_key = available_key\n",
    "                break\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize:\n",
    "        best_metric_value = np.max(metric_values)\n",
    "    else:\n",
    "        best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "\n",
    "\n",
    "# Specify list of models to load (each entry can glob multiple models to average across)\n",
    "list_regex_model_dir = [\n",
    "    'human',\n",
    "    '../models/default/arch_????',\n",
    "]\n",
    "\n",
    "# Specify basename for validation metrics\n",
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "\n",
    "# Specify results_dict basenames for each experiment\n",
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_transposedtones_v01_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_freqshifted_v01_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_mistunedharm_v01_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_altphase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "# Specify human results_dict for each experiment\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "# Specify list of experiments to load\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'altphasecomplexes',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'transposedtones',\n",
    "]\n",
    "\n",
    "# Compile list of lists of model psychophysical data to plot grid of results (models-by-experiments) \n",
    "list_list_model_dir = []\n",
    "list_list_valid_metric = []\n",
    "list_dict_results_dicts = []\n",
    "# For each entry in list_regex_model_dir, grab all of the models that are globbed by the regex\n",
    "for regex_model_dir in list_regex_model_dir:\n",
    "    prefix = None\n",
    "    if isinstance(regex_model_dir, tuple):\n",
    "        (regex_model_dir, prefix) = regex_model_dir\n",
    "    list_model_dir = []\n",
    "    list_valid_metric = []\n",
    "    dict_results_dicts = {ek: [] for ek in experiment_keys}\n",
    "    if 'HUMAN' in regex_model_dir.upper():\n",
    "        list_model_dir = 'HUMAN'\n",
    "        list_valid_metric = []\n",
    "        dict_results_dicts = experiment_to_human_results_map\n",
    "    else:\n",
    "        for idx, model_dir in enumerate(sorted(glob.glob(regex_model_dir))):\n",
    "            fn_valid_metric = os.path.join(model_dir, basename_valid_metrics)\n",
    "            fn_result_dict = {\n",
    "                ek: os.path.join(model_dir, experiment_to_basename_map[ek]) for ek in experiment_keys\n",
    "            }\n",
    "            if 'snr_pos' in model_dir:\n",
    "                high_snr_basename = 'EVAL_SOFTMAX_lowharm_v04_bestckpt_results_dict.json'\n",
    "                fn_result_dict['bernox2005'] = os.path.join(model_dir, high_snr_basename)\n",
    "                high_snr_basename = 'EVAL_SOFTMAX_transposedtones_v02_bestckpt_results_dict.json'\n",
    "                fn_result_dict['transposedtones'] = os.path.join(model_dir, high_snr_basename)\n",
    "                print(model_dir)\n",
    "            if prefix is not None:\n",
    "                for k in fn_result_dict.keys():\n",
    "                    fn_result_dict[k] = fn_result_dict[k].replace('EVAL_SOFTMAX', prefix)\n",
    "                    print(fn_result_dict[k])\n",
    "            include_model_flag = True\n",
    "            for ek in experiment_keys:\n",
    "                if not os.path.exists(fn_result_dict[ek]): include_model_flag = False\n",
    "            if include_model_flag:\n",
    "                list_valid_metric.append(calc_best_metric(fn_valid_metric))\n",
    "                list_model_dir.append(model_dir)\n",
    "                # Load results_dict for each model\n",
    "                for ek, results_dict_fn in fn_result_dict.items():\n",
    "                    with open(results_dict_fn) as f:\n",
    "                        dict_results_dicts[ek].append(json.load(f))\n",
    "    \n",
    "    # Add lists of model results to the master list\n",
    "    list_list_valid_metric.append(list_valid_metric)\n",
    "    list_list_model_dir.append(list_model_dir)\n",
    "    list_dict_results_dicts.append(dict_results_dicts)\n",
    "    print(regex_model_dir, len(list_model_dir), list_valid_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_figures)\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "\n",
    "experiment_to_plot_fcn_map = {\n",
    "    'bernox2005': util_figures_psychophysics.make_bernox_threshold_plot,\n",
    "    'transposedtones': util_figures_psychophysics.make_TT_threshold_plot,\n",
    "    'freqshiftedcomplexes': util_figures_psychophysics.make_freqshiftedcomplexes_plot,\n",
    "    'mistunedharmonics': util_figures_psychophysics.make_mistuned_harmonics_line_plot,\n",
    "    'altphasecomplexes': util_figures_psychophysics.make_altphase_histogram_plot,\n",
    "}\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'altphasecomplexes',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'transposedtones',\n",
    "]\n",
    "\n",
    "NROWS = len(experiment_keys)\n",
    "NCOLS = len(list_dict_results_dicts)\n",
    "figsize = (4*NCOLS*0.9, 3*NROWS*0.9)\n",
    "gridspec_kw = {}\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=figsize, gridspec_kw=gridspec_kw)\n",
    "ax = np.array(ax).reshape([NROWS, NCOLS])\n",
    "\n",
    "for c_idx, (dict_results_dicts, list_model_dir) in enumerate(zip(list_dict_results_dicts, list_list_model_dir)):\n",
    "    for r_idx, key in enumerate(experiment_keys):\n",
    "        results_dict_input = dict_results_dicts[key]\n",
    "        plot_fcn = experiment_to_plot_fcn_map[key]\n",
    "        # Specify kwargs for all psychophysics subplots\n",
    "        kwargs = {\n",
    "            'include_yerr': True,\n",
    "        }\n",
    "        # Modify kwargs for special cases\n",
    "        if (isinstance(list_model_dir, str)) and (list_model_dir == 'HUMAN'):\n",
    "            kwargs['include_yerr'] = False\n",
    "        plot_fcn(ax[r_idx, c_idx], results_dict_input, **kwargs)\n",
    "#         if c_idx > 0:\n",
    "#             ax[r_idx, c_idx].set_ylabel(None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in range(ax.shape[0]):\n",
    "#     for c in range(ax.shape[1]):\n",
    "#         bbox_inches = ax[r, c].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "#         save_fn = os.path.join(save_dir, 'panel_{}{}.pdf'.format(r, c))\n",
    "#         fig.savefig(save_fn, bbox_inches=bbox_inches, pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERIC PARAMETERS\n",
    "figsize=(4,3)\n",
    "poster_plot_kwargs = {\n",
    "    'fontsize_labels': 16,\n",
    "    'fontsize_legend': 14,\n",
    "    'fontsize_ticks': 14,\n",
    "    'include_yerr': True,\n",
    "    'kwargs_bootstrap': {\n",
    "        'bootstrap_repeats': 1000,\n",
    "        'metric_function': 'median',\n",
    "    },\n",
    "}\n",
    "\n",
    "### Build dictionary of human results_dict for each experiment\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_human_model_comparison\n",
    "import util_figures_psychophysics\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "\n",
    "sys.path.append('/packages/msutil')\n",
    "import util_figures\n",
    "\n",
    "\n",
    "### SPECIFY THE OUTERMOST DIRECTORY CONTAINING ALL MODELS\n",
    "model_dir = '/om2/user/msaddler/pitchnet/saved_models/'\n",
    "\n",
    "### SPECIFY RESULTS DICT BASENAME: determines which experiment to plot\n",
    "# results_dict_basename = 'EVAL_SOFTMAX_bernox2005_FixedFilter_bestckpt_results_dict.json'\n",
    "results_dict_basename = 'EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json'\n",
    "\n",
    "### SPECIFY REGULAR EXPRESSIONS FOR MODELS: (regex, model_name) pairs\n",
    "master_list = [\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species004_spont070_BWlinear_IHC3000Hz_IHC7order/arch_0???/', 'Linearly spaced'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW02eN1_IHC3000Hz_IHC7order/arch_0???/', '4x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW05eN1_IHC3000Hz_IHC7order/arch_0???/', '2x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', 'Human filter BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW20eN1_IHC3000Hz_IHC7order/arch_0???/', '2x broader BWs'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW40eN1_IHC3000Hz_IHC7order/arch_0???/', '4x broader BWs'),\n",
    "    \n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW05eN1_IHC3000Hz_IHC7order/arch_0191_seed*/', '2x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191_seed*/', 'Human filter BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW20eN1_IHC3000Hz_IHC7order/arch_0191_seed*/', '2x broader BWs'),\n",
    "    \n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', 'Natural'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_v08_noise_TLAS_snr_neg10pos10_filter_signalLPv01/arch_0???/', 'Lowpass'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_v08_noise_TLAS_snr_neg10pos10_filter_signalHPv00/arch_0???/', 'Highpass'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_mfcc_PNDv08PYSmatched12_TLASmatched12_snr_neg10pos10_phase3/arch_0???/', 'Matched'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_mfcc_PNDv08PYSnegated12_TLASmatched12_snr_neg10pos10_phase3/arch_0???/', 'Anti-matched'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_v08spch_noise_TLAS_snr_neg10pos10/arch_0???/', 'Speech only'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0???/', 'Music only'),\n",
    "#     ('/saved_models/arch_search_v02_topN/PND_v08_noise_TLAS_snr_posInf/arch_0???/EVAL_SOFTMAX_lowharm_v04_bestckpt_results_dict.json', 'Speech + music (natural)\\nwith no background noise'),\n",
    "#     ('/saved_models/arch_search_v02_topN/cochlearn_PND_v08spch_noise_TLAS_snr_neg10pos10/arch_0???/', 'Speech only'),\n",
    "#     ('/saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0???/', 'Music only'),\n",
    "    ('/saved_models/arch_search_v02_topN/cochlearn_IHC4000Hz_PND_v08spch_noise_TLAS_snr_neg10pos10/arch_0???/', 'Speech only'),\n",
    "    ('/saved_models/arch_search_v02_topN/cochlearn_IHC4000Hz_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0???/', 'Music only'),\n",
    "\n",
    "    \n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_024/arch_0???/', '1/2 st'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_048/arch_0???/', '1/4 st'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_096/arch_0???/', '1/8 st'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', '1/16 st'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_384/arch_0???/', '1/32 st'),\n",
    "    \n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '100 ANF'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '100$^T$ ANF'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI250_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '250$^T$ ANF'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI500_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '500$^T$ ANF'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '1000$^T$ ANF'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW05eN1_IHC3000Hz_IHC7order/arch_0???/', '2x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', 'Human filter BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW20eN1_IHC3000Hz_IHC7order/arch_0???/', '2x broader BWs'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '50Hz'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '50Hz'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0250Hz_IHC7order/arch_0???/', '250Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/', '320Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/', '1000Hz'),\n",
    "# #     ('HUMAN', 'Humans'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', '3000Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/', '6000Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/', '9000Hz'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json', 'train NH + test NH'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_dbspl85_bestckpt_results_dict.json', 'train NH + test NH (85dB)'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_cohc0_lowharm_v01_bestckpt_results_dict.json', 'train NH + test HI'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_cohc0_lowharm_v01_dbspl85_bestckpt_results_dict.json', 'train NH + test HI (85dB)'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order_cohc0_dBSPL60to90/arch_0???/EVAL_SOFTMAX_cohc0_lowharm_v01_bestckpt_results_dict.json', 'train HI + test HI'),\n",
    "# #     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order_cohc0_dBSPL60to90/arch_0???/EVAL_SOFTMAX_cohc0_lowharm_v01_dbspl85_bestckpt_results_dict.json', 'train HI + test HI (85dB)'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW05eN1_IHC3000Hz_IHC7order/arch_0???/', '2x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', 'Human filter BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW20eN1_IHC3000Hz_IHC7order/arch_0???/', '2x broader BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_BW05eN1_lowharm_v01_bestckpt_results_dict.json', '2x narrower BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json', 'Human filter BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_BW20eN1_lowharm_v01_bestckpt_results_dict.json', '2x broader BWs'),\n",
    "    \n",
    "#     ('HUMAN', 'Humans'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json', 'Model'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_thresh40_bestckpt_results_dict.json', 'Model (thresh40)'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_noise08_bestckpt_results_dict.json', 'Model (noise08)'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/EVAL_SOFTMAX_lowharm_v01_noise10_bestckpt_results_dict.json', 'Model (noise10)'),\n",
    "]\n",
    "\n",
    "### LOAD PSYCHOPHYSICS EXPERIMENT RESULTS\n",
    "model_keys = []\n",
    "results_dicts = {}\n",
    "master_count = 0\n",
    "for fn_regex, model_key in master_list:\n",
    "    results_dicts[model_key] = []\n",
    "    model_keys.append(model_key)\n",
    "    if fn_regex.upper() == 'HUMAN':\n",
    "        results_dicts[model_key].append(util_human_model_comparison.get_human_results_dict_bernox2005())\n",
    "    else:\n",
    "        if not fn_regex[0] == '/': fn_regex = os.path.join(model_dir, fn_regex)\n",
    "        if '.json' not in fn_regex: fn_regex = os.path.join(fn_regex, results_dict_basename)\n",
    "        for results_dict_fn in sorted(glob.glob(fn_regex)):\n",
    "            master_count = master_count + 1\n",
    "            with open(results_dict_fn) as f:\n",
    "                results_dicts[model_key].append(json.load(f))\n",
    "\n",
    "print('Loaded results from {} files ({})'.format(master_count, results_dict_basename))\n",
    "for key in results_dicts.keys():\n",
    "    print(key, len(results_dicts[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### bernox2005 discrimination threholds\n",
    "\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "plot_fcn = util_figures_psychophysics.make_bernox_threshold_plot\n",
    "human_rd = util_human_model_comparison.get_human_results_dict_bernox2005()\n",
    "\n",
    "\n",
    "legend_loc = 'lower right'\n",
    "add_lines = False\n",
    "save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2021_05_07_pitchnet_paper_figures_v04/'\n",
    "if 'noise' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR FILTERING SOUNDS\n",
    "    color_list = [color_list[idx] for idx in [0, 2, 4]]\n",
    "    legend_loc = 'lower right'\n",
    "    save_fn = 'tmp.pdf'\n",
    "elif 'natural' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR FILTERING SOUNDS\n",
    "    color_list = [color_list[idx] for idx in [0, 2, 4]]\n",
    "    legend_loc = 'upper right'\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_natural.pdf')\n",
    "elif 'matched' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR SYNTHETIC TONES\n",
    "    color_list = [color_list[idx] for idx in [0, 4]]\n",
    "    legend_loc = 'upper right'\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_synthetic.pdf')\n",
    "elif 'only' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(8, cmap_name='Accent') # CMAP FOR SPEECH VS MUSIC\n",
    "    color_list = [color_list[idx] for idx in [4,5]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_speech_vs_music.pdf')\n",
    "    if 'cochlearn_IHC4000Hz' in master_list[0][0]:\n",
    "        save_fn = save_fn.replace('.pdf', '_cochlearn_IHC4000Hz.pdf')\n",
    "    elif 'cochlearn' in master_list[0][0]:\n",
    "        save_fn = save_fn.replace('.pdf', '_cochlearn.pdf')\n",
    "elif 'BW' in model_keys[1].upper():\n",
    "    color_list = ['#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_cochFilterBWs.pdf')\n",
    "elif 'hz' in model_keys[0].lower():\n",
    "    color_list = ['#fdb863', '#e08214', '#b35806', 'k', '#8073ac', '#b2abd2'] #  CMAP FOR IHC LOWPASS\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHClowpass.pdf')\n",
    "elif '/' in model_keys[0]:\n",
    "    color_list = ['#fed976', '#feb24c', '#fd8d3c', '#f03b20', '#bd0026'] # CMAP for F0 bin width\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_f0_bin_width.pdf')\n",
    "elif 'ANF' in model_keys[0]:\n",
    "    color_list = ['#bdd7e7', '#6baed6', '#3182bd', '#08519c'] # CMAP for number of ANFs\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHC0050Hz_num_ANFs.pdf')\n",
    "else:\n",
    "    raise ValueError(\"Failed to automatically specify color_list and save_fn!!!\")\n",
    "\n",
    "color_list = color_list + ['b']\n",
    "\n",
    "kwargs = {\n",
    "    'xlimits': [0,31],\n",
    "    'include_yerr': True,\n",
    "    'legend_on': True,\n",
    "    'restrict_conditions': [0],\n",
    "}\n",
    "kwargs['kwargs_legend'] = {\n",
    "    'loc': legend_loc,\n",
    "    'ncol': 2,\n",
    "    'frameon': False,\n",
    "    'framealpha': 1.0,\n",
    "    'facecolor': 'w',\n",
    "    'edgecolor': 'k',\n",
    "    'handlelength': 0.5,\n",
    "    'markerscale': 0.0,\n",
    "    'fontsize': 10.0,\n",
    "    'borderpad': 0.6,\n",
    "    'borderaxespad': 0.3,\n",
    "}\n",
    "if len(model_keys) < 4:\n",
    "    kwargs['kwargs_legend']['ncol'] = 1\n",
    "    kwargs['kwargs_legend']['frameon'] = True\n",
    "\n",
    "NROWS = 1\n",
    "NCOLS = 1\n",
    "# figsize = (4*NCOLS*.9, 3*NROWS*.9)\n",
    "figsize = (4, 3)\n",
    "gridspec_kw = {}\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=figsize, gridspec_kw=gridspec_kw)\n",
    "\n",
    "\n",
    "### PLOT MODEL ###\n",
    "zorder = 0\n",
    "for cidx, key in enumerate(model_keys):\n",
    "    kwargs['sine_plot_kwargs'] = {\n",
    "        'label': key,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "    kwargs['rand_plot_kwargs'] = {\n",
    "        'label': None,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "#     for rd in results_dicts[key]:\n",
    "#         plot_fcn(ax, rd, **kwargs)\n",
    "\n",
    "    rd_itr0 = plot_fcn(ax, results_dicts[key], **kwargs)\n",
    "    zorder -= 1\n",
    "\n",
    "import matplotlib\n",
    "leg = [c for c in ax.get_children() if isinstance(c, matplotlib.legend.Legend)]\n",
    "if len(leg) == 1:\n",
    "    for legobj in leg[0].legendHandles:\n",
    "        legobj.set_linewidth(6.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print(save_fn)\n",
    "# fig.savefig(save_fn, bbox_inches='tight', pad_inches=0, transparent=False)\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bernox2005 discrimination threholds\n",
    "\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "plot_fcn = util_figures_psychophysics.make_bernox_threshold_plot\n",
    "human_rd = util_human_model_comparison.get_human_results_dict_bernox2005()\n",
    "\n",
    "\n",
    "save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2020_09_26_pitchnet_paper_figures_v03/'\n",
    "if 'natural' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR FILTERING SOUNDS\n",
    "    color_list = [color_list[idx] for idx in [0, 2, 4]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_natural.pdf')\n",
    "elif 'matched' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR SYNTHETIC TONES\n",
    "    color_list = [color_list[idx] for idx in [0, 4]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_synthetic.pdf')\n",
    "elif 'only' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(8, cmap_name='Accent') # CMAP FOR SPEECH VS MUSIC\n",
    "    color_list = [color_list[idx] for idx in [4,5]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_speech_vs_music.pdf')\n",
    "elif 'BW' in model_keys[1].upper():\n",
    "#     color_list = ['#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "#     save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_cochFilterBWs.pdf')\n",
    "    color_list = ['#f768a1', '#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "    if len(model_keys) < 4:\n",
    "        color_list = color_list[1:]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_cochFilterBWs_linear.pdf')\n",
    "elif 'hz' in model_keys[0].lower():\n",
    "    color_list = ['#fdb863', '#e08214', '#b35806', 'k', '#8073ac', '#b2abd2'] #  CMAP FOR IHC LOWPASS\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHClowpass.pdf')\n",
    "elif '/' in model_keys[0]:\n",
    "    color_list = ['#fed976', '#feb24c', '#fd8d3c', '#f03b20', '#bd0026'] # CMAP for F0 bin width\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_f0_bin_width.pdf')\n",
    "elif 'ANF' in model_keys[0]:\n",
    "    color_list = ['#bdd7e7', '#6baed6', '#3182bd', '#08519c'] # CMAP for number of ANFs\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHC0050Hz_num_ANFs.pdf')\n",
    "elif 'train NH' in model_keys[0]:\n",
    "    color_list = util_figures.get_color_list(12, cmap_name='Paired')\n",
    "    save_fn = None\n",
    "else:\n",
    "    color_list = util_figures.get_color_list(9, cmap_name='Set1')\n",
    "    save_fn = None\n",
    "#     raise ValueError(\"Failed to automatically specify color_list and save_fn!!!\")\n",
    "\n",
    "color_list = color_list + ['b']\n",
    "\n",
    "\n",
    "def get_transition_point(results_dict_input, phase_mode=0, transition_f0dl=1.0,):\n",
    "    '''\n",
    "    '''\n",
    "    if not isinstance(results_dict_input, list):\n",
    "        results_dict_input = [results_dict_input]\n",
    "    \n",
    "    f0dls = np.array([rd['f0dl'] for rd in results_dict_input])\n",
    "    list_phase_mode = np.array(results_dict_input[0]['phase_mode'])\n",
    "    list_low_harm = np.array(results_dict_input[0]['low_harm'])\n",
    "    \n",
    "    f0dls = f0dls[:, list_phase_mode == phase_mode]\n",
    "    list_low_harm = list_low_harm[list_phase_mode == phase_mode]\n",
    "    list_phase_mode = list_phase_mode[list_phase_mode == phase_mode]\n",
    "    \n",
    "    list_transition = np.zeros([f0dls.shape[0]])\n",
    "    for itr0 in range(f0dls.shape[0]):\n",
    "        list_transition[itr0] = list_low_harm[f0dls[itr0, :] > transition_f0dl][0]\n",
    "    transition_mean, transition_err = util_figures_psychophysics.bootstrap(list_transition)\n",
    "    return transition_mean, transition_err, list_transition\n",
    "\n",
    "\n",
    "fontsize_labels=12\n",
    "fontsize_ticks=12\n",
    "xlimits=[0, 31]\n",
    "ylimits=[1e-1, 1e2]\n",
    "kwargs = {\n",
    "    'xlimits': xlimits,\n",
    "    'ylimits': ylimits,\n",
    "    'include_yerr': True,\n",
    "    'legend_on': True,\n",
    "    'restrict_conditions': [0],\n",
    "    'kwargs_legend': {\n",
    "#         'ncol': 2,\n",
    "        'handlelength': 0.5,\n",
    "        'borderpad': 0,\n",
    "        'columnspacing': 1,\n",
    "        'loc': 'lower right',\n",
    "        'handletextpad': 0.5,\n",
    "        'ncol': 1,\n",
    "#         'fontsize': 8,\n",
    "    },\n",
    "#     'kwargs_bootstrap':{'bootstrap_repeats': 1000, 'metric_function': 'median'},\n",
    "}\n",
    "if len(model_keys) <= 4:\n",
    "    kwargs['kwargs_legend']['ncol'] = 1\n",
    "\n",
    "NROWS = 2\n",
    "NCOLS = 2\n",
    "wratio = 6.5\n",
    "hratio = 6.5 * 3.6/4\n",
    "figsize = (4 * (wratio + 1) / wratio, 3 * (hratio + 1) / hratio)\n",
    "gridspec_kw = {\n",
    "    'width_ratios': [1, wratio],\n",
    "    'height_ratios': [hratio, 1],\n",
    "    'wspace': 0.0,\n",
    "    'hspace': 0.0,\n",
    "}\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=figsize, gridspec_kw=gridspec_kw, sharex='col', sharey='row')\n",
    "\n",
    "### PLOT MODEL ###\n",
    "zorder = 0\n",
    "cidx = 0\n",
    "for itr0, key in enumerate(model_keys):\n",
    "    kwargs['sine_plot_kwargs'] = {\n",
    "        'label': key,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "    kwargs['rand_plot_kwargs'] = {\n",
    "        'label': None,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "    if False:#'HUMAN' in key.upper():\n",
    "        kwargs['sine_plot_kwargs'] = {\n",
    "            'color': [0, 0, 0],\n",
    "            'label': None,\n",
    "            'lw': 1,\n",
    "            'ls': '--',\n",
    "            'zorder': 1000,\n",
    "            'marker': 'o',\n",
    "            'ms': 6,\n",
    "            'markerfacecolor': [1, 1, 1],\n",
    "            'markeredgecolor': [0, 0, 0],\n",
    "            'markeredgewidth': 1,\n",
    "        }\n",
    "    \n",
    "    rd_itr0 = plot_fcn(ax_arr[0, 1], results_dicts[key], **kwargs)\n",
    "    \n",
    "    if True:#'HUMAN' not in key.upper():\n",
    "        transition_mean, transition_err, list_transition = get_transition_point(results_dicts[key])\n",
    "        threshold_mask = np.logical_and(np.array(rd_itr0['phase_mode']) == 0,\n",
    "                                        np.array(rd_itr0['low_harm']) == 1)\n",
    "        log10_f0dl = rd_itr0['log10_f0dl'][threshold_mask][0]\n",
    "        log10_f0dl_err = rd_itr0['log10_f0dl_err'][threshold_mask][0]\n",
    "\n",
    "        line_plot_kwargs = {\n",
    "            'lw': 0.50,\n",
    "            'ls': '--',\n",
    "            'dashes': (2, 2),\n",
    "            'color': color_list[cidx],\n",
    "            'zorder': zorder,\n",
    "        }\n",
    "        line_ymin = 1e-1\n",
    "        line_ymax = np.power(10.0, np.interp(transition_mean, rd_itr0['low_harm'], rd_itr0['log10_f0dl']))\n",
    "        ax_arr[0, 1].plot([transition_mean, transition_mean],\n",
    "                          [line_ymin, line_ymax],\n",
    "                          **line_plot_kwargs)\n",
    "        errorbar_kwargs = {\n",
    "            'fmt': 's',\n",
    "            'color': color_list[cidx],\n",
    "            'ms': 2,\n",
    "            'ecolor': color_list[cidx],\n",
    "            'elinewidth': 3,\n",
    "            'capsize': 0,\n",
    "            'capthick': 0,\n",
    "        }\n",
    "        yerr = np.array([\n",
    "            np.power(10.0, log10_f0dl) - np.power(10.0, log10_f0dl-2*log10_f0dl_err),\n",
    "            np.power(10.0, log10_f0dl+2*log10_f0dl_err) - np.power(10.0, log10_f0dl)\n",
    "        ]).reshape([2, -1])\n",
    "        ax_arr[0, 0].errorbar(itr0, np.power(10.0, log10_f0dl), xerr=None, yerr=yerr, **errorbar_kwargs)\n",
    "        ax_arr[1, 1].errorbar(transition_mean, len(model_keys)-itr0-1, xerr=2*transition_err, yerr=None, **errorbar_kwargs)\n",
    "        ax_arr[1, 1].plot([transition_mean, transition_mean],\n",
    "                          [len(model_keys)-itr0-1, 100],\n",
    "                          **line_plot_kwargs)\n",
    "        cidx += 1\n",
    "    zorder -= 1\n",
    "    \n",
    "\n",
    "import matplotlib\n",
    "leg = [c for c in ax_arr[0, 1].get_children() if isinstance(c, matplotlib.legend.Legend)]\n",
    "if len(leg) == 1:\n",
    "    for legobj in leg[0].legendHandles:\n",
    "        if False:#'human' in str(legobj).lower():\n",
    "            legobj.set_linewidth(1.0)\n",
    "            legobj._legmarker.set_markersize(6)\n",
    "        else:\n",
    "            legobj.set_linewidth(6.0)\n",
    "\n",
    "ax_arr[0, 1].set(xlabel=None, ylabel=None, xticklabels=[], yticklabels=[])\n",
    "ax_arr[0, 1].tick_params(which='both', length=0)\n",
    "\n",
    "util_figures.format_axes(ax_arr[0, 0],\n",
    "                         str_xlabel=None,\n",
    "                         str_ylabel='F0 discrimination\\nthreshold (%F0)',\n",
    "                         fontsize_labels=fontsize_labels,\n",
    "                         fontsize_ticks=fontsize_ticks,\n",
    "                         fontweight_labels=None,\n",
    "                         xscale='linear',\n",
    "                         yscale='log',\n",
    "                         xlimits=[-1, itr0+1],\n",
    "                         ylimits=ylimits,\n",
    "                         xticks=[],\n",
    "                         yticks=None,\n",
    "                         xticks_minor=[],\n",
    "                         yticks_minor=None,\n",
    "                         xticklabels=[],\n",
    "                         yticklabels=None,\n",
    "                         spines_to_hide=[],\n",
    "                         major_tick_params_kwargs_update={},\n",
    "                         minor_tick_params_kwargs_update={})\n",
    "util_figures.format_axes(ax_arr[1, 1],\n",
    "                         str_xlabel='Lowest harmonic number',\n",
    "                         str_ylabel=None,\n",
    "                         fontsize_labels=fontsize_labels,\n",
    "                         fontsize_ticks=fontsize_ticks,\n",
    "                         fontweight_labels=None,\n",
    "                         xscale='linear',\n",
    "                         yscale='linear',\n",
    "                         xlimits=xlimits,\n",
    "                         ylimits=[-1, itr0+1],\n",
    "                         xticks=np.arange(xlimits[0], xlimits[1], 5),\n",
    "                         yticks=[],\n",
    "                         xticks_minor=np.arange(xlimits[0], xlimits[1], 1),\n",
    "                         yticks_minor=None,\n",
    "                         xticklabels=None,\n",
    "                         yticklabels=None,\n",
    "                         spines_to_hide=[],\n",
    "                         major_tick_params_kwargs_update={},\n",
    "                         minor_tick_params_kwargs_update={})\n",
    "\n",
    "ax_arr[0, 0].text(np.mean([-1, itr0+1]), 1.8, 'Best thresholds', {'ha': 'center', 'va': 'bottom'}, rotation=90, fontsize=11)\n",
    "ax_arr[1, 1].text(9, np.mean([-1, itr0+1]), 'Transition points', {'ha': 'left', 'va': 'center'}, rotation=0, fontsize=11)\n",
    "\n",
    "ax_arr[1, 0].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(save_fn)\n",
    "# fig.savefig(save_fn, bbox_inches='tight', pad_inches=0, transparent=False)\n",
    "\n",
    "fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bernox2005 discrimination threholds\n",
    "\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "plot_fcn = util_figures_psychophysics.make_bernox_threshold_plot\n",
    "human_rd = util_human_model_comparison.get_human_results_dict_bernox2005()\n",
    "\n",
    "\n",
    "save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2020_09_26_pitchnet_paper_figures_v03/'\n",
    "if 'natural' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR FILTERING SOUNDS\n",
    "    color_list = [color_list[idx] for idx in [0, 2, 4]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_natural.pdf')\n",
    "elif 'matched' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(6, cmap_name='gist_heat') # CMAP FOR SYNTHETIC TONES\n",
    "    color_list = [color_list[idx] for idx in [0, 4]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_synthetic.pdf')\n",
    "elif 'only' in model_keys[0].lower():\n",
    "    color_list = util_figures.get_color_list(8, cmap_name='Accent') # CMAP FOR SPEECH VS MUSIC\n",
    "    color_list = [color_list[idx] for idx in [4,5]]\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_sound_statistics_speech_vs_music.pdf')\n",
    "elif 'BW' in model_keys[1].upper():\n",
    "#     color_list = ['#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "#     save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_cochFilterBWs.pdf')\n",
    "    color_list = ['#f768a1', '#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_cochFilterBWs_linear.pdf')\n",
    "elif 'hz' in model_keys[0].lower():\n",
    "    color_list = ['#fdb863', '#e08214', '#b35806', 'k', '#8073ac', '#b2abd2'] #  CMAP FOR IHC LOWPASS\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHClowpass.pdf')\n",
    "elif '/' in model_keys[0]:\n",
    "    color_list = ['#fed976', '#feb24c', '#fd8d3c', '#f03b20', '#bd0026'] # CMAP for F0 bin width\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_f0_bin_width.pdf')\n",
    "elif 'ANF' in model_keys[0]:\n",
    "    color_list = ['#c6dbef', '#bdd7e7', '#6baed6', '#3182bd', '#08519c'] # CMAP for number of ANFs\n",
    "    save_fn = os.path.join(save_dir, 'psychophysics_bernoxSinePhase_manipulation_IHC0050Hz_num_ANFs.pdf')\n",
    "else:\n",
    "    raise ValueError(\"Failed to automatically specify color_list and save_fn!!!\")\n",
    "\n",
    "color_list = color_list + ['b']\n",
    "\n",
    "\n",
    "def get_transition_point(results_dict_input, phase_mode=0, transition_f0dl=1.0,):\n",
    "    '''\n",
    "    '''\n",
    "    if not isinstance(results_dict_input, list):\n",
    "        results_dict_input = [results_dict_input]\n",
    "    \n",
    "    f0dls = np.array([rd['f0dl'] for rd in results_dict_input])\n",
    "    list_phase_mode = np.array(results_dict_input[0]['phase_mode'])\n",
    "    list_low_harm = np.array(results_dict_input[0]['low_harm'])\n",
    "    \n",
    "    f0dls = f0dls[:, list_phase_mode == phase_mode]\n",
    "    list_low_harm = list_low_harm[list_phase_mode == phase_mode]\n",
    "    list_phase_mode = list_phase_mode[list_phase_mode == phase_mode]\n",
    "    \n",
    "    list_transition = np.zeros([f0dls.shape[0]])\n",
    "    for itr0 in range(f0dls.shape[0]):\n",
    "        list_transition[itr0] = list_low_harm[f0dls[itr0, :] > transition_f0dl][0]\n",
    "    transition_mean, transition_err = util_figures_psychophysics.bootstrap(list_transition)\n",
    "    return transition_mean, transition_err, list_transition\n",
    "\n",
    "\n",
    "fontsize_labels=12\n",
    "fontsize_ticks=12\n",
    "xlimits=[0, 31]\n",
    "ylimits=[1e-1, 1e2]\n",
    "kwargs = {\n",
    "    'xlimits': xlimits,\n",
    "    'ylimits': ylimits,\n",
    "    'include_yerr': True,\n",
    "    'legend_on': True,\n",
    "    'restrict_conditions': [0],\n",
    "    'kwargs_legend': {\n",
    "        'ncol': 2,\n",
    "        'handlelength': 0.5,\n",
    "        'borderpad': 0,\n",
    "        'columnspacing': 1,\n",
    "        'loc': 'lower right',\n",
    "        'handletextpad': 0.5,\n",
    "    },\n",
    "}\n",
    "if len(model_keys) <= 4:\n",
    "    kwargs['kwargs_legend']['ncol'] = 1\n",
    "\n",
    "NROWS = 1\n",
    "NCOLS = 2\n",
    "wratio = 6.5\n",
    "figsize = (4 * (wratio + 1) / wratio, 3 * (wratio + 1/2) / wratio)\n",
    "gridspec_kw = {\n",
    "    'width_ratios': [1, wratio],\n",
    "    'wspace': 0.0,\n",
    "    'hspace': 0.0,\n",
    "}\n",
    "fig, ax_arr = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=figsize, gridspec_kw=gridspec_kw, sharex='col', sharey='row')\n",
    "ax_arr = ax_arr.reshape([1, -1])\n",
    "\n",
    "### PLOT MODEL ###\n",
    "zorder = 0\n",
    "cidx = 0\n",
    "for itr0, key in enumerate(model_keys):\n",
    "    kwargs['sine_plot_kwargs'] = {\n",
    "        'label': key,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "    kwargs['rand_plot_kwargs'] = {\n",
    "        'label': None,\n",
    "        'color': color_list[cidx],\n",
    "        'lw': 3,\n",
    "        'zorder': zorder,\n",
    "    }\n",
    "    if 'HUMAN' in key.upper():\n",
    "        kwargs['sine_plot_kwargs'] = {\n",
    "            'color': [0, 0, 0],\n",
    "            'label': None,\n",
    "            'lw': 1,\n",
    "            'ls': '--',\n",
    "            'zorder': 1000,\n",
    "            'marker': 'o',\n",
    "            'ms': 6,\n",
    "            'markerfacecolor': [1, 1, 1],\n",
    "            'markeredgecolor': [0, 0, 0],\n",
    "            'markeredgewidth': 1,\n",
    "        }\n",
    "    \n",
    "    rd_itr0 = plot_fcn(ax_arr[0, 1], results_dicts[key], **kwargs)\n",
    "    \n",
    "    if 'HUMAN' not in key.upper():\n",
    "        transition_mean, transition_err, list_transition = get_transition_point(results_dicts[key])\n",
    "        threshold_mask = np.logical_and(np.array(rd_itr0['phase_mode']) == 0,\n",
    "                                        np.array(rd_itr0['low_harm']) == 1)\n",
    "        log10_f0dl = rd_itr0['log10_f0dl'][threshold_mask][0]\n",
    "        log10_f0dl_err = rd_itr0['log10_f0dl_err'][threshold_mask][0]\n",
    "\n",
    "        line_plot_kwargs = {\n",
    "            'lw': 0.50,\n",
    "            'ls': '--',\n",
    "            'dashes': (2, 2),\n",
    "            'color': color_list[cidx],\n",
    "            'zorder': zorder,\n",
    "        }\n",
    "        line_ymin = 1e-1\n",
    "        line_ymax = np.power(10.0, np.interp(transition_mean, rd_itr0['low_harm'], rd_itr0['log10_f0dl']))\n",
    "#         ax_arr[0, 1].plot([transition_mean, transition_mean],\n",
    "#                           [line_ymin, line_ymax],\n",
    "#                           **line_plot_kwargs)\n",
    "        errorbar_kwargs = {\n",
    "            'fmt': 's',\n",
    "            'color': color_list[cidx],\n",
    "            'ms': 2,\n",
    "            'ecolor': color_list[cidx],\n",
    "            'elinewidth': 3,\n",
    "            'capsize': 0,\n",
    "            'capthick': 0,\n",
    "        }\n",
    "        yerr = np.array([\n",
    "            np.power(10.0, log10_f0dl) - np.power(10.0, log10_f0dl-2*log10_f0dl_err),\n",
    "            np.power(10.0, log10_f0dl+2*log10_f0dl_err) - np.power(10.0, log10_f0dl)\n",
    "        ]).reshape([2, -1])\n",
    "        ax_arr[0, 0].errorbar(itr0, np.power(10.0, log10_f0dl), xerr=None, yerr=yerr, **errorbar_kwargs)\n",
    "        cidx += 1\n",
    "    zorder -= 1\n",
    "    \n",
    "\n",
    "import matplotlib\n",
    "leg = [c for c in ax_arr[0, 1].get_children() if isinstance(c, matplotlib.legend.Legend)]\n",
    "if len(leg) == 1:\n",
    "    for legobj in leg[0].legendHandles:\n",
    "        if 'human' in str(legobj).lower():\n",
    "            legobj.set_linewidth(1.0)\n",
    "            legobj._legmarker.set_markersize(6)\n",
    "        else:\n",
    "            legobj.set_linewidth(6.0)\n",
    "\n",
    "ax_arr[0, 1].set(ylabel=None, yticklabels=[])\n",
    "ax_arr[0, 1].tick_params(which='both', axis='y', length=0)\n",
    "\n",
    "util_figures.format_axes(ax_arr[0, 0],\n",
    "                         str_xlabel=None,\n",
    "                         str_ylabel='F0 discrimination\\nthreshold (%F0)',\n",
    "                         fontsize_labels=fontsize_labels,\n",
    "                         fontsize_ticks=fontsize_ticks,\n",
    "                         fontweight_labels=None,\n",
    "                         xscale='linear',\n",
    "                         yscale='log',\n",
    "                         xlimits=[-1, itr0+1],\n",
    "                         ylimits=ylimits,\n",
    "                         xticks=[],\n",
    "                         yticks=None,\n",
    "                         xticks_minor=[],\n",
    "                         yticks_minor=None,\n",
    "                         xticklabels=[],\n",
    "                         yticklabels=None,\n",
    "                         spines_to_hide=[],\n",
    "                         major_tick_params_kwargs_update={},\n",
    "                         minor_tick_params_kwargs_update={})\n",
    "\n",
    "ax_arr[0, 0].text(np.mean([-1, itr0+1]), 1.8, 'Best thresholds', {'ha': 'center', 'va': 'bottom'}, rotation=90, fontsize=11)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print(save_fn)\n",
    "# fig.savefig(save_fn, bbox_inches='tight', pad_inches=0, transparent=False)\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import glob\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "import f0dl_bernox\n",
    "import f0dl_generalized\n",
    "import util_human_model_comparison\n",
    "import util_figures_psychophysics\n",
    "import importlib\n",
    "importlib.reload(f0dl_generalized)\n",
    "importlib.reload(util_human_model_comparison)\n",
    "importlib.reload(util_figures_psychophysics)\n",
    "\n",
    "sys.path.append('/packages/msutil')\n",
    "import util_figures\n",
    "\n",
    "\n",
    "model_dir_list = [\n",
    "#     ('/saved_models/arch_search_v02_topN/connear_IHC3000Hz/arch_0???/', 'CoNNear_IHC3000Hz'),\n",
    "#     ('HUMAN', 'Human listeners\\n(Wier et al., 1977)'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW02eN1_IHC3000Hz_IHC7order/arch_0???/', '4x narrower BWs'),\n",
    "    ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW05eN1_IHC3000Hz_IHC7order/arch_0???/', '2x narrower BWs'),\n",
    "    ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', 'Human filter BWs'),\n",
    "    ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW20eN1_IHC3000Hz_IHC7order/arch_0???/', '2x broader BWs'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW40eN1_IHC3000Hz_IHC7order/arch_0???/', '4x broader BWs'),\n",
    "\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '50Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/', '320Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/', '1000Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', '3000Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/', '6000Hz'),\n",
    "#     ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/', '9000Hz'),\n",
    "]\n",
    "\n",
    "if 'BW0' in model_dir_list[0][0]:\n",
    "    basename, key_xval = ('EVAL_SOFTMAX_testsnr_v02_bestckpt_results_dict.json', 'snr_per_component')\n",
    "else:\n",
    "    basename, key_xval = ('EVAL_SOFTMAX_testspl_v03_bestckpt_results_dict.json', 'dbspl')\n",
    "\n",
    "list_model_name = []\n",
    "list_list_results_dict = []\n",
    "for (model_dir, model_name) in model_dir_list:\n",
    "    if model_dir.upper() == 'HUMAN':\n",
    "        list_results_dict = [util_human_model_comparison.get_human_results_dict_pure_tone_spl(threshold_level=0)]\n",
    "        print(model_dir, len(list_results_dict))\n",
    "    else:\n",
    "        regex_json_fn = model_dir\n",
    "        if '.json' not in regex_json_fn:\n",
    "            regex_json_fn = os.path.join(regex_json_fn, basename)\n",
    "        list_results_dict = []\n",
    "        for fn_results_dict in sorted(glob.glob(regex_json_fn)):\n",
    "            with open(fn_results_dict) as f:\n",
    "                results_dict = json.load(f)\n",
    "            list_results_dict.append(results_dict)\n",
    "        print(regex_json_fn, len(list_results_dict))\n",
    "    list_model_name.append(model_name)\n",
    "    list_list_results_dict.append(list_results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_figures_psychophysics)\n",
    "\n",
    "if 'BW' in list_model_name[0]:\n",
    "    color_list = ['#5ab4ac', 'k', '#a6611a'] # CMAP FOR COCH FILTER BW\n",
    "else:\n",
    "    color_list = ['#fdb863', '#e08214', '#b35806', 'k', '#8073ac', '#b2abd2'] #  CMAP FOR IHC LOWPASS\n",
    "\n",
    "# color_list = np.array([[90,180,172], [0,0,0], [166,97,26]])/256 # CMAP FOR COCH FILTER BW\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "for cidx, (list_results_dict, model_name) in enumerate(zip(list_list_results_dict, list_model_name)):\n",
    "    \n",
    "    kwargs = {\n",
    "        'key_xval': key_xval,\n",
    "        'str_xlabel': 'Per component SNR (dB)',\n",
    "#         'xlimits': [-23, -7],\n",
    "        'xticks': 5,\n",
    "        'xticks_minor': 1,\n",
    "        'include_yerr': True,\n",
    "        'plot_kwargs_update': {\n",
    "            'color': color_list[cidx],\n",
    "            'label': model_name,\n",
    "            'lw': 3,\n",
    "            'marker': '.',\n",
    "            'markersize': 6,\n",
    "        },\n",
    "        'kwargs_legend': {\n",
    "            'ncol': 1,\n",
    "            'handlelength': 0.5,\n",
    "            'borderpad': 0,\n",
    "            'columnspacing': 1,\n",
    "            'loc': 'upper right',\n",
    "            'handletextpad':0.5,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    util_figures_psychophysics.make_f0dl_threshold_plot(ax, list_results_dict, **kwargs)\n",
    "\n",
    "import matplotlib\n",
    "leg = [c for c in ax.get_children() if isinstance(c, matplotlib.legend.Legend)]\n",
    "if len(leg) == 1:\n",
    "    for legobj in leg[0].legendHandles:\n",
    "        legobj.set_linewidth(6.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_figures_psychophysics)\n",
    "\n",
    "color_list = np.array([[253,184,99], [224,130,20], [179,88,6], [0,0,0], [128,115,172], [178,171,210]])/256# CMAP FOR IHC LOWPASS\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4, 3))\n",
    "# fig, ax = plt.subplots(figsize=(4.615384615384615, 3.5128205128205128))\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3.5128205128205128))\n",
    "zorder = 0\n",
    "cidx = 0\n",
    "for (list_results_dict, model_name) in zip(list_list_results_dict, list_model_name):\n",
    "    if len(list_results_dict) == 1:\n",
    "        kwargs = {\n",
    "            'key_xval': key_xval,\n",
    "            'str_xlabel': 'Sensation level (dB SL)',\n",
    "            'str_ylabel': 'Frequency discrimination\\nthreshold (%)',\n",
    "            'xlimits': [0, 105],\n",
    "            'xticks': 20,\n",
    "            'xticks_minor': 5,\n",
    "            'include_yerr': True,\n",
    "            'plot_kwargs_update': {\n",
    "                'color': [0, 0, 0],\n",
    "                'label': model_name,\n",
    "                'lw': 1,\n",
    "                'ls': '--',\n",
    "                'zorder': 1000,\n",
    "                'marker': 'o',\n",
    "                'markersize': 6,\n",
    "                'markerfacecolor': [1, 1, 1],\n",
    "                'markeredgecolor': [0, 0, 0],\n",
    "                'markeredgewidth': 1,\n",
    "            },\n",
    "            'kwargs_legend': {\n",
    "                'ncol': 2,\n",
    "                'handlelength': 3*0.5,\n",
    "                'borderpad': 0.25,\n",
    "                'columnspacing': 1,\n",
    "                'loc': 'upper center',\n",
    "                'handletextpad': 0.5,\n",
    "            },\n",
    "        }\n",
    "    else:\n",
    "        kwargs = {\n",
    "            'key_xval': key_xval,\n",
    "            'str_xlabel': 'Stimulus level (dB SPL)',\n",
    "            'str_ylabel': 'Frequency discrimination\\nthreshold (%)',\n",
    "            'xlimits': [0, 105],\n",
    "            'xticks': 20,\n",
    "            'xticks_minor': 5,\n",
    "            'include_yerr': True,\n",
    "            'plot_kwargs_update': {\n",
    "                'color': color_list[cidx],\n",
    "                'label': model_name,\n",
    "                'lw': 3,\n",
    "                'zorder': zorder,\n",
    "                'marker': '.',\n",
    "                'markersize': 6,\n",
    "            },\n",
    "            'kwargs_legend': {\n",
    "                'ncol': 2,\n",
    "                'handlelength': 0.5,\n",
    "                'borderpad': 0.25,\n",
    "                'columnspacing': 1,\n",
    "                'loc': 'upper center',\n",
    "                'handletextpad': 0.5,\n",
    "            },\n",
    "        }\n",
    "        cidx += 1\n",
    "        zorder -= 1\n",
    "    util_figures_psychophysics.make_f0dl_threshold_plot(ax, list_results_dict, **kwargs)\n",
    "    \n",
    "\n",
    "import matplotlib\n",
    "leg = [c for c in ax.get_children() if isinstance(c, matplotlib.legend.Legend)]\n",
    "if len(leg) == 1:\n",
    "    for legobj in leg[0].legendHandles:\n",
    "        if 'human' in str(legobj).lower():\n",
    "            legobj.set_linewidth(1.0)\n",
    "            legobj._legmarker.set_markersize(6)\n",
    "        else:\n",
    "            legobj.set_linewidth(6.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util_figures_psychophysics\n",
    "import f0dl_bernox\n",
    "\n",
    "sys.path.append('/packages/msutil')\n",
    "import util_figures\n",
    "import util_misc\n",
    "\n",
    "master_list = [\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_024/arch_0???/', '1/2'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_048/arch_0???/', '1/4'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_096/arch_0???/', '1/8'),\n",
    "#     ('/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/', '1/16'),\n",
    "#     ('/saved_models/arch_search_v02_topN/f0_label_384/arch_0???/', '1/32'),\n",
    "    \n",
    "    ('/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '100'),\n",
    "    ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '100$^T$'),\n",
    "    ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI250_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '250$^T$'),\n",
    "    ('/saved_models/arch_search_v02_topN/REDOsr2000_cfI500_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '500$^T$'),\n",
    "    ('/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/', '1000$^T$'),\n",
    "]\n",
    "\n",
    "results_dict_basename = 'EVAL_validation_bestckpt_results_dict.json'\n",
    "\n",
    "if '/' in master_list[0][1]:\n",
    "    str_xlabel = 'F0 bin width (semitones)'\n",
    "    list_color = ['#fed976', '#feb24c', '#fd8d3c', '#f03b20', '#bd0026']\n",
    "else:\n",
    "    str_xlabel = 'Number of simulated ANFs'\n",
    "    list_color = ['#c6dbef', '#bdd7e7', '#6baed6', '#3182bd', '#08519c']\n",
    "\n",
    "model_keys = []\n",
    "results_dicts = {}\n",
    "master_count = 0\n",
    "for fn_regex, model_key in master_list:\n",
    "    results_dicts[model_key] = []\n",
    "    model_keys.append(model_key)\n",
    "    if '.json' not in fn_regex:\n",
    "        fn_regex = os.path.join(fn_regex, results_dict_basename)\n",
    "    for results_dict_fn in sorted(glob.glob(fn_regex)):\n",
    "        master_count = master_count + 1\n",
    "        with open(results_dict_fn) as f:\n",
    "            results_dicts[model_key].append(json.load(f))\n",
    "\n",
    "print('Loaded results from {} files ({})'.format(master_count, results_dict_basename))\n",
    "for key in results_dicts.keys():\n",
    "    print(key, len(results_dicts[key]))\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "xticklabels = model_keys\n",
    "for xval, key in enumerate(model_keys):\n",
    "    list_rd = results_dicts[key]\n",
    "    list_f0_pct_error_median = [rd['f0_pct_error_median'] for rd in list_rd]\n",
    "    print(key, len(list_f0_pct_error_median), np.mean(list_f0_pct_error_median))\n",
    "    yval, yerr = util_figures_psychophysics.bootstrap(np.array(list_f0_pct_error_median))\n",
    "    bar_kwargs = {\n",
    "        'yerr': 2*yerr,\n",
    "        'color': list_color[xval],\n",
    "        'capsize': 6,\n",
    "        'ecolor': list_color[xval],\n",
    "        'linewidth': 12,\n",
    "        'capthick': 1,\n",
    "    }    \n",
    "    ax.errorbar(xval, yval, **bar_kwargs)\n",
    "    \n",
    "    point_xvals = np.linspace(xval-0.12, xval+0.12, len(list_f0_pct_error_median))\n",
    "    ax.plot(point_xvals,\n",
    "            list_f0_pct_error_median,\n",
    "            color='k',\n",
    "            ls='',\n",
    "            marker='.',\n",
    "            ms=3)\n",
    "\n",
    "ax = util_figures.format_axes(ax,\n",
    "                              str_xlabel=str_xlabel,\n",
    "                              str_ylabel='Median F0 error for\\nnatural sounds (%F0)',\n",
    "                              xlimits=[-0.5, len(model_keys)-0.5],\n",
    "                              xticks=np.arange(0, len(model_keys)),\n",
    "                              xticks_minor=[],\n",
    "                              xticklabels=model_keys,\n",
    "                              yscale='log',\n",
    "                              ylimits=[0.4, 20],\n",
    "                              spines_to_hide=[])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('tmp.pdf', bbox_inches='tight', pad_inches=0, transparent=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
