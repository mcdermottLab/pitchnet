{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../assets_psychophysics')\n",
    "import util_human_model_comparison\n",
    "import util_figures_psychophysics\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    if not os.path.exists(valid_metrics_fn):\n",
    "        return None\n",
    "    with open(valid_metrics_fn) as f:\n",
    "        valid_metrics_dict = json.load(f)\n",
    "    if metric_key not in valid_metrics_dict.keys():\n",
    "        # If metric_key does not exist in validation_metrics_dict, look for a similarly named key\n",
    "        for available_key in valid_metrics_dict.keys():\n",
    "            if all([mkp in available_key for mkp in metric_key.split(':')]):\n",
    "                metric_key = available_key\n",
    "                break\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize:\n",
    "        best_metric_value = np.max(metric_values)\n",
    "    else:\n",
    "        best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "\n",
    "def all_equal(iterator):\n",
    "    try:\n",
    "        iterator = iter(iterator)\n",
    "        first = next(iterator)\n",
    "        return all(np.array_equal(first, rest) for rest in iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "\n",
    "\n",
    "def combine_results_dicts(list_results_dicts):\n",
    "    results_dict = {}\n",
    "    rd0 = list_results_dicts[0]\n",
    "    for k in sorted(rd0.keys()):\n",
    "        if isinstance(rd0[k], (list, int, float, np.ndarray)):\n",
    "            results_dict[k] = np.array(rd0[k])\n",
    "        elif isinstance(rd0[k], dict):\n",
    "            results_dict[k] = {}\n",
    "            for k1 in sorted(rd0[k].keys()):\n",
    "                if isinstance(rd0[k][k1], (list, int, float, np.ndarray)):\n",
    "                    results_dict[k][k1] = np.array(rd0[k][k1])\n",
    "                elif isinstance(rd0[k][k1], dict):\n",
    "                    results_dict[k][k1] = {}\n",
    "                    for k2 in sorted(rd0[k][k1].keys()):\n",
    "                        if isinstance(rd0[k][k1][k2], (list, int, float, np.ndarray)):\n",
    "                            results_dict[k][k1][k2] = np.array(rd0[k][k1][k2])\n",
    "                        elif isinstance(rd0[k][k1][k2], dict):\n",
    "                            results_dict[k][k1][k2] = {}\n",
    "                            for k3 in sorted(rd0[k][k1][k2].keys()):\n",
    "                                if isinstance(rd0[k][k1][k2][k3], (list, int, float, np.ndarray)):\n",
    "                                    results_dict[k][k1][k2][k3] = np.array(rd0[k][k1][k2][k3])\n",
    "                                elif isinstance(rd0[k][k1][k2][k3], dict):\n",
    "                                    results_dict[k][k1][k2][k3] = {}\n",
    "                                    for k4 in sorted(rd0[k][k1][k2][k3].keys()):\n",
    "                                        if isinstance(rd0[k][k1][k2][k3][k4], (list, int, float, np.ndarray)):\n",
    "                                            results_dict[k][k1][k2][k3][k4] = np.array(rd0[k][k1][k2][k3][k4])\n",
    "                                        elif isinstance(rd0[k][k1][k2][k3][k4], dict):\n",
    "                                            raise ValueError(\"NESTING WENT TOO FAR\")\n",
    "\n",
    "    for k in sorted(results_dict.keys()):\n",
    "        if isinstance(results_dict[k], np.ndarray):\n",
    "            list_rdk = [rd[k] for rd in list_results_dicts]\n",
    "            if not all_equal(list_rdk):\n",
    "                results_dict[k] = np.stack(list_rdk, axis=0)\n",
    "\n",
    "        elif isinstance(results_dict[k], dict):\n",
    "            for k1 in sorted(results_dict[k].keys()):\n",
    "                if isinstance(results_dict[k][k1], np.ndarray):\n",
    "                    list_rdk = [rd[k][k1] for rd in list_results_dicts]\n",
    "                    if not all_equal(list_rdk):\n",
    "                        results_dict[k][k1] = np.stack(list_rdk, axis=0)\n",
    "\n",
    "                elif isinstance(results_dict[k][k1], dict):\n",
    "                    for k2 in sorted(results_dict[k][k1].keys()):\n",
    "                        if isinstance(results_dict[k][k1][k2], np.ndarray):\n",
    "                            list_rdk = [rd[k][k1][k2] for rd in list_results_dicts]\n",
    "                            if not all_equal(list_rdk):\n",
    "                                results_dict[k][k1][k2] = np.stack(list_rdk, axis=0)\n",
    "\n",
    "                        elif isinstance(results_dict[k][k1][k2], dict):\n",
    "                            for k3 in sorted(results_dict[k][k1][k2].keys()):\n",
    "                                if isinstance(results_dict[k][k1][k2][k3], np.ndarray):\n",
    "                                    list_rdk = [rd[k][k1][k2][k3] for rd in list_results_dicts]\n",
    "                                    if not all_equal(list_rdk):\n",
    "                                        results_dict[k][k1][k2][k3] = np.stack(list_rdk, axis=0)\n",
    "\n",
    "                                elif isinstance(results_dict[k][k1][k2][k3], dict):\n",
    "                                    for k4 in sorted(results_dict[k][k1][k2][k3].keys()):\n",
    "                                        if isinstance(results_dict[k][k1][k2][k3][k4], np.ndarray):\n",
    "                                            list_rdk = [rd[k][k1][k2][k3][k4] for rd in list_results_dicts]\n",
    "                                            if not all_equal(list_rdk):\n",
    "                                                results_dict[k][k1][k2][k3][k4] = np.stack(list_rdk, axis=0)\n",
    "\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_transposedtones_v01_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_freqshifted_v01_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_mistunedharm_v01_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_altphase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "experiment_to_compfunc_map = {\n",
    "    'bernox2005': util_human_model_comparison.compare_bernox2005,\n",
    "    'transposedtones': util_human_model_comparison.compare_transposedtones,\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.compare_freqshiftedcomplexes,\n",
    "    'mistunedharmonics': util_human_model_comparison.compare_mistunedharmonics,\n",
    "    'altphasecomplexes': util_human_model_comparison.compare_altphasecomplexes_hist,\n",
    "}\n",
    "\n",
    "experiment_to_compfunc_kwargs_map = {\n",
    "    'bernox2005': {},\n",
    "    'transposedtones': {},\n",
    "    'freqshiftedcomplexes': {},\n",
    "    'mistunedharmonics': {},\n",
    "    'altphasecomplexes': {},\n",
    "}\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'altphasecomplexes',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'transposedtones',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/ 10\n"
     ]
    }
   ],
   "source": [
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "list_regex_model_dir = [\n",
    "    '/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/',\n",
    "\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/',\n",
    "]\n",
    "\n",
    "# Compile list of lists of model psychophysical data to plot grid of results (models-by-experiments)\n",
    "list_list_model_dir = []\n",
    "list_list_valid_metric = []\n",
    "list_dict_results_dicts = []\n",
    "list_dict_human_model_comparison = []\n",
    "list_dict_super = []\n",
    "# For each entry in list_regex_model_dir, grab all of the models that are globbed by the regex\n",
    "for regex_model_dir in list_regex_model_dir:\n",
    "    prefix = None\n",
    "    if isinstance(regex_model_dir, tuple):\n",
    "        (regex_model_dir, prefix) = regex_model_dir\n",
    "    \n",
    "    list_model_dir = []\n",
    "    list_valid_metric = []\n",
    "    dict_results_dicts = {ek: [] for ek in experiment_keys}\n",
    "    dict_human_model_comparison = {\n",
    "        ek: {'human_model_similarity_pval': [], 'human_model_similarity_coef': []}\n",
    "        for ek in experiment_keys}\n",
    "\n",
    "    for idx, model_dir in enumerate(sorted(glob.glob(regex_model_dir))):\n",
    "        fn_valid_metric = os.path.join(model_dir, basename_valid_metrics)\n",
    "        fn_result_dict = {\n",
    "            ek: os.path.join(model_dir, experiment_to_basename_map[ek]) for ek in experiment_keys\n",
    "        }\n",
    "        if 'snr_pos' in model_dir:\n",
    "            high_snr_basename = 'EVAL_SOFTMAX_lowharm_v04_bestckpt_results_dict.json'\n",
    "            fn_result_dict['bernox2005'] = os.path.join(model_dir, high_snr_basename)\n",
    "            high_snr_basename = 'EVAL_SOFTMAX_transposedtones_v02_bestckpt_results_dict.json'\n",
    "            fn_result_dict['transposedtones'] = os.path.join(model_dir, high_snr_basename)\n",
    "            print(model_dir)\n",
    "        if prefix is not None:\n",
    "            for k in fn_result_dict.keys():\n",
    "                fn_result_dict[k] = fn_result_dict[k].replace('EVAL_SOFTMAX', prefix)\n",
    "        include_model_flag = True\n",
    "        for ek in experiment_keys:\n",
    "            if not os.path.exists(fn_result_dict[ek]):\n",
    "                include_model_flag = False\n",
    "        if include_model_flag:\n",
    "            list_valid_metric.append(calc_best_metric(fn_valid_metric))\n",
    "            list_model_dir.append(model_dir)\n",
    "            # Load results_dict for each model and experiment\n",
    "            for ek, results_dict_fn in fn_result_dict.items():\n",
    "                results_dict = load_results_dict(results_dict_fn)\n",
    "                dict_results_dicts[ek].append(results_dict)\n",
    "                # Measure human-model similarity for each model and experiment\n",
    "                compfunc = experiment_to_compfunc_map[ek]\n",
    "                compfunc_kwargs = experiment_to_compfunc_kwargs_map[ek]\n",
    "                r, p = compfunc(\n",
    "                    experiment_to_human_results_map[ek],\n",
    "                    results_dict,\n",
    "                    **compfunc_kwargs)\n",
    "                dict_human_model_comparison[ek]['human_model_similarity_coef'].append(r)\n",
    "                dict_human_model_comparison[ek]['human_model_similarity_pval'].append(p)\n",
    "\n",
    "    dict_super = {}\n",
    "    for ek in experiment_keys:\n",
    "        dict_super[ek] = combine_results_dicts(dict_results_dicts[ek])\n",
    "        dict_super[ek]['human_model_similarity_coef'] = dict_human_model_comparison[ek]['human_model_similarity_coef']\n",
    "        dict_super[ek]['human_model_similarity_pval'] = dict_human_model_comparison[ek]['human_model_similarity_pval']\n",
    "        dict_super[ek]['validation_accuracy'] = list_valid_metric\n",
    "\n",
    "    # Add lists of model results to the master list\n",
    "    list_list_valid_metric.append(list_valid_metric)\n",
    "    list_list_model_dir.append(list_model_dir)\n",
    "    list_dict_results_dicts.append(dict_results_dicts)\n",
    "    list_dict_human_model_comparison.append(dict_human_model_comparison)\n",
    "    list_dict_super.append(dict_super)\n",
    "    \n",
    "    print(regex_model_dir, len(list_model_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pitchnet_paper_stats_data_psychophysics_2020AUG09.json', 'r') as f:\n",
    "    DATA_DICT = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________ bernox2005 ____________________________\n",
      "### OLD\n",
      "f0dl (10, 60)\n",
      "human_combined_model_similarity_coef ()\n",
      "human_combined_model_similarity_pval ()\n",
      "human_combined_model_similarity_rand_coef ()\n",
      "human_combined_model_similarity_rand_pval ()\n",
      "human_combined_model_similarity_sine_coef ()\n",
      "human_combined_model_similarity_sine_pval ()\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "low_harm (60,)\n",
      "phase_mode (60,)\n",
      "### NEW\n",
      "f0dl (10, 60)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior ()\n",
      "low_harm (60,)\n",
      "phase_mode (60,)\n",
      "validation_accuracy (10,)\n",
      "COMPARING f0dl_NEW and f0dl_OLD\n",
      "93.99341047890917\n",
      "100.0 100.0 0.21645388920785683\n",
      "____________________________ altphasecomplexes ____________________________\n",
      "### OLD\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "### NEW\n",
      "f0_bin_centers (12,)\n",
      "f0_pred_ratio_results ()\n",
      "filter_fl_bin_means ()\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior ()\n",
      "validation_accuracy (10,)\n",
      "____________________________ freqshiftedcomplexes ____________________________\n",
      "### OLD\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "### NEW\n",
      "f0_max ()\n",
      "f0_min ()\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior ()\n",
      "spectral_envelope_centered_harmonic ()\n",
      "validation_accuracy (10,)\n",
      "____________________________ mistunedharmonics ____________________________\n",
      "### OLD\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "### NEW\n",
      "f0_ref ()\n",
      "f0_ref_list (3,)\n",
      "f0_ref_width ()\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior ()\n",
      "validation_accuracy (10,)\n",
      "____________________________ transposedtones ____________________________\n",
      "### OLD\n",
      "f0_ref (20,)\n",
      "f0dl (10, 20)\n",
      "f_carrier (20,)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "tt_combined_f0_ref (10,)\n",
      "tt_combined_f0dl (10, 10)\n",
      "tt_combined_f_carrier (10,)\n",
      "### NEW\n",
      "f0_ref (20,)\n",
      "f0dl (10, 20)\n",
      "f_carrier (20,)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior ()\n",
      "validation_accuracy (10,)\n",
      "COMPARING f0dl_NEW and f0dl_OLD\n",
      "95.31568273666707\n",
      "100.0 100.0 0.24719918934418514\n"
     ]
    }
   ],
   "source": [
    "for ek in experiment_keys:\n",
    "    print('____________________________', ek, '____________________________')\n",
    "    X = DATA_DICT['IHC3000Hz-{}'.format(ek)]\n",
    "    print('### OLD')\n",
    "    for k in sorted(X.keys()):\n",
    "        print(k, np.array(X[k]).shape)\n",
    "    print('### NEW')\n",
    "    for k in sorted(list_dict_super[0][ek].keys()):\n",
    "        print(k, np.array(list_dict_super[0][ek][k]).shape)\n",
    "    \n",
    "    if 'f0dl' in X:\n",
    "        f0dl_OLD = np.array(X['f0dl'])\n",
    "        f0dl_NEW = np.array(list_dict_super[0][ek]['f0dl'])\n",
    "        \n",
    "        f0dl_OLD[f0dl_OLD > 100.0] = 100.0\n",
    "        f0dl_NEW[f0dl_NEW > 100.0] = 100.0\n",
    "        print('COMPARING f0dl_NEW and f0dl_OLD')\n",
    "        print(np.max(np.abs(f0dl_OLD - f0dl_NEW)))\n",
    "        print(np.max(f0dl_OLD), np.max(f0dl_NEW), np.min(f0dl_NEW))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0_ref 200.0 f0_min ()\n",
      "f0_ref 200.0 mistuned_harm 1 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 1 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 1 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 1 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 1 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 12 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 12 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 12 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 12 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 12 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 6 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 6 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 6 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 6 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 6 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 9 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 9 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 9 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 9 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 9 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 7 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 7 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 7 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 7 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 7 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 5 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 5 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 5 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 5 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 5 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 4 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 4 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 4 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 4 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 4 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 10 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 10 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 10 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 10 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 10 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 11 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 11 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 11 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 11 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 11 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 3 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 3 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 3 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 3 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 3 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 2 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 2 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 2 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 2 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 2 mistuned_pct (13,)\n",
      "f0_ref 200.0 mistuned_harm 8 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 8 f0_pred_pct_median (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 8 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 200.0 mistuned_harm 8 mistuned_harm ()\n",
      "f0_ref 200.0 mistuned_harm 8 mistuned_pct (13,)\n",
      "f0_ref 200.0 f0_max ()\n",
      "f0_ref 100.0 f0_min ()\n",
      "f0_ref 100.0 mistuned_harm 1 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 1 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 1 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 1 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 1 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 12 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 12 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 12 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 12 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 12 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 6 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 6 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 6 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 6 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 6 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 9 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 9 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 9 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 9 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 9 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 7 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 7 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 7 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 7 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 7 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 5 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 5 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 5 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 5 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 5 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 4 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 4 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 4 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 4 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 4 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 10 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 10 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 10 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 10 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 10 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 11 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 11 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 11 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 11 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 11 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 3 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 3 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 3 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 3 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 3 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 2 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 2 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 2 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 2 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 2 mistuned_pct (13,)\n",
      "f0_ref 100.0 mistuned_harm 8 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 8 f0_pred_pct_median (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 8 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 100.0 mistuned_harm 8 mistuned_harm ()\n",
      "f0_ref 100.0 mistuned_harm 8 mistuned_pct (13,)\n",
      "f0_ref 100.0 f0_max ()\n",
      "f0_ref 400.0 f0_min ()\n",
      "f0_ref 400.0 mistuned_harm 1 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 1 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 1 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 1 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 1 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 12 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 12 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 12 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 12 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 12 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 6 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 6 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 6 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 6 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 6 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 9 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 9 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 9 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 9 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 9 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 7 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 7 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 7 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 7 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 7 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 5 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 5 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 5 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 5 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 5 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 4 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 4 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 4 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 4 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 4 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 10 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 10 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 10 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 10 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 10 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 11 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 11 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 11 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 11 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 11 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 3 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 3 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 3 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 3 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 3 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 2 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 2 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 2 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 2 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 2 mistuned_pct (13,)\n",
      "f0_ref 400.0 mistuned_harm 8 f0_pred_pct_mean (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 8 f0_pred_pct_median (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 8 f0_pred_pct_stddev (10, 13)\n",
      "f0_ref 400.0 mistuned_harm 8 mistuned_harm ()\n",
      "f0_ref 400.0 mistuned_harm 8 mistuned_pct (13,)\n",
      "f0_ref 400.0 f0_max ()\n",
      "f0_ref_list (3,)\n",
      "f0_ref_width ()\n",
      "kwargs_f0_prior octave_range (2,)\n"
     ]
    }
   ],
   "source": [
    "X = combine_results_dicts(list_dict_results_dicts[0]['mistunedharmonics'])\n",
    "for k in X.keys():\n",
    "    if isinstance(X[k], dict):\n",
    "        for k1 in X[k].keys():\n",
    "            if isinstance(X[k][k1], dict):\n",
    "                for k2 in X[k][k1].keys():\n",
    "                    if isinstance(X[k][k1][k2], dict):\n",
    "                        for k3 in X[k][k1][k2].keys():\n",
    "                            if isinstance(X[k][k1][k2][k3], dict):\n",
    "                                for k4 in X[k][k1][k2][k3].keys():\n",
    "                                    print(k, k1, k2, k3, k4, X[k][k1][k2][k3][k4].shape)\n",
    "                            else:\n",
    "                                print(k, k1, k2, k3, X[k][k1][k2][k3].shape)\n",
    "                    else:\n",
    "                        print(k, k1, k2, X[k][k1][k2].shape)\n",
    "            else:\n",
    "                print(k, k1, X[k][k1].shape)\n",
    "    else:\n",
    "        print(k, X[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
