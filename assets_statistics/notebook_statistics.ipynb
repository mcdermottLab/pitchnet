{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../assets_psychophysics')\n",
    "import util_human_model_comparison\n",
    "import util_figures_psychophysics\n",
    "\n",
    "\n",
    "def load_results_dict(results_dict_fn, pop_key_list=['psychometric_function']):\n",
    "    with open(results_dict_fn) as f: results_dict = json.load(f)\n",
    "    for pop_key in pop_key_list:\n",
    "        if pop_key in results_dict.keys():\n",
    "            results_dict.pop(pop_key)\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def calc_best_metric(valid_metrics_fn, metric_key='f0_label:accuracy', maximize=True):\n",
    "    if not os.path.exists(valid_metrics_fn):\n",
    "        return None\n",
    "    with open(valid_metrics_fn) as f:\n",
    "        valid_metrics_dict = json.load(f)\n",
    "    if metric_key not in valid_metrics_dict.keys():\n",
    "        # If metric_key does not exist in validation_metrics_dict, look for a similarly named key\n",
    "        for available_key in valid_metrics_dict.keys():\n",
    "            if all([mkp in available_key for mkp in metric_key.split(':')]):\n",
    "                metric_key = available_key\n",
    "                break\n",
    "    metric_values = valid_metrics_dict[metric_key]\n",
    "    if maximize:\n",
    "        best_metric_value = np.max(metric_values)\n",
    "    else:\n",
    "        best_metric_value = np.min(metric_values)\n",
    "    return best_metric_value\n",
    "\n",
    "\n",
    "def flatten_dict(d, parent_key=None, sep='/'):\n",
    "    d_flat = {}\n",
    "    for key in sorted(d.keys()):\n",
    "        key_flat = key\n",
    "        if parent_key is not None:\n",
    "            key_flat = parent_key + sep + key_flat\n",
    "        if isinstance(d[key], dict):\n",
    "            d_flat.update(flatten_dict(d[key], parent_key=key_flat, sep=sep))\n",
    "        else:\n",
    "            d_flat.update({key_flat: d[key]})\n",
    "    return d_flat\n",
    "\n",
    "\n",
    "def all_equal(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    first = next(iterator)\n",
    "    return all(np.array_equal(first, rest) for rest in iterator)\n",
    "\n",
    "\n",
    "def concatenate_dicts(list_d):\n",
    "    list_d_flat = [flatten_dict(d) for d in list_d]\n",
    "    d_concatenated = {}\n",
    "    for key in sorted(list_d_flat[0].keys()):\n",
    "        if isinstance(list_d_flat[0][key], (list, int, float, np.ndarray)):\n",
    "            list_key_val = [d[key] for d in list_d_flat]\n",
    "            if all_equal(list_key_val):\n",
    "                d_concatenated[key] = list_key_val[0]\n",
    "            else:\n",
    "                d_concatenated[key] = np.stack(list_key_val, axis=0)\n",
    "    return d_concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_to_basename_map = {\n",
    "    'bernox2005': 'EVAL_SOFTMAX_lowharm_v01_bestckpt_results_dict.json',\n",
    "    'transposedtones': 'EVAL_SOFTMAX_transposedtones_v01_bestckpt_results_dict.json',\n",
    "    'freqshiftedcomplexes': 'EVAL_SOFTMAX_freqshifted_v01_bestckpt_results_dict.json',\n",
    "    'mistunedharmonics': 'EVAL_SOFTMAX_mistunedharm_v01_bestckpt_results_dict.json',\n",
    "    'altphasecomplexes': 'EVAL_SOFTMAX_altphase_v01_bestckpt_results_dict.json',\n",
    "}\n",
    "\n",
    "experiment_to_human_results_map = {\n",
    "    'bernox2005': util_human_model_comparison.get_human_results_dict_bernox2005(),\n",
    "    'transposedtones': util_human_model_comparison.get_human_results_dict_transposedtones(),\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.get_human_results_dict_freqshiftedcomplexes(),\n",
    "    'mistunedharmonics': util_human_model_comparison.get_human_results_dict_mistunedharmonics(),\n",
    "    'altphasecomplexes': util_human_model_comparison.get_human_results_dict_altphasecomplexes(),\n",
    "}\n",
    "\n",
    "experiment_to_compfunc_map = {\n",
    "    'bernox2005': util_human_model_comparison.compare_bernox2005,\n",
    "    'transposedtones': util_human_model_comparison.compare_transposedtones,\n",
    "    'freqshiftedcomplexes': util_human_model_comparison.compare_freqshiftedcomplexes,\n",
    "    'mistunedharmonics': util_human_model_comparison.compare_mistunedharmonics,\n",
    "    'altphasecomplexes': util_human_model_comparison.compare_altphasecomplexes_hist,\n",
    "}\n",
    "\n",
    "experiment_to_compfunc_kwargs_map = {\n",
    "    'bernox2005': {},\n",
    "    'transposedtones': {},\n",
    "    'freqshiftedcomplexes': {},\n",
    "    'mistunedharmonics': {},\n",
    "    'altphasecomplexes': {},\n",
    "}\n",
    "\n",
    "experiment_keys = [\n",
    "    'bernox2005',\n",
    "    'altphasecomplexes',\n",
    "    'freqshiftedcomplexes',\n",
    "    'mistunedharmonics',\n",
    "    'transposedtones',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/ 10\n",
      "/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/ 10\n"
     ]
    }
   ],
   "source": [
    "basename_valid_metrics = 'validation_metrics.json'\n",
    "list_regex_model_dir = [\n",
    "    '/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/',\n",
    "\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr2000_cf1000_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0050Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC0320Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC1000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC6000Hz_IHC7order/arch_0???/',\n",
    "    '/saved_models/arch_search_v02_topN/REDOsr20000_cf100_species002_spont070_BW10eN1_IHC9000Hz_IHC7order/arch_0???/',\n",
    "]\n",
    "\n",
    "# Compile list of lists of model psychophysical data\n",
    "list_list_model_dir = []\n",
    "list_dict_super = []\n",
    "\n",
    "# For each entry in list_regex_model_dir, grab all of the models that are globbed by the regex\n",
    "for regex_model_dir in list_regex_model_dir:\n",
    "    prefix = None\n",
    "    if isinstance(regex_model_dir, tuple):\n",
    "        (regex_model_dir, prefix) = regex_model_dir\n",
    "\n",
    "    list_model_dir = []\n",
    "    list_valid_metric = []\n",
    "    dict_results_dicts = {ek: [] for ek in experiment_keys}\n",
    "    dict_human_model_comparison = {\n",
    "        ek: {\n",
    "            'human_model_similarity_pval': [],\n",
    "            'human_model_similarity_coef': [],\n",
    "        }\n",
    "        for ek in experiment_keys\n",
    "    }\n",
    "    for idx, model_dir in enumerate(sorted(glob.glob(regex_model_dir))):\n",
    "        fn_valid_metric = os.path.join(model_dir, basename_valid_metrics)\n",
    "        fn_result_dict = {\n",
    "            ek: os.path.join(model_dir, experiment_to_basename_map[ek]) for ek in experiment_keys\n",
    "        }\n",
    "        if 'snr_pos' in model_dir:\n",
    "            high_snr_basename = 'EVAL_SOFTMAX_lowharm_v04_bestckpt_results_dict.json'\n",
    "            fn_result_dict['bernox2005'] = os.path.join(model_dir, high_snr_basename)\n",
    "            high_snr_basename = 'EVAL_SOFTMAX_transposedtones_v02_bestckpt_results_dict.json'\n",
    "            fn_result_dict['transposedtones'] = os.path.join(model_dir, high_snr_basename)\n",
    "            print(model_dir)\n",
    "        if prefix is not None:\n",
    "            for k in fn_result_dict.keys():\n",
    "                fn_result_dict[k] = fn_result_dict[k].replace('EVAL_SOFTMAX', prefix)\n",
    "        include_model_flag = True\n",
    "        for ek in experiment_keys:\n",
    "            if not os.path.exists(fn_result_dict[ek]):\n",
    "                include_model_flag = False\n",
    "        if include_model_flag:\n",
    "            list_valid_metric.append(calc_best_metric(fn_valid_metric))\n",
    "            list_model_dir.append(model_dir)\n",
    "            # Load results_dict for each model and experiment\n",
    "            for ek, results_dict_fn in fn_result_dict.items():\n",
    "                results_dict = load_results_dict(results_dict_fn)\n",
    "                dict_results_dicts[ek].append(results_dict)\n",
    "                # Measure human-model similarity for each model and experiment\n",
    "                compfunc = experiment_to_compfunc_map[ek]\n",
    "                compfunc_kwargs = experiment_to_compfunc_kwargs_map[ek]\n",
    "                r, p = compfunc(\n",
    "                    experiment_to_human_results_map[ek],\n",
    "                    results_dict,\n",
    "                    **compfunc_kwargs)\n",
    "                dict_human_model_comparison[ek]['human_model_similarity_coef'].append(r)\n",
    "                dict_human_model_comparison[ek]['human_model_similarity_pval'].append(p)\n",
    "\n",
    "    dict_super = {}\n",
    "    for ek in experiment_keys:\n",
    "        dict_super[ek] = concatenate_dicts(dict_results_dicts[ek])\n",
    "        dict_super[ek]['human_model_similarity_coef'] = dict_human_model_comparison[ek]['human_model_similarity_coef']\n",
    "        dict_super[ek]['human_model_similarity_pval'] = dict_human_model_comparison[ek]['human_model_similarity_pval']\n",
    "        dict_super[ek]['validation_accuracy'] = list_valid_metric\n",
    "\n",
    "    # Add lists of model results to the master list\n",
    "    list_list_model_dir.append(list_model_dir)\n",
    "    list_dict_super.append(dict_super)\n",
    "\n",
    "    print(regex_model_dir, len(list_model_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________ bernox2005 ________________________\n",
      "f0dl (10, 60)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior/octave_range (2,)\n",
      "low_harm (60,)\n",
      "phase_mode (60,)\n",
      "validation_accuracy (10,)\n",
      "________________________ altphasecomplexes ________________________\n",
      "f0_bin_centers (12,)\n",
      "f0_pred_ratio_results/f0_condition_list (9,)\n",
      "f0_pred_ratio_results/f0_pred_ratio_list (10, 9)\n",
      "f0_pred_ratio_results/filter_condition_list (9,)\n",
      "f0_pred_ratio_results/kwargs_f0_pred_ratio/f0_bin_centers (3,)\n",
      "f0_pred_ratio_results/kwargs_f0_pred_ratio/f0_bin_width ()\n",
      "filter_fl_bin_means/125.0 (10, 12)\n",
      "filter_fl_bin_means/1375.0 (10, 12)\n",
      "filter_fl_bin_means/3900.0 (10, 12)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior/octave_range (2,)\n",
      "validation_accuracy (10,)\n",
      "________________________ freqshiftedcomplexes ________________________\n",
      "f0_max ()\n",
      "f0_min ()\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior/octave_range (2,)\n",
      "spectral_envelope_centered_harmonic/11/f0_pred_shift_mean (10, 7)\n",
      "spectral_envelope_centered_harmonic/11/f0_pred_shift_median (10, 7)\n",
      "spectral_envelope_centered_harmonic/11/f0_pred_shift_stddev (10, 7)\n",
      "spectral_envelope_centered_harmonic/11/f0_shift (7,)\n",
      "spectral_envelope_centered_harmonic/16/f0_pred_shift_mean (10, 7)\n",
      "spectral_envelope_centered_harmonic/16/f0_pred_shift_median (10, 7)\n",
      "spectral_envelope_centered_harmonic/16/f0_pred_shift_stddev (10, 7)\n",
      "spectral_envelope_centered_harmonic/16/f0_shift (7,)\n",
      "spectral_envelope_centered_harmonic/5/f0_pred_shift_mean (10, 7)\n",
      "spectral_envelope_centered_harmonic/5/f0_pred_shift_median (10, 7)\n",
      "spectral_envelope_centered_harmonic/5/f0_pred_shift_stddev (10, 7)\n",
      "spectral_envelope_centered_harmonic/5/f0_shift (7,)\n",
      "validation_accuracy (10,)\n",
      "________________________ mistunedharmonics ________________________\n",
      "________________________ transposedtones ________________________\n",
      "f0_ref (20,)\n",
      "f0dl (10, 20)\n",
      "f_carrier (20,)\n",
      "human_model_similarity_coef (10,)\n",
      "human_model_similarity_pval (10,)\n",
      "kwargs_f0_prior/octave_range (2,)\n",
      "validation_accuracy (10,)\n"
     ]
    }
   ],
   "source": [
    "for ek in experiment_keys:\n",
    "    print('_'*24, ek, '_'*24)\n",
    "    if 'mistuned' not in ek:\n",
    "        for k in sorted(list_dict_super[0][ek].keys()):\n",
    "            print(k, np.array(list_dict_super[0][ek][k]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pitchnet_paper_stats_data_psychophysics_2020AUG09.json', 'r') as f:\n",
    "    DATA_DICT = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ek in experiment_keys:\n",
    "#     print('____________________________', ek, '____________________________')\n",
    "#     X = DATA_DICT['IHC3000Hz-{}'.format(ek)]\n",
    "#     print('### OLD')\n",
    "#     for k in sorted(X.keys()):\n",
    "#         print(k, np.array(X[k]).shape)\n",
    "#     print('### NEW')\n",
    "#     for k in sorted(list_dict_super[0][ek].keys()):\n",
    "#         print(k, np.array(list_dict_super[0][ek][k]).shape)\n",
    "    \n",
    "#     if 'f0dl' in X:\n",
    "#         f0dl_OLD = np.array(X['f0dl'])\n",
    "#         f0dl_NEW = np.array(list_dict_super[0][ek]['f0dl'])\n",
    "        \n",
    "#         f0dl_OLD[f0dl_OLD > 100.0] = 100.0\n",
    "#         f0dl_NEW[f0dl_NEW > 100.0] = 100.0\n",
    "#         print('COMPARING f0dl_NEW and f0dl_OLD')\n",
    "#         print(np.max(np.abs(f0dl_OLD - f0dl_NEW)))\n",
    "#         print(np.max(f0dl_OLD), np.max(f0dl_NEW), np.min(f0dl_NEW))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
